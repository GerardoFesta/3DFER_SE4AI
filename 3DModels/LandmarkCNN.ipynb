{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GerardoFesta/3DFER_SE4AI/blob/main/3DModels/LandmarkCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FapmTK_OFaC",
        "outputId": "707aa425-6145-4c8d-d06c-51f2217258f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mlflow\n",
        "!databricks configure --host https://community.cloud.databricks.com/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1AydPg2zdxu",
        "outputId": "9e1e9d02-fe04-4675-e297-9cd725996a6b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Username: gfesta24@gmail.com\n",
            "Password: \n",
            "Repeat for confirmation: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import sys\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "u48FmrFrUoY0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/drive/Shareddrives/Datasets SEFAI/training_set.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/Shareddrives/Datasets SEFAI/test_set.csv\")"
      ],
      "metadata": {
        "id": "IHibrFNrUpAX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#Questo commento serve per provare il funzionamento dei commit con colab\n",
        "\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "bryr8yPGUt5D"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X_array, Y_array, transform=None):\n",
        "        self.X = X_array\n",
        "        self.Y = Y_array\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.X[index]\n",
        "        label = self.Y[index]\n",
        "\n",
        "        # Esegui le trasformazioni se definite\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "LfCxw2btUxW2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_df['landmarks'] = test_df['landmarks'].apply(lambda lab: eval(lab))\n",
        "\n",
        "train_df['landmarks'] = train_df['landmarks'].apply(lambda lab: eval(lab))\n",
        "print(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "3usK34x0Uzdc",
        "outputId": "f3eef38c-b988-4fa1-f33a-b3dd4865862f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-c09c094a60e9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'landmarks'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'landmarks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'landmarks'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'landmarks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4770\u001b[0m         \"\"\"\n\u001b[0;32m-> 4771\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4773\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;31m# self.f is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m                 mapped = lib.map_infer(\n\u001b[0m\u001b[1;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-c09c094a60e9>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(lab)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'landmarks'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'landmarks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'landmarks'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'landmarks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: eval() arg 1 must be a string, bytes or code object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_df.at[0,\"landmarks\"]))\n",
        "\n",
        "label_dict = {\"angry\":0, \"sad\": 1, \"neutral\": 2, \"surprise\": 3, \"disgust\": 4, \"fear\": 5, \"happy\": 6}\n",
        "\n",
        "test_df['label'] = test_df['label'].apply(lambda lab: label_dict[lab])\n",
        "\n",
        "train_df['label'] = train_df['label'].apply(lambda lab: label_dict[lab])\n",
        "\n",
        "array_train = train_df['landmarks'].to_numpy()\n",
        "X_train = np.stack([np.array(lst) for lst in array_train])\n",
        "y_train = train_df['label'].to_numpy()\n",
        "array_test = test_df['landmarks'].to_numpy()\n",
        "X_test = np.stack([np.array(lst) for lst in array_test])\n",
        "y_test = test_df['label'].to_numpy()"
      ],
      "metadata": {
        "id": "_isIbX4iU2Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(X_train, y_train, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "test_dataset = CustomDataset(X_test, y_test, transform=transforms.ToTensor())\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print( X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCS33IqXU7IE",
        "outputId": "21da356e-a696-4864-ef1f-c5eafc304d95"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26705, 478, 3) (26705,) (6678, 478, 3) (6678,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(preds, labels):\n",
        "  probabilities = torch.nn.functional.softmax(preds, dim=1)\n",
        "  _, predicted = torch.max(probabilities, dim=1)\n",
        "  n_correct = (predicted==labels).sum().float()\n",
        "\n",
        "  acc =n_correct / labels.shape[0]\n",
        "  acc= torch.round(acc*100)\n",
        "  return acc, n_correct;"
      ],
      "metadata": {
        "id": "7u4XfRo9U8tZ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class LandmarkCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LandmarkCNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(3, 32, kernel_size=3, padding=1, dtype=torch.float64)\n",
        "        self.bn1 = nn.BatchNorm1d(32, dtype=torch.float64)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1, dtype=torch.float64)\n",
        "        self.bn2 = nn.BatchNorm1d(64, dtype=torch.float64)\n",
        "\n",
        "        self.pool = nn.MaxPool1d(2, 2)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1, dtype=torch.float64)\n",
        "        self.bn3 = nn.BatchNorm1d(128, dtype=torch.float64)\n",
        "\n",
        "        self.conv4 = nn.Conv1d(128, 128, kernel_size=3, padding=1, dtype=torch.float64)\n",
        "        self.bn4 = nn.BatchNorm1d(128, dtype=torch.float64)\n",
        "\n",
        "        self.dropout2 = nn.Dropout(0.25)\n",
        "\n",
        "        self.conv5 = nn.Conv1d(128, 256, kernel_size=3, padding=1, dtype=torch.float64)\n",
        "        self.bn5 = nn.BatchNorm1d(256, dtype=torch.float64)\n",
        "\n",
        "        self.conv6 = nn.Conv1d(256, 256, kernel_size=3, padding=1, dtype=torch.float64)\n",
        "        self.bn6 = nn.BatchNorm1d(256, dtype=torch.float64)\n",
        "\n",
        "        self.dropout3 = nn.Dropout(0.25)\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 59, 256, dtype=torch.float64)\n",
        "        self.bn7 = nn.BatchNorm1d(256, dtype=torch.float64)\n",
        "\n",
        "        self.dropout4 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc2 = nn.Linear(256, 7, dtype=torch.float64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3, 478)\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = nn.LeakyReLU()(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = nn.LeakyReLU()(x)\n",
        "\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = nn.LeakyReLU()(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = nn.LeakyReLU()(x)\n",
        "\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.bn5(x)\n",
        "        x = nn.LeakyReLU()(x)\n",
        "\n",
        "        x = self.conv6(x)\n",
        "        x = self.bn6(x)\n",
        "        x = nn.LeakyReLU()(x)\n",
        "\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout3(x)\n",
        "        x=x.view(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn7(x)\n",
        "        x = nn.LeakyReLU()(x)\n",
        "        x = self.dropout4(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "yfie7jhRU-vL"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LandmarkCNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "Zf4xTdGXVPZK"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "mlflow.set_tracking_uri(\"databricks\")\n",
        "mlflow.set_experiment(\"/Users/gfesta24@gmail.com/LandmarksCNN\")\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7FbuO2_z9Yk",
        "outputId": "f896bd0a-e217-41ee-fda1-1a40524a2266"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/1154140902182959', creation_time=1687113740157, experiment_id='1154140902182959', last_update_time=1687117276059, lifecycle_stage='active', name='/Users/gfesta24@gmail.com/LandmarksCNN', tags={'mlflow.experiment.sourceName': '/Users/gfesta24@gmail.com/LandmarksCNN',\n",
              " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
              " 'mlflow.ownerEmail': 'gfesta24@gmail.com',\n",
              " 'mlflow.ownerId': '1923923806180228'}>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.start_run()\n",
        "\n",
        "mlflow.set_tag(\"model_name\", \"ResNet50\")\n",
        "mlflow.log_param(\"lr\", 0.001)\n",
        "mlflow.log_param(\"batch_size\", 64)\n",
        "\n",
        "patience = 3\n",
        "\n",
        "acc_list_train=[]\n",
        "acc_list_test=[]\n",
        "\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "\n",
        "best_loss = 100\n",
        "counter=0\n",
        "stop=False\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        print(counter)\n",
        "        if stop:\n",
        "          print(stop)\n",
        "          break\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0\n",
        "        seen = 0\n",
        "        for images, labels in train_loader:\n",
        "\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "\n",
        "          outputs = model(images)\n",
        "\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          _, acc = accuracy(outputs, labels)\n",
        "          seen +=labels.shape[0]\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "          running_acc += acc\n",
        "\n",
        "        print (f'Epoch [{epoch}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Acc: {running_acc/seen:.4f}')\n",
        "        acc_list_train.append(running_acc/len(train_loader))\n",
        "        mlflow.log_metric(\"train_loss\", running_loss / len(train_loader), step=epoch)\n",
        "        mlflow.log_metric(\"train_acc\", running_acc/seen, step=epoch)\n",
        "        model.eval()\n",
        "\n",
        "        tot_corrette = 0\n",
        "        tot_eseguite = 0\n",
        "        running_test_loss = 0\n",
        "        val_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "          for images, labels in test_loader:\n",
        "              images = images.to(device)\n",
        "              labels = labels.to(device)\n",
        "\n",
        "              outputs = model(images)\n",
        "              test_loss = criterion(outputs, labels)\n",
        "              _, n_corrette=accuracy(outputs, labels)\n",
        "\n",
        "              running_test_loss += test_loss.item()\n",
        "              tot_corrette+=n_corrette.item()\n",
        "              tot_eseguite+=labels.shape[0]\n",
        "\n",
        "          test_acc=100* (tot_corrette/tot_eseguite)\n",
        "          val_loss = running_test_loss / len(test_loader)\n",
        "          acc_list_test.append(test_acc)\n",
        "          print(\"Test acc: \", test_acc)\n",
        "          print(\"Test loss: \", val_loss)\n",
        "          mlflow.log_metric(\"test_acc\", test_acc, step=epoch)\n",
        "          mlflow.log_metric(\"test_loss\", val_loss, step=epoch)\n",
        "\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "          print(\"MIGLIORATO\")\n",
        "          torch.save(model.state_dict(), 'model_weights.pth')\n",
        "          best_loss = val_loss\n",
        "          best_model_train_acc=running_acc/seen\n",
        "          best_model_test_acc=test_acc\n",
        "          best_model_test_loss=val_loss\n",
        "          best_model_train_loss=running_loss / len(train_loader)\n",
        "          counter = 0\n",
        "          # Salva i pesi del modello se la validation loss è migliorata\n",
        "          torch.save(model.state_dict(), 'best_model.pt')\n",
        "        else:\n",
        "          counter += 1\n",
        "        # Verifica se raggiunto il criterio di early stopping\n",
        "          if counter >= patience:\n",
        "              print(f'Early stopping at epoch {epoch+1}')\n",
        "              mlflow.set_tag(\"Epochs_stopped\", epoch+1)\n",
        "              mlflow.log_artifact(\"best_model.pt\")\n",
        "              mlflow.log_metric(\"best_test_acc\", best_model_test_acc)\n",
        "              mlflow.log_metric(\"best_test_loss\", best_model_test_loss)\n",
        "              mlflow.log_metric(\"best_train_acc\", best_model_train_acc)\n",
        "              mlflow.log_metric(\"best_train_loss\", best_model_train_loss)\n",
        "              mlflow.end_run()\n",
        "              stop=True\n",
        "        print(\"BEST TEST LOSS: \", best_loss)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJeu_qO0VZuL",
        "outputId": "3bedad0c-b9b1-48a4-f999-742b883e223c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Epoch [0/100], Loss: 1.5476, Acc: 0.4032\n",
            "Test acc:  46.55585504642109\n",
            "Test loss:  1.4000879606131353\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.4000879606131353\n",
            "0\n",
            "Epoch [1/100], Loss: 1.4266, Acc: 0.4472\n",
            "Test acc:  48.39772386942198\n",
            "Test loss:  1.3239127167453584\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3239127167453584\n",
            "0\n",
            "Epoch [2/100], Loss: 1.3890, Acc: 0.4625\n",
            "Test acc:  48.742138364779876\n",
            "Test loss:  1.3259888704156495\n",
            "BEST TEST LOSS:  1.3239127167453584\n",
            "1\n",
            "Epoch [3/100], Loss: 1.3679, Acc: 0.4735\n",
            "Test acc:  48.08325846061695\n",
            "Test loss:  1.3555247229467964\n",
            "BEST TEST LOSS:  1.3239127167453584\n",
            "2\n",
            "Epoch [4/100], Loss: 1.3548, Acc: 0.4780\n",
            "Test acc:  50.119796346211444\n",
            "Test loss:  1.3018348198260905\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3018348198260905\n",
            "0\n",
            "Epoch [5/100], Loss: 1.3341, Acc: 0.4853\n",
            "Test acc:  49.17640011979635\n",
            "Test loss:  1.3115598189246203\n",
            "BEST TEST LOSS:  1.3018348198260905\n",
            "1\n",
            "Epoch [6/100], Loss: 1.3285, Acc: 0.4883\n",
            "Test acc:  50.26954177897574\n",
            "Test loss:  1.2805724005890193\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2805724005890193\n",
            "0\n",
            "Epoch [7/100], Loss: 1.3143, Acc: 0.4898\n",
            "Test acc:  52.41090146750524\n",
            "Test loss:  1.2403728611899778\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2403728611899778\n",
            "0\n",
            "Epoch [8/100], Loss: 1.3039, Acc: 0.4965\n",
            "Test acc:  52.06648697214735\n",
            "Test loss:  1.2423966866674812\n",
            "BEST TEST LOSS:  1.2403728611899778\n",
            "1\n",
            "Epoch [9/100], Loss: 1.2960, Acc: 0.4973\n",
            "Test acc:  51.317759808325846\n",
            "Test loss:  1.2619253011930667\n",
            "BEST TEST LOSS:  1.2403728611899778\n",
            "2\n",
            "Epoch [10/100], Loss: 1.2883, Acc: 0.5034\n",
            "Test acc:  52.530697813716685\n",
            "Test loss:  1.2398469335667086\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2398469335667086\n",
            "0\n",
            "Epoch [11/100], Loss: 1.2815, Acc: 0.5044\n",
            "Test acc:  53.05480682839173\n",
            "Test loss:  1.2255007721678954\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2255007721678954\n",
            "0\n",
            "Epoch [12/100], Loss: 1.2756, Acc: 0.5069\n",
            "Test acc:  53.144654088050316\n",
            "Test loss:  1.2115845838516053\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2115845838516053\n",
            "0\n",
            "Epoch [13/100], Loss: 1.2729, Acc: 0.5106\n",
            "Test acc:  53.57891584306679\n",
            "Test loss:  1.1999994321809246\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1999994321809246\n",
            "0\n",
            "Epoch [14/100], Loss: 1.2574, Acc: 0.5162\n",
            "Test acc:  53.09973045822103\n",
            "Test loss:  1.216009067939152\n",
            "BEST TEST LOSS:  1.1999994321809246\n",
            "1\n",
            "Epoch [15/100], Loss: 1.2538, Acc: 0.5153\n",
            "Test acc:  52.890086852351004\n",
            "Test loss:  1.2163164424590076\n",
            "BEST TEST LOSS:  1.1999994321809246\n",
            "2\n",
            "Epoch [16/100], Loss: 1.2543, Acc: 0.5162\n",
            "Test acc:  52.80023959269242\n",
            "Test loss:  1.2173138096261666\n",
            "Early stopping at epoch 17\n",
            "BEST TEST LOSS:  1.1999994321809246\n",
            "3\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "model = LandmarkCNN()\n",
        "model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Calcola le metriche sul test dataset\n",
        "model.eval()  # Imposta il modello in modalità di valutazione (non addestramento)\n",
        "test_predictions = []\n",
        "test_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(torch.nn.functional.softmax(outputs, dim=1), 1)\n",
        "        test_predictions.extend(predictions.cpu().numpy())\n",
        "        test_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy = accuracy_score(test_labels, test_predictions)\n",
        "precision = precision_score(test_labels, test_predictions, average=None)\n",
        "f1 = f1_score(test_labels, test_predictions, average=None)\n",
        "#auc_roc = roc_auc_score(test_labels, test_predictions, multi_class='ovr')\n",
        "classification_rep = classification_report(test_labels, test_predictions)\n",
        "\n",
        "print(\"Test Metrics:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1 Score:\", f1)\n",
        "#print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXRhNcZ4Vfq2",
        "outputId": "2b6e613d-850a-4389-c25c-9327c2b3a05d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics:\n",
            "Accuracy: 0.5357891584306679\n",
            "Precision: [0.40390545 0.40468909 0.43455497 0.58848168 0.34482759 0.28888889\n",
            " 0.7944032 ]\n",
            "F1 Score: [0.43044907 0.3802682  0.51446281 0.64746544 0.15873016 0.12881916\n",
            " 0.802886  ]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.46      0.43       853\n",
            "           1       0.40      0.36      0.38      1107\n",
            "           2       0.43      0.63      0.51      1185\n",
            "           3       0.59      0.72      0.65       781\n",
            "           4       0.34      0.10      0.16        97\n",
            "           5       0.29      0.08      0.13       941\n",
            "           6       0.79      0.81      0.80      1714\n",
            "\n",
            "    accuracy                           0.54      6678\n",
            "   macro avg       0.47      0.45      0.44      6678\n",
            "weighted avg       0.51      0.54      0.51      6678\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "eIH-mFGGOZk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import zipfile\n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/content/drive/Shareddrives/Datasets SEFAI/scraped_pictures.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall() #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "-dPkuUe4O_qs"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uRiWrIYRPPrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "import glob, os\n",
        "import cv2\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "label_dict = {\"angry\":0, \"sad\": 1, \"neutral\": 2, \"surprise\": 3, \"disgust\": 4, \"fear\": 5, \"happy\": 6}\n",
        "label_arr=[]\n",
        "images = []\n",
        "with mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=True,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5) as face_mesh:\n",
        "\n",
        "    for root, dirs, files in os.walk(\"photos\"):\n",
        "      for dir in dirs:\n",
        "        if(not dir==\".ipynb_checkpoints\"):\n",
        "          label=label_dict[dir]\n",
        "          for _file in glob.glob(\"photos/\"+dir+\"/*.*\"):\n",
        "\n",
        "              image = cv2.imread(_file)\n",
        "          # Convert the BGR image to RGB before processing.\n",
        "              #print(_file)\n",
        "              results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "\n",
        "              annotated_image = image.copy()\n",
        "              if(results.multi_face_landmarks!=None):\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                  #print('face_landmarks:', face_landmarks)\n",
        "                  mp_drawing.draw_landmarks(\n",
        "                      image=annotated_image,\n",
        "                      landmark_list=face_landmarks,\n",
        "                      connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                      landmark_drawing_spec=None,\n",
        "                      connection_drawing_spec=mp_drawing_styles\n",
        "                      .get_default_face_mesh_tesselation_style())\n",
        "                  mp_drawing.draw_landmarks(\n",
        "                      image=annotated_image,\n",
        "                      landmark_list=face_landmarks,\n",
        "                      connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                      landmark_drawing_spec=None,\n",
        "                      connection_drawing_spec=mp_drawing_styles\n",
        "                      .get_default_face_mesh_contours_style())\n",
        "                  mp_drawing.draw_landmarks(\n",
        "                      image=annotated_image,\n",
        "                      landmark_list=face_landmarks,\n",
        "                      connections=mp_face_mesh.FACEMESH_IRISES,\n",
        "                      landmark_drawing_spec=None,\n",
        "                      connection_drawing_spec=mp_drawing_styles\n",
        "                      .get_default_face_mesh_iris_connections_style())\n",
        "                points_array = np.array(face_landmarks)\n",
        "\n",
        "                x_array=[]\n",
        "                y_array=[]\n",
        "                z_array=[]\n",
        "\n",
        "                landmark_matrix = []\n",
        "                for data_point in face_landmarks.landmark:\n",
        "                  landmark_matrix.append([data_point.x, data_point.y, data_point.z])\n",
        "\n",
        "                label_arr.append(label)\n",
        "                images.append(landmark_matrix)\n"
      ],
      "metadata": {
        "id": "MsKrK-BiOn5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.array(images)"
      ],
      "metadata": {
        "id": "cTjF4EdXRWCv"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.array(label_arr)"
      ],
      "metadata": {
        "id": "EV33OowHUirt"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scraped_dataset = CustomDataset(images, labels, transform=transforms.ToTensor())\n",
        "\n",
        "scraped_loader = DataLoader(scraped_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "MblUToiBURjC"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LandmarkCNN()\n",
        "model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Calcola le metriche sul test dataset\n",
        "model.eval()  # Imposta il modello in modalità di valutazione (non addestramento)\n",
        "test_predictions = []\n",
        "test_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in scraped_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(torch.nn.functional.softmax(outputs, dim=1), 1)\n",
        "        test_predictions.extend(predictions.cpu().numpy())\n",
        "        test_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy = accuracy_score(test_labels, test_predictions)\n",
        "precision = precision_score(test_labels, test_predictions, average=None)\n",
        "f1 = f1_score(test_labels, test_predictions, average=None)\n",
        "#auc_roc = roc_auc_score(test_labels, test_predictions, multi_class='ovr')\n",
        "classification_rep = classification_report(test_labels, test_predictions)\n",
        "\n",
        "print(\"Test Metrics:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1 Score:\", f1)\n",
        "#print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTkaV4MjUxGn",
        "outputId": "7a690567-3dd7-4359-d1c4-fc8596b77a80"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics:\n",
            "Accuracy: 0.30517711171662126\n",
            "Precision: [0.47826087 0.14210526 0.2        0.39705882 0.         0.\n",
            " 0.65671642]\n",
            "F1 Score: [0.25       0.23275862 0.13333333 0.45378151 0.         0.\n",
            " 0.61538462]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.17      0.25        65\n",
            "           1       0.14      0.64      0.23        42\n",
            "           2       0.20      0.10      0.13        30\n",
            "           3       0.40      0.53      0.45        51\n",
            "           4       0.00      0.00      0.00        74\n",
            "           5       0.00      0.00      0.00        29\n",
            "           6       0.66      0.58      0.62        76\n",
            "\n",
            "    accuracy                           0.31       367\n",
            "   macro avg       0.27      0.29      0.24       367\n",
            "weighted avg       0.31      0.31      0.27       367\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}