{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GerardoFesta/3DFER_SE4AI/blob/1-poor-performances-on-test-set/ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "04Ind-xwGX3t",
        "outputId": "22f7bdd5-b160-435e-a17c-5b2ee6e689ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Username: gfesta24@gmail.com\n",
            "Password: \n",
            "Repeat for confirmation: \n"
          ]
        }
      ],
      "source": [
        "!databricks configure --host https://community.cloud.databricks.com/\n",
        "!pip install -q mlflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import mlflow\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "TRAIN_PATH = \"train\"\n",
        "TEST_PATH =\"test\"\n"
      ],
      "metadata": {
        "id": "gsen0EXzN_aK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "mlflow.set_tracking_uri(\"databricks\")\n",
        "mlflow.set_experiment(\"/Users/gfesta24@gmail.com/2DFERResNet\")"
      ],
      "metadata": {
        "id": "1BTZqxSaSB94",
        "outputId": "c5253b1e-7bbf-412a-fa3b-bc944931c9f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/4292817106382685', creation_time=1685048826432, experiment_id='4292817106382685', last_update_time=1685634027802, lifecycle_stage='active', name='/Users/gfesta24@gmail.com/2DFERResNet', tags={'mlflow.experiment.sourceName': '/Users/gfesta24@gmail.com/2DFERResNet',\n",
              " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
              " 'mlflow.ownerEmail': 'gfesta24@gmail.com',\n",
              " 'mlflow.ownerId': '1923923806180228'}>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "tBv43qjlRIAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#Questo commento serve per provare il funzionamento dei commit con colab\n",
        "\n",
        "batch_size = 1024 "
      ],
      "metadata": {
        "id": "fE7pCxDmOYph"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile('fer2013.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall() #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "iT26qYfvO8sG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "class_dir=os.listdir(TRAIN_PATH+'/')\n",
        "folder_names = class_dir\n",
        "label_dict = {folder_names[i]:i for i in range(len(folder_names))}\n",
        "num_classes=len(label_dict)\n",
        "train_image_filenames = []\n",
        "train_labels = []\n",
        "\n",
        "# iterate through each folder and collect filenames and labels\n",
        "for folder_name in folder_names:\n",
        "    folder_path = os.path.join(TRAIN_PATH, folder_name)\n",
        "    for filename in os.listdir(folder_path):\n",
        "        train_image_filenames.append(os.path.join(TRAIN_PATH+\"/\"+folder_name, filename))\n",
        "        train_labels.append(label_dict[folder_name])\n",
        "\n",
        "# create pandas dataframe\n",
        "train_df = pd.DataFrame({'filename': train_image_filenames, 'emotion': train_labels})\n",
        "\n",
        "print(len(train_df))\n",
        "\n",
        "\n",
        "test_image_filenames = []\n",
        "test_labels = []\n",
        "class_dir=os.listdir(TEST_PATH+'/')\n",
        "for folder_name in folder_names:\n",
        "    folder_path = os.path.join(TEST_PATH, folder_name)\n",
        "    for filename in os.listdir(folder_path):\n",
        "        test_image_filenames.append(os.path.join(TEST_PATH+\"/\"+folder_name, filename))\n",
        "        test_labels.append(label_dict[folder_name])\n",
        "\n",
        "test_df = pd.DataFrame({'filename': test_image_filenames, 'emotion': test_labels})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp6VXk73PUy8",
        "outputId": "41131828-3e06-4915-c144-64b638ecc4fc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['img_as_matrix'] = train_df['filename'].apply(lambda path: cv2.imread(path))\n",
        "test_df['img_as_matrix'] = test_df['filename'].apply(lambda path: cv2.imread(path))\n"
      ],
      "metadata": {
        "id": "AGSZTlxmPbut"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.data = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.data.iloc[index]['img_as_matrix'] \n",
        "        label = self.data.iloc[index]['emotion'] \n",
        "\n",
        "        # Esegui le trasformazioni se definite\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "geovWMyTPhBA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.drop(columns=[\"filename\"], inplace=True)\n",
        "test_df.drop(columns=[\"filename\"], inplace=True)\n",
        "train_df.at[0,\"img_as_matrix\"]\n",
        "full_df = pd.concat([train_df, test_df])\n",
        "\n",
        "full_dataset = CustomDataset(full_df, transform=transforms.ToTensor())\n",
        "full_daset_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "#train_dataset = CustomDataset(train_df, transform=transforms.ToTensor())\n",
        "#test_dataset = CustomDataset(test_df, transform=transforms.ToTensor())\n",
        " \n",
        "\n",
        "#train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "#test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(full_df['img_as_matrix'], full_df['emotion'], test_size=0.33, random_state=42, stratify=full_df['emotion'])\n",
        "\n",
        "print(type(X_train))\n",
        "def mean_std_calc(loader):\n",
        "  cnt = 0\n",
        "  fst_moment = torch.empty(3)\n",
        "  snd_moment = torch.empty(3)\n",
        "\n",
        "  for images, _ in loader:\n",
        "      b, c, h, w = images.shape\n",
        "      nb_pixels = b * h * w\n",
        "      sum_ = torch.sum(images, dim=[0, 2, 3])\n",
        "      sum_of_square = torch.sum(images ** 2,\n",
        "                                dim=[0, 2, 3])\n",
        "      fst_moment = (cnt * fst_moment + sum_) / (\n",
        "                    cnt + nb_pixels)\n",
        "      snd_moment = (cnt * snd_moment + sum_of_square) / (\n",
        "                          cnt + nb_pixels)\n",
        "      cnt += nb_pixels\n",
        "\n",
        "  mean, std = fst_moment, torch.sqrt(snd_moment - fst_moment ** 2)\n",
        "  return mean, std\n",
        "\n",
        "#Normalizzazione train loader\n",
        "mean, std = mean_std_calc(full_daset_loader)\n",
        "\n",
        "transform_img_normal = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = mean, std= std),\n",
        "])\n",
        "\n",
        "X_train.name=\"img_as_matrix\"\n",
        "X_test.name=\"img_as_matrix\"\n",
        "y_test.name=\"emotion\"\n",
        "y_train.name=\"emotion\"\n",
        "new_train_df=pd.concat([X_train, y_train], axis=1)\n",
        "new_test_df=pd.concat([X_test, y_test], axis=1)\n",
        "print(new_train_df)\n",
        "\n",
        "train_dataset = CustomDataset(new_train_df, transform=transform_img_normal)\n",
        "\n",
        "test_dataset = CustomDataset(new_test_df, transform=transform_img_normal)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QLPPzSbRPi-A",
        "outputId": "82671788-cced-4596-d804-cbf7bc6aab37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "                                           img_as_matrix  emotion\n",
            "625    [[[48, 48, 48], [52, 52, 52], [54, 54, 54], [5...        0\n",
            "1345   [[[38, 38, 38], [45, 45, 45], [48, 48, 48], [5...        0\n",
            "9439   [[[144, 144, 144], [137, 137, 137], [134, 134,...        1\n",
            "6114   [[[108, 108, 108], [24, 24, 24], [0, 0, 0], [1...        6\n",
            "12430  [[[3, 3, 3], [1, 1, 1], [2, 2, 2], [4, 4, 4], ...        2\n",
            "...                                                  ...      ...\n",
            "23339  [[[253, 253, 253], [248, 248, 248], [252, 252,...        5\n",
            "21635  [[[182, 182, 182], [172, 172, 172], [154, 154,...        5\n",
            "14447  [[[63, 63, 63], [64, 64, 64], [58, 58, 58], [5...        2\n",
            "14240  [[[181, 181, 181], [175, 175, 175], [161, 161,...        2\n",
            "17100  [[[175, 175, 175], [148, 148, 148], [101, 101,...        3\n",
            "\n",
            "[24044 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(preds, labels):\n",
        "  probabilities = torch.nn.functional.softmax(preds, dim=1)\n",
        "  _, predicted = torch.max(probabilities, dim=1)\n",
        "  n_correct = (predicted==labels).sum().float()\n",
        "\n",
        "  acc =n_correct / labels.shape[0]\n",
        "  acc= torch.round(acc*100)\n",
        "  return acc, n_correct;"
      ],
      "metadata": {
        "id": "4rPc52-TPyEs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet 50 Pytorch Code"
      ],
      "metadata": {
        "id": "c7t0zHoDHt2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class block(nn.Module):\n",
        "    def __init__(\n",
        "        self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.expansion = 4\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels,\n",
        "            intermediate_channels,\n",
        "            kernel_size=1,\n",
        "            stride=1,\n",
        "            padding=0,\n",
        "            bias=False,\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            intermediate_channels,\n",
        "            intermediate_channels,\n",
        "            kernel_size=3,\n",
        "            stride=stride,\n",
        "            padding=1,\n",
        "            bias=False,\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            intermediate_channels,\n",
        "            intermediate_channels * self.expansion,\n",
        "            kernel_size=1,\n",
        "            stride=1,\n",
        "            padding=0,\n",
        "            bias=False,\n",
        "        )\n",
        "        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_downsample = identity_downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        if self.identity_downsample is not None:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, image_channels, num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Essentially the entire ResNet architecture are in these 4 lines below\n",
        "        self.layer1 = self._make_layer(\n",
        "            block, layers[0], intermediate_channels=64, stride=1\n",
        "        )\n",
        "        self.layer2 = self._make_layer(\n",
        "            block, layers[1], intermediate_channels=128, stride=2\n",
        "        )\n",
        "        self.layer3 = self._make_layer(\n",
        "            block, layers[2], intermediate_channels=256, stride=2\n",
        "        )\n",
        "        self.layer4 = self._make_layer(\n",
        "            block, layers[3], intermediate_channels=512, stride=2\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc1 = nn.Linear(512 * 4, 512)\n",
        "        self.bn2 = nn.BatchNorm1d(512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.bn3 = nn.BatchNorm1d(256)        \n",
        "        self.fc3 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
        "        identity_downsample = None\n",
        "        layers = []\n",
        "\n",
        "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
        "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
        "        # to the layer that's ahead\n",
        "        if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
        "            identity_downsample = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    self.in_channels,\n",
        "                    intermediate_channels * 4,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(intermediate_channels * 4),\n",
        "            )\n",
        "\n",
        "        layers.append(\n",
        "            block(self.in_channels, intermediate_channels, identity_downsample, stride)\n",
        "        )\n",
        "\n",
        "        # The expansion size is always 4 for ResNet 50,101,152\n",
        "        self.in_channels = intermediate_channels * 4\n",
        "\n",
        "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
        "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
        "        # and also same amount of channels.\n",
        "        for i in range(num_residual_blocks - 1):\n",
        "            layers.append(block(self.in_channels, intermediate_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def ResNet50(img_channel=3, num_classes=7):\n",
        "    return ResNet(block, [3, 4, 6, 3], img_channel, num_classes)\n"
      ],
      "metadata": {
        "id": "Lig4-9-OH8S2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.end_run()"
      ],
      "metadata": {
        "id": "rgvXWGRCDEXZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "param_grid = {'batch_size': [64, 128, 256, 512],'lr': [0.01, 0.001, 0.0001], \"momentum\":[0.7, 0.8, 0.9], \"decay\":[0.001, 0.01, 0.1]}\n",
        "expanded_grid = ParameterGrid(param_grid)\n",
        "\n",
        "\n",
        "for i in range(len(expanded_grid)):\n",
        "  best_loss=100\n",
        "  best_model_train_acc=0\n",
        "  best_model_test_acc=0\n",
        "  best_model_test_loss=0\n",
        "  best_model_train_loss=0\n",
        "  min_delta=0\n",
        "  patience=3\n",
        "  train_loader = DataLoader(train_dataset, batch_size=expanded_grid[i]['batch_size'], shuffle=True)\n",
        "  \n",
        "  test_loader = DataLoader(test_dataset, batch_size=expanded_grid[i]['batch_size'], shuffle=False)\n",
        "  model = ResNet50().to(device)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=expanded_grid[i]['lr'], momentum =expanded_grid[i]['momentum'])\n",
        "\n",
        "\n",
        "  mlflow.start_run()\n",
        "\n",
        "\n",
        "  n_total_steps = len(train_loader)\n",
        "  num_epochs = 100\n",
        "  acc_list_train=[]\n",
        "  acc_list_test=[]\n",
        "  model.train()\n",
        "\n",
        "\n",
        "  mlflow.set_tag(\"model_name\", \"ResNet50\")\n",
        "  mlflow.log_param(\"lr\", expanded_grid[i]['lr'])\n",
        "  mlflow.log_param(\"momentum\", expanded_grid[i]['momentum'])\n",
        "  mlflow.log_param(\"batch_size\", expanded_grid[i]['batch_size'])\n",
        "  mlflow.log_param(\"decay\", expanded_grid[i]['decay'])\n",
        "  best_loss = 100\n",
        "  counter=0\n",
        "  stop=False\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      print(counter)\n",
        "      if stop:\n",
        "        print(stop)\n",
        "        break\n",
        "      running_loss = 0.0\n",
        "      running_acc = 0.0\n",
        "      seen = 0\n",
        "      for i, (images, labels) in enumerate(train_loader):\n",
        "        \n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        _, acc = accuracy(outputs, labels)\n",
        "        seen +=labels.shape[0]\n",
        "\n",
        "        optimizer.zero_grad()      \n",
        "        loss.backward()            \n",
        "        optimizer.step()  \n",
        "        running_loss += loss.item()    \n",
        "        running_acc += acc\n",
        "\n",
        "      print (f'Epoch [{epoch}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Acc: {running_acc/seen:.4f}')\n",
        "      acc_list_train.append(running_acc/len(train_loader))\n",
        "      mlflow.log_metric(\"train_loss\", running_loss / len(train_loader), step=epoch)\n",
        "      mlflow.log_metric(\"train_acc\", running_acc/seen, step=epoch)\n",
        "      \n",
        "\n",
        "      tot_corrette = 0\n",
        "      tot_eseguite = 0\n",
        "      running_test_loss = 0\n",
        "      val_loss = 0\n",
        "      \n",
        "      with torch.no_grad():\n",
        "\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "          \n",
        "            outputs = model(images)\n",
        "            test_loss = criterion(outputs, labels)\n",
        "            _, n_corrette=accuracy(outputs, labels)\n",
        "            \n",
        "            running_test_loss += test_loss.item() \n",
        "            tot_corrette+=n_corrette.item()\n",
        "            tot_eseguite+=labels.shape[0]\n",
        "\n",
        "        test_acc=100* (tot_corrette/tot_eseguite)\n",
        "        val_loss = running_test_loss / len(test_loader)\n",
        "        acc_list_test.append(test_acc)\n",
        "        print(\"Test acc: \", test_acc)\n",
        "        print(\"Test loss: \", val_loss)\n",
        "        \n",
        "        mlflow.log_metric(\"test_acc\", test_acc, step=epoch)\n",
        "        mlflow.log_metric(\"test_loss\", val_loss, step=epoch)\n",
        "        \n",
        "        \n",
        "      if val_loss < best_loss - min_delta:\n",
        "        print(\"MIGLIORATO\")\n",
        "        best_loss = val_loss\n",
        "        best_model_train_acc=running_acc/seen\n",
        "        best_model_test_acc=test_acc\n",
        "        best_model_test_loss=val_loss\n",
        "        best_model_train_loss=running_loss / len(train_loader)\n",
        "        counter = 0\n",
        "        # Salva i pesi del modello se la validation loss è migliorata\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "      else:\n",
        "        counter += 1\n",
        "      # Verifica se raggiunto il criterio di early stopping\n",
        "        if counter >= patience:\n",
        "            print(f'Early stopping at epoch {epoch+1}')\n",
        "            stop=True\n",
        "      print(\"BEST TEST LOSS: \", best_loss)\n",
        "\n",
        "  mlflow.set_tag(\"Epochs_stopped\", epoch+1)\n",
        "  mlflow.log_artifact(\"best_model.pt\")\n",
        "  mlflow.log_metric(\"best_test_acc\", best_model_test_acc)\n",
        "  mlflow.log_metric(\"best_test_loss\", best_model_test_loss)\n",
        "  mlflow.log_metric(\"best_train_acc\", best_model_train_acc)\n",
        "  mlflow.log_metric(\"best_train_loss\", best_model_train_loss)\n",
        "  mlflow.end_run()\n",
        "\n",
        "  print('Finished Training')\n",
        "\n",
        "  PATH = './cnn.pth'\n",
        "  torch.save(model.state_dict(), PATH)\n",
        "  torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "MqTk-ssnQAMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Creazione dell'asse x con gli indici delle liste\n",
        "epochs = range(1, len(acc_list_train) + 1)\n",
        "\n",
        "# Tracciamento delle due variabili come linee di colori diversi\n",
        "plt.plot(epochs, acc_list_train, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, acc_list_test, 'r', label='Test Accuracy')\n",
        "\n",
        "# Titoli degli assi\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "# Aggiunta di una legenda\n",
        "plt.legend()\n",
        "\n",
        "# Visualizzazione del grafico\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3JTADuzcEzcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    tot_corrette = 0\n",
        "    tot_eseguite = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "       \n",
        "        outputs = model(images)\n",
        "        _, n_corrette=accuracy(outputs, labels)\n",
        "        tot_corrette+=n_corrette\n",
        "        tot_eseguite+=labels.shape[0]"
      ],
      "metadata": {
        "id": "oJoj04GlT1vO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}