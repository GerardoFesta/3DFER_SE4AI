{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GerardoFesta/3DFER_SE4AI/blob/main/models/3DModels/DistanceCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erhIpaFQRqVi"
      },
      "outputs": [],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtG7qIns_Fcl",
        "outputId": "4b9325d9-4fc4-45fc-8355-15f9f1441dea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/content/drive/Shareddrives/Datasets SEFAI/fer2013.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall() #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "xiKX_yakRskq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import numpy as np\n",
        "from numpy import linspace\n",
        "from mpl_toolkits import mplot3d\n",
        "import glob, os\n",
        "import json\n",
        "import pandas as pd\n",
        "import math"
      ],
      "metadata": {
        "id": "le7zNhQYSSnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "contour_list = [landmark_tuple for landmark_tuple in mp_face_mesh.FACEMESH_CONTOURS]\n",
        "tass_list = [landmark_tuple for landmark_tuple in mp_face_mesh.FACEMESH_TESSELATION]\n",
        "irises_list = [landmark_tuple for landmark_tuple in mp_face_mesh.FACEMESH_IRISES]\n",
        "all_links_list = list(set(contour_list) | set(tass_list) | set(irises_list))\n",
        "all_links_array = np.array(all_links_list)"
      ],
      "metadata": {
        "id": "HHbWXPY8Rvuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/drive/Shareddrives/Datasets SEFAI/training_set.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/Shareddrives/Datasets SEFAI/test_set.csv\")\n",
        "test_df['landmarks'] = test_df['landmarks'].apply(lambda lab: eval(lab))\n",
        "\n",
        "train_df['landmarks'] = train_df['landmarks'].apply(lambda lab: eval(lab))\n",
        "print(len(train_df))\n",
        "print(len(test_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twUdiWeqlZQU",
        "outputId": "7d033792-b557-4ac5-ca73-808f1cfb80c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26705\n",
            "6678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = np.empty(shape= (len(train_df),2626))\n",
        "for i in range(len(train_df)):\n",
        "  landmarks = train_df.iloc[i][\"landmarks\"]\n",
        "  for j, couple in enumerate(all_links_array):\n",
        "    x2 = landmarks[couple[1]][0]\n",
        "    x1 = landmarks[couple[0]][0]\n",
        "    y2 = landmarks[couple[1]][1]\n",
        "    y1 = landmarks[couple[0]][1]\n",
        "    z2 = landmarks[couple[1]][2]\n",
        "    z1 = landmarks[couple[0]][2]\n",
        "    distance =  math.sqrt((x2 - x1)**2 + (y2 - y1)**2 + (z2 - z1)**2)\n",
        "    train_dataset[i][j] = distance\n"
      ],
      "metadata": {
        "id": "K3BgmhowljJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = np.empty(shape= (len(test_df),2626))\n",
        "for i in range(len(test_df)):\n",
        "  landmarks = test_df.iloc[i][\"landmarks\"]\n",
        "  for j, couple in enumerate(all_links_array):\n",
        "    x2 = landmarks[couple[1]][0]\n",
        "    x1 = landmarks[couple[0]][0]\n",
        "    y2 = landmarks[couple[1]][1]\n",
        "    y1 = landmarks[couple[0]][1]\n",
        "    z2 = landmarks[couple[1]][2]\n",
        "    z1 = landmarks[couple[0]][2]\n",
        "    distance =  math.sqrt((x2 - x1)**2 + (y2 - y1)**2 + (z2 - z1)**2)\n",
        "    test_dataset[i][j] = distance"
      ],
      "metadata": {
        "id": "T4YYL-WuqJDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "label_dict = {\"angry\":0, \"sad\": 1, \"neutral\": 2, \"surprise\": 3, \"disgust\": 4, \"fear\": 5, \"happy\": 6}\n",
        "test_df['label'] = test_df['label'].apply(lambda lab: label_dict[lab])\n",
        "\n",
        "train_df['label'] = train_df['label'].apply(lambda lab: label_dict[lab])\n",
        "\n",
        "y_test = test_df['label'].to_numpy()\n",
        "y_train = train_df['label'].to_numpy()"
      ],
      "metadata": {
        "id": "qGSEkMepq3lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savez('distance_test_dataset.npz', data=test_dataset, labels=y_test)\n",
        "np.savez('distance_train_dataset.npz', data=train_dataset, labels=y_train)"
      ],
      "metadata": {
        "id": "twkViygKqDET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checkpoint to reload data\n"
      ],
      "metadata": {
        "id": "qY1zZ7B531aP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "Nn2fIoHU4YuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mlflow\n",
        "!databricks configure --host https://community.cloud.databricks.com/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sab9OMmM4WVF",
        "outputId": "4c996039-5862-448b-de64-4de67e413d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Username: gfesta24@gmail.com\n",
            "Password: \n",
            "Repeat for confirmation: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X_array, Y_array, transform=None):\n",
        "        self.X = X_array\n",
        "        self.Y = Y_array\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.X[index]\n",
        "        label = self.Y[index]\n",
        "\n",
        "        # Esegui le trasformazioni se definite\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "-KYzISlyrHOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "train_df = np.load('/content/drive/Shareddrives/Datasets SEFAI/distance_train_dataset.npz')\n",
        "test_df = np.load('/content/drive/Shareddrives/Datasets SEFAI/distance_test_dataset.npz')\n",
        "\n",
        "X_train= train_df['data']\n",
        "X_test = test_df['data']\n",
        "y_train = train_df['labels']\n",
        "y_test = test_df['labels']\n",
        "\n",
        "train_dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
        "\n",
        "test_dataset = TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test))\n"
      ],
      "metadata": {
        "id": "YgO5TGEPrZFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def accuracy(preds, labels):\n",
        "  probabilities = torch.nn.functional.softmax(preds, dim=1)\n",
        "  _, predicted = torch.max(probabilities, dim=1)\n",
        "  n_correct = (predicted==labels).sum().float()\n",
        "\n",
        "  acc =n_correct / labels.shape[0]\n",
        "  acc= torch.round(acc*100)\n",
        "  return acc, n_correct;"
      ],
      "metadata": {
        "id": "RHWMXiwarzVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Distance CNN"
      ],
      "metadata": {
        "id": "7itVXtBltBZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3)\n",
        "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool1d(kernel_size=2)\n",
        "        self.fc1 = nn.Linear(128 * 326, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        #print(x.shape)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        #print(x.shape)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "RVj-_39ttBDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "mlflow.set_tracking_uri(\"databricks\")\n",
        "mlflow.set_experiment(\"/Users/gfesta24@gmail.com/DistanceCNN\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t5hR6SD5BJy",
        "outputId": "78ee0818-f81b-4782-baa8-5108f69800fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/531884495140798', creation_time=1688071348937, experiment_id='531884495140798', last_update_time=1688071348937, lifecycle_stage='active', name='/Users/gfesta24@gmail.com/DistanceCNN', tags={'mlflow.experiment.sourceName': '/Users/gfesta24@gmail.com/DistanceCNN',\n",
              " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
              " 'mlflow.ownerEmail': 'gfesta24@gmail.com',\n",
              " 'mlflow.ownerId': '1923923806180228'}>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ParameterGrid\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "param_grid = {'batch_size': [64, 128, 256, 512],'lr': [0.0001, 0.001], \"decay\":[0, 0.001, 0.01]}\n",
        "expanded_grid = ParameterGrid(param_grid)\n",
        "client = mlflow.tracking.MlflowClient()\n",
        "experiment = client.get_experiment_by_name(\"/Users/gfesta24@gmail.com/DistanceCNN\")\n",
        "\n",
        "for i in range(len(expanded_grid)):\n",
        "\n",
        "  runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id], filter_string=\" and \".join([f\"params.{k} = '{v}'\" for k, v in expanded_grid[i].items()]))\n",
        "  if not len(runs) == 0:\n",
        "    print(\"RUN: \", [f\"params.{k} = '{v}'\" for k, v in expanded_grid[i].items()], \" già completata\" )\n",
        "  else:\n",
        "    train_loader = DataLoader(train_dataset, batch_size=expanded_grid[i]['batch_size'], shuffle=True)\n",
        "\n",
        "    test_loader = DataLoader(test_dataset, batch_size=expanded_grid[i]['batch_size'], shuffle=False)\n",
        "\n",
        "    model = CNN()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=expanded_grid[i]['lr'], weight_decay=expanded_grid[i]['decay'])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.to(device)\n",
        "\n",
        "    mlflow.start_run()\n",
        "\n",
        "    mlflow.set_tag(\"model_name\", \"3LayerCNN\")\n",
        "    mlflow.log_param(\"lr\", expanded_grid[i]['lr'])\n",
        "    mlflow.log_param(\"batch_size\", expanded_grid[i]['batch_size'])\n",
        "    mlflow.log_param(\"decay\", expanded_grid[i]['decay'])\n",
        "\n",
        "    patience=3\n",
        "    counter = 0\n",
        "    stop = False\n",
        "\n",
        "    # Training loop\n",
        "    best_accuracy = 0.0\n",
        "    best_loss = 1000\n",
        "\n",
        "    for epoch in range(100):\n",
        "      print(counter)\n",
        "      if stop:\n",
        "        print(stop)\n",
        "        break\n",
        "      model.train()\n",
        "      running_loss = 0.0\n",
        "      running_acc = 0\n",
        "      tot_seen = 0\n",
        "      for X_batch, y_batch in train_loader:\n",
        "        X_batch=X_batch.unsqueeze(1)\n",
        "        X_batch = X_batch.type(torch.cuda.FloatTensor)\n",
        "        y_batch = y_batch.long()\n",
        "        #manda i batch al device\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        #azzera gradiente\n",
        "        optimizer.zero_grad()\n",
        "        #predict\n",
        "        y_pred = model(X_batch)\n",
        "\n",
        "\n",
        "        #print(y_batch.shape)\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "        _,acc = accuracy(y_pred, y_batch)\n",
        "        #backpropagation della loss\n",
        "        loss.backward()\n",
        "        #ottimizzazione\n",
        "        optimizer.step()\n",
        "\n",
        "        #somma della loss e dell'accuracy per il batch\n",
        "        running_loss += loss.item()\n",
        "        running_acc += acc\n",
        "        tot_seen += len(y_batch)\n",
        "\n",
        "      train_accuracy = running_acc/tot_seen\n",
        "      train_loss = running_loss / len(train_loader)\n",
        "      print(f'Epoch {epoch}: | Loss: {train_loss:.5f} | Acc: {running_acc/tot_seen:.3f}')\n",
        "      mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
        "      mlflow.log_metric(\"train_acc\", train_accuracy, step=epoch)\n",
        "      model.eval()\n",
        "\n",
        "      tot_corrette = 0\n",
        "      tot_eseguite = 0\n",
        "      running_test_loss = 0\n",
        "      val_loss = 0\n",
        "\n",
        "      with torch.no_grad():\n",
        "\n",
        "        for images, labels in test_loader:\n",
        "            images=images.unsqueeze(1)\n",
        "            images = images.to(device)\n",
        "            labels = labels.long()\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            test_loss = criterion(outputs, labels)\n",
        "            _, n_corrette=accuracy(outputs, labels)\n",
        "\n",
        "            running_test_loss += test_loss.item()\n",
        "            tot_corrette+=n_corrette.item()\n",
        "            tot_eseguite+=labels.shape[0]\n",
        "\n",
        "        test_acc=100* (tot_corrette/tot_eseguite)\n",
        "        test_loss = running_test_loss / len(test_loader)\n",
        "        print(\"Test acc: \", test_acc)\n",
        "        print(\"Test loss: \", test_loss)\n",
        "        mlflow.log_metric(\"test_acc\", test_acc, step=epoch)\n",
        "        mlflow.log_metric(\"test_loss\", test_loss, step=epoch)\n",
        "\n",
        "        if test_loss < best_loss:\n",
        "              print(\"MIGLIORATO\")\n",
        "              torch.save(model.state_dict(), 'model_weights.pth')\n",
        "              best_loss = test_loss\n",
        "              best_model_train_acc=train_accuracy\n",
        "              best_model_test_acc=test_acc\n",
        "              best_model_test_loss=test_loss\n",
        "              best_model_train_loss=running_loss / len(train_loader)\n",
        "              counter = 0\n",
        "              # Salva i pesi del modello se la validation loss è migliorata\n",
        "              torch.save(model.state_dict(), 'best_model.pt')\n",
        "        else:\n",
        "            counter += 1\n",
        "            # Verifica se raggiunto il criterio di early stopping\n",
        "            if counter >= patience:\n",
        "                  print(f'Early stopping at epoch {epoch+1}')\n",
        "                  mlflow.set_tag(\"Epochs_stopped\", epoch+1)\n",
        "                  mlflow.log_artifact(\"best_model.pt\")\n",
        "                  mlflow.log_metric(\"best_test_acc\", best_model_test_acc)\n",
        "                  mlflow.log_metric(\"best_test_loss\", best_model_test_loss)\n",
        "                  mlflow.log_metric(\"best_train_acc\", best_model_train_acc)\n",
        "                  mlflow.log_metric(\"best_train_loss\", best_model_train_loss)\n",
        "                  mlflow.end_run()\n",
        "                  stop=True\n",
        "        print(\"BEST TEST LOSS: \", best_loss)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmdUVzRat0oF",
        "outputId": "9b1aaa61-ce95-4fdd-ec58-fa9adb99bd03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Epoch 0: | Loss: 1.80826 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8039232605979556\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8039232605979556\n",
            "0\n",
            "Epoch 1: | Loss: 1.80370 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8047355504263014\n",
            "BEST TEST LOSS:  1.8039232605979556\n",
            "1\n",
            "Epoch 2: | Loss: 1.80280 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.800826300893511\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.800826300893511\n",
            "0\n",
            "Epoch 3: | Loss: 1.79882 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.788718741280692\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.788718741280692\n",
            "0\n",
            "Epoch 4: | Loss: 1.68414 | Acc: 0.317\n",
            "Test acc:  34.17190775681342\n",
            "Test loss:  1.6107831969147637\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6107831969147637\n",
            "0\n",
            "Epoch 5: | Loss: 1.52761 | Acc: 0.404\n",
            "Test acc:  42.108415693321355\n",
            "Test loss:  1.4993064448946998\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.4993064448946998\n",
            "0\n",
            "Epoch 6: | Loss: 1.46716 | Acc: 0.427\n",
            "Test acc:  43.06678646301288\n",
            "Test loss:  1.4608079893248422\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.4608079893248422\n",
            "0\n",
            "Epoch 7: | Loss: 1.41645 | Acc: 0.444\n",
            "Test acc:  44.95357891584307\n",
            "Test loss:  1.396753171512059\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.396753171512059\n",
            "0\n",
            "Epoch 8: | Loss: 1.38834 | Acc: 0.460\n",
            "Test acc:  46.40610961365678\n",
            "Test loss:  1.3577391681217013\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3577391681217013\n",
            "0\n",
            "Epoch 9: | Loss: 1.35899 | Acc: 0.474\n",
            "Test acc:  49.74543276430069\n",
            "Test loss:  1.3273499573980059\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3273499573980059\n",
            "0\n",
            "Epoch 10: | Loss: 1.33291 | Acc: 0.490\n",
            "Test acc:  50.074872716382146\n",
            "Test loss:  1.3066876928011577\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3066876928011577\n",
            "0\n",
            "Epoch 11: | Loss: 1.31306 | Acc: 0.495\n",
            "Test acc:  50.73375262054507\n",
            "Test loss:  1.2928709302629744\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2928709302629744\n",
            "0\n",
            "Epoch 12: | Loss: 1.29274 | Acc: 0.504\n",
            "Test acc:  50.08984725965858\n",
            "Test loss:  1.283103124868302\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.283103124868302\n",
            "0\n",
            "Epoch 13: | Loss: 1.27970 | Acc: 0.511\n",
            "Test acc:  52.06648697214735\n",
            "Test loss:  1.2481306731700896\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2481306731700896\n",
            "0\n",
            "Epoch 14: | Loss: 1.26974 | Acc: 0.512\n",
            "Test acc:  50.98831985624438\n",
            "Test loss:  1.2684334686824255\n",
            "BEST TEST LOSS:  1.2481306731700896\n",
            "1\n",
            "Epoch 15: | Loss: 1.25799 | Acc: 0.518\n",
            "Test acc:  51.093141659179395\n",
            "Test loss:  1.256506021249862\n",
            "BEST TEST LOSS:  1.2481306731700896\n",
            "2\n",
            "Epoch 16: | Loss: 1.25080 | Acc: 0.520\n",
            "Test acc:  52.81521413596886\n",
            "Test loss:  1.2368129347051893\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2368129347051893\n",
            "0\n",
            "Epoch 17: | Loss: 1.24384 | Acc: 0.522\n",
            "Test acc:  52.7403414195867\n",
            "Test loss:  1.2264973379316784\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2264973379316784\n",
            "0\n",
            "Epoch 18: | Loss: 1.23775 | Acc: 0.524\n",
            "Test acc:  53.35429769392034\n",
            "Test loss:  1.2131561702206022\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2131561702206022\n",
            "0\n",
            "Epoch 19: | Loss: 1.23086 | Acc: 0.528\n",
            "Test acc:  53.60886492961965\n",
            "Test loss:  1.209300754751478\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.209300754751478\n",
            "0\n",
            "Epoch 20: | Loss: 1.22888 | Acc: 0.527\n",
            "Test acc:  52.96495956873315\n",
            "Test loss:  1.2070338606834412\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2070338606834412\n",
            "0\n",
            "Epoch 21: | Loss: 1.21710 | Acc: 0.534\n",
            "Test acc:  53.728661275831094\n",
            "Test loss:  1.2032518284661429\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2032518284661429\n",
            "0\n",
            "Epoch 22: | Loss: 1.21562 | Acc: 0.531\n",
            "Test acc:  54.02815214135968\n",
            "Test loss:  1.1934971139544532\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1934971139544532\n",
            "0\n",
            "Epoch 23: | Loss: 1.20744 | Acc: 0.536\n",
            "Test acc:  53.8334830787661\n",
            "Test loss:  1.197587344476155\n",
            "BEST TEST LOSS:  1.1934971139544532\n",
            "1\n",
            "Epoch 24: | Loss: 1.20490 | Acc: 0.537\n",
            "Test acc:  53.77358490566038\n",
            "Test loss:  1.1996454658962432\n",
            "BEST TEST LOSS:  1.1934971139544532\n",
            "2\n",
            "Epoch 25: | Loss: 1.19807 | Acc: 0.538\n",
            "Test acc:  53.848457622042524\n",
            "Test loss:  1.1893413203103202\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1893413203103202\n",
            "0\n",
            "Epoch 26: | Loss: 1.19533 | Acc: 0.540\n",
            "Test acc:  54.20784666067685\n",
            "Test loss:  1.1937134230420703\n",
            "BEST TEST LOSS:  1.1893413203103202\n",
            "1\n",
            "Epoch 27: | Loss: 1.19199 | Acc: 0.542\n",
            "Test acc:  54.357592093441156\n",
            "Test loss:  1.1828791470754714\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1828791470754714\n",
            "0\n",
            "Epoch 28: | Loss: 1.18839 | Acc: 0.542\n",
            "Test acc:  54.50733752620545\n",
            "Test loss:  1.171110666082019\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.171110666082019\n",
            "0\n",
            "Epoch 29: | Loss: 1.18472 | Acc: 0.546\n",
            "Test acc:  53.713686732554656\n",
            "Test loss:  1.1886154424576532\n",
            "BEST TEST LOSS:  1.171110666082019\n",
            "1\n",
            "Epoch 30: | Loss: 1.18274 | Acc: 0.544\n",
            "Test acc:  54.64210841569332\n",
            "Test loss:  1.1827253388507026\n",
            "BEST TEST LOSS:  1.171110666082019\n",
            "2\n",
            "Epoch 31: | Loss: 1.17888 | Acc: 0.547\n",
            "Test acc:  54.67205750224618\n",
            "Test loss:  1.1672522868428912\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1672522868428912\n",
            "0\n",
            "Epoch 32: | Loss: 1.17431 | Acc: 0.550\n",
            "Test acc:  54.80682839173405\n",
            "Test loss:  1.1722434716565269\n",
            "BEST TEST LOSS:  1.1672522868428912\n",
            "1\n",
            "Epoch 33: | Loss: 1.16958 | Acc: 0.549\n",
            "Test acc:  55.45073375262054\n",
            "Test loss:  1.1630009313424428\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1630009313424428\n",
            "0\n",
            "Epoch 34: | Loss: 1.17190 | Acc: 0.553\n",
            "Test acc:  55.01647199760408\n",
            "Test loss:  1.1645262601829711\n",
            "BEST TEST LOSS:  1.1630009313424428\n",
            "1\n",
            "Epoch 35: | Loss: 1.16462 | Acc: 0.551\n",
            "Test acc:  54.74693021862833\n",
            "Test loss:  1.1759765937214806\n",
            "BEST TEST LOSS:  1.1630009313424428\n",
            "2\n",
            "Epoch 36: | Loss: 1.16271 | Acc: 0.554\n",
            "Test acc:  54.65708295896975\n",
            "Test loss:  1.1686724012806302\n",
            "Early stopping at epoch 37\n",
            "BEST TEST LOSS:  1.1630009313424428\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.81049 | Acc: 0.259\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8057556118283953\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8057556118283953\n",
            "0\n",
            "Epoch 1: | Loss: 1.80609 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8052458308991932\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8052458308991932\n",
            "0\n",
            "Epoch 2: | Loss: 1.72297 | Acc: 0.298\n",
            "Test acc:  40.20664869721474\n",
            "Test loss:  1.5182679789406912\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5182679789406912\n",
            "0\n",
            "Epoch 3: | Loss: 1.41486 | Acc: 0.443\n",
            "Test acc:  47.61904761904761\n",
            "Test loss:  1.3210995552085696\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3210995552085696\n",
            "0\n",
            "Epoch 4: | Loss: 1.30748 | Acc: 0.492\n",
            "Test acc:  51.647199760407304\n",
            "Test loss:  1.23999173839887\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.23999173839887\n",
            "0\n",
            "Epoch 5: | Loss: 1.24758 | Acc: 0.523\n",
            "Test acc:  52.83018867924528\n",
            "Test loss:  1.2094311118125916\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2094311118125916\n",
            "0\n",
            "Epoch 6: | Loss: 1.21518 | Acc: 0.535\n",
            "Test acc:  54.01317759808326\n",
            "Test loss:  1.1883595940612612\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1883595940612612\n",
            "0\n",
            "Epoch 7: | Loss: 1.19781 | Acc: 0.540\n",
            "Test acc:  53.06978137166817\n",
            "Test loss:  1.2151721874872843\n",
            "BEST TEST LOSS:  1.1883595940612612\n",
            "1\n",
            "Epoch 8: | Loss: 1.18261 | Acc: 0.547\n",
            "Test acc:  55.78017370470201\n",
            "Test loss:  1.158370433251063\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.158370433251063\n",
            "0\n",
            "Epoch 9: | Loss: 1.17152 | Acc: 0.550\n",
            "Test acc:  55.43575920934411\n",
            "Test loss:  1.1628880012603033\n",
            "BEST TEST LOSS:  1.158370433251063\n",
            "1\n",
            "Epoch 10: | Loss: 1.15980 | Acc: 0.556\n",
            "Test acc:  53.47409404013178\n",
            "Test loss:  1.1973098263854072\n",
            "BEST TEST LOSS:  1.158370433251063\n",
            "2\n",
            "Epoch 11: | Loss: 1.15083 | Acc: 0.560\n",
            "Test acc:  55.94489368074274\n",
            "Test loss:  1.1535828755015418\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1535828755015418\n",
            "0\n",
            "Epoch 12: | Loss: 1.13834 | Acc: 0.564\n",
            "Test acc:  54.77687930518119\n",
            "Test loss:  1.1851507103159313\n",
            "BEST TEST LOSS:  1.1535828755015418\n",
            "1\n",
            "Epoch 13: | Loss: 1.13171 | Acc: 0.569\n",
            "Test acc:  54.8817011081162\n",
            "Test loss:  1.1743537643126079\n",
            "BEST TEST LOSS:  1.1535828755015418\n",
            "2\n",
            "Epoch 14: | Loss: 1.12218 | Acc: 0.569\n",
            "Test acc:  55.42078466606768\n",
            "Test loss:  1.1540622089590344\n",
            "Early stopping at epoch 15\n",
            "BEST TEST LOSS:  1.1535828755015418\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.80820 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8055255765006655\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8055255765006655\n",
            "0\n",
            "Epoch 1: | Loss: 1.80422 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8055812517801921\n",
            "BEST TEST LOSS:  1.8055255765006655\n",
            "1\n",
            "Epoch 2: | Loss: 1.80336 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8028545527231126\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8028545527231126\n",
            "0\n",
            "Epoch 3: | Loss: 1.80376 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8032728149777366\n",
            "BEST TEST LOSS:  1.8028545527231126\n",
            "1\n",
            "Epoch 4: | Loss: 1.80356 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.804000213032677\n",
            "BEST TEST LOSS:  1.8028545527231126\n",
            "2\n",
            "Epoch 5: | Loss: 1.80304 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8031936849866594\n",
            "Early stopping at epoch 6\n",
            "BEST TEST LOSS:  1.8028545527231126\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.81010 | Acc: 0.258\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.804329878943307\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.804329878943307\n",
            "0\n",
            "Epoch 1: | Loss: 1.80746 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8044758830751693\n",
            "BEST TEST LOSS:  1.804329878943307\n",
            "1\n",
            "Epoch 2: | Loss: 1.80436 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8051329067775181\n",
            "BEST TEST LOSS:  1.804329878943307\n",
            "2\n",
            "Epoch 3: | Loss: 1.80440 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8038335357393538\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8038335357393538\n",
            "0\n",
            "Epoch 4: | Loss: 1.80394 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.803432507742019\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.803432507742019\n",
            "0\n",
            "Epoch 5: | Loss: 1.80456 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8044345742180234\n",
            "BEST TEST LOSS:  1.803432507742019\n",
            "1\n",
            "Epoch 6: | Loss: 1.80409 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8040006262915476\n",
            "BEST TEST LOSS:  1.803432507742019\n",
            "2\n",
            "Epoch 7: | Loss: 1.80325 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.803571013041905\n",
            "Early stopping at epoch 8\n",
            "BEST TEST LOSS:  1.803432507742019\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.81060 | Acc: 0.259\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.806713004339309\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.806713004339309\n",
            "0\n",
            "Epoch 1: | Loss: 1.80454 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8068323510033744\n",
            "BEST TEST LOSS:  1.806713004339309\n",
            "1\n",
            "Epoch 2: | Loss: 1.80479 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8064324276787893\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8064324276787893\n",
            "0\n",
            "Epoch 3: | Loss: 1.80474 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8047123159681047\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8047123159681047\n",
            "0\n",
            "Epoch 4: | Loss: 1.80335 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8042440743673416\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8042440743673416\n",
            "0\n",
            "Epoch 5: | Loss: 1.80398 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.805832712990897\n",
            "BEST TEST LOSS:  1.8042440743673416\n",
            "1\n",
            "Epoch 6: | Loss: 1.80340 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8045114233380273\n",
            "BEST TEST LOSS:  1.8042440743673416\n",
            "2\n",
            "Epoch 7: | Loss: 1.80339 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8038526239849273\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8038526239849273\n",
            "0\n",
            "Epoch 8: | Loss: 1.80299 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8034209387642997\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8034209387642997\n",
            "0\n",
            "Epoch 9: | Loss: 1.80319 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8027535359064737\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8027535359064737\n",
            "0\n",
            "Epoch 10: | Loss: 1.80329 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8031017382939656\n",
            "BEST TEST LOSS:  1.8027535359064737\n",
            "1\n",
            "Epoch 11: | Loss: 1.80328 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.802899290266491\n",
            "BEST TEST LOSS:  1.8027535359064737\n",
            "2\n",
            "Epoch 12: | Loss: 1.80281 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8034455651328678\n",
            "Early stopping at epoch 13\n",
            "BEST TEST LOSS:  1.8027535359064737\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.81139 | Acc: 0.258\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.815547666095552\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.815547666095552\n",
            "0\n",
            "Epoch 1: | Loss: 1.80608 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8039991310664585\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8039991310664585\n",
            "0\n",
            "Epoch 2: | Loss: 1.80635 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.807376894496736\n",
            "BEST TEST LOSS:  1.8039991310664585\n",
            "1\n",
            "Epoch 3: | Loss: 1.80507 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8042965684618268\n",
            "BEST TEST LOSS:  1.8039991310664585\n",
            "2\n",
            "Epoch 4: | Loss: 1.80432 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8092114891324724\n",
            "Early stopping at epoch 5\n",
            "BEST TEST LOSS:  1.8039991310664585\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.80997 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8014274813094229\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8014274813094229\n",
            "0\n",
            "Epoch 1: | Loss: 1.80369 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7990008862513416\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7990008862513416\n",
            "0\n",
            "Epoch 2: | Loss: 1.80280 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7993078276796162\n",
            "BEST TEST LOSS:  1.7990008862513416\n",
            "1\n",
            "Epoch 3: | Loss: 1.80160 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7978875367146618\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7978875367146618\n",
            "0\n",
            "Epoch 4: | Loss: 1.80043 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7948372633952014\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7948372633952014\n",
            "0\n",
            "Epoch 5: | Loss: 1.79511 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7835502399588532\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7835502399588532\n",
            "0\n",
            "Epoch 6: | Loss: 1.75835 | Acc: 0.269\n",
            "Test acc:  36.65768194070081\n",
            "Test loss:  1.683774154141264\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.683774154141264\n",
            "0\n",
            "Epoch 7: | Loss: 1.58418 | Acc: 0.373\n",
            "Test acc:  39.78736148547469\n",
            "Test loss:  1.5443513910725433\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5443513910725433\n",
            "0\n",
            "Epoch 8: | Loss: 1.52287 | Acc: 0.404\n",
            "Test acc:  41.299790356394126\n",
            "Test loss:  1.4901255695325024\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.4901255695325024\n",
            "0\n",
            "Epoch 9: | Loss: 1.48623 | Acc: 0.420\n",
            "Test acc:  42.692422881102125\n",
            "Test loss:  1.4587930795156732\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.4587930795156732\n",
            "0\n",
            "Epoch 10: | Loss: 1.44979 | Acc: 0.436\n",
            "Test acc:  44.45941898772087\n",
            "Test loss:  1.4245837139633466\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.4245837139633466\n",
            "0\n",
            "Epoch 11: | Loss: 1.41730 | Acc: 0.448\n",
            "Test acc:  43.47109913147649\n",
            "Test loss:  1.4076545249741033\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.4076545249741033\n",
            "0\n",
            "Epoch 12: | Loss: 1.39805 | Acc: 0.460\n",
            "Test acc:  46.61575321952681\n",
            "Test loss:  1.3764937216380857\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3764937216380857\n",
            "0\n",
            "Epoch 13: | Loss: 1.37488 | Acc: 0.471\n",
            "Test acc:  48.502545672356995\n",
            "Test loss:  1.3491840115133322\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3491840115133322\n",
            "0\n",
            "Epoch 14: | Loss: 1.35008 | Acc: 0.483\n",
            "Test acc:  47.918538484576224\n",
            "Test loss:  1.3252847155310072\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3252847155310072\n",
            "0\n",
            "Epoch 15: | Loss: 1.33248 | Acc: 0.489\n",
            "Test acc:  49.5507637017071\n",
            "Test loss:  1.3036680783865586\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3036680783865586\n",
            "0\n",
            "Epoch 16: | Loss: 1.31453 | Acc: 0.497\n",
            "Test acc:  50.673854447439346\n",
            "Test loss:  1.2845717061240718\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2845717061240718\n",
            "0\n",
            "Epoch 17: | Loss: 1.29995 | Acc: 0.504\n",
            "Test acc:  50.943396226415096\n",
            "Test loss:  1.2704099979040757\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2704099979040757\n",
            "0\n",
            "Epoch 18: | Loss: 1.28816 | Acc: 0.510\n",
            "Test acc:  51.78197064989518\n",
            "Test loss:  1.2621806252677485\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2621806252677485\n",
            "0\n",
            "Epoch 19: | Loss: 1.27804 | Acc: 0.511\n",
            "Test acc:  51.61725067385444\n",
            "Test loss:  1.2874654880109824\n",
            "BEST TEST LOSS:  1.2621806252677485\n",
            "1\n",
            "Epoch 20: | Loss: 1.26793 | Acc: 0.518\n",
            "Test acc:  52.351003294399526\n",
            "Test loss:  1.241304821563217\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.241304821563217\n",
            "0\n",
            "Epoch 21: | Loss: 1.26317 | Acc: 0.519\n",
            "Test acc:  52.2911051212938\n",
            "Test loss:  1.2355619455283542\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2355619455283542\n",
            "0\n",
            "Epoch 22: | Loss: 1.25404 | Acc: 0.524\n",
            "Test acc:  52.63551961665169\n",
            "Test loss:  1.2316908993810978\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2316908993810978\n",
            "0\n",
            "Epoch 23: | Loss: 1.24858 | Acc: 0.524\n",
            "Test acc:  52.41090146750524\n",
            "Test loss:  1.2315052635264847\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2315052635264847\n",
            "0\n",
            "Epoch 24: | Loss: 1.24177 | Acc: 0.526\n",
            "Test acc:  52.71039233303384\n",
            "Test loss:  1.2156003994761773\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2156003994761773\n",
            "0\n",
            "Epoch 25: | Loss: 1.23794 | Acc: 0.525\n",
            "Test acc:  52.90506139562743\n",
            "Test loss:  1.2120572913367793\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2120572913367793\n",
            "0\n",
            "Epoch 26: | Loss: 1.22956 | Acc: 0.529\n",
            "Test acc:  53.06978137166817\n",
            "Test loss:  1.2113957129559427\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2113957129559427\n",
            "0\n",
            "Epoch 27: | Loss: 1.22822 | Acc: 0.529\n",
            "Test acc:  52.890086852351004\n",
            "Test loss:  1.2145683579849746\n",
            "BEST TEST LOSS:  1.2113957129559427\n",
            "1\n",
            "Epoch 28: | Loss: 1.22469 | Acc: 0.533\n",
            "Test acc:  52.66546870320455\n",
            "Test loss:  1.213962439096199\n",
            "BEST TEST LOSS:  1.2113957129559427\n",
            "2\n",
            "Epoch 29: | Loss: 1.21859 | Acc: 0.535\n",
            "Test acc:  53.99820305480682\n",
            "Test loss:  1.1942379238470546\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1942379238470546\n",
            "0\n",
            "Epoch 30: | Loss: 1.21590 | Acc: 0.535\n",
            "Test acc:  53.95327942497754\n",
            "Test loss:  1.1913004556916795\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1913004556916795\n",
            "0\n",
            "Epoch 31: | Loss: 1.21299 | Acc: 0.535\n",
            "Test acc:  53.713686732554656\n",
            "Test loss:  1.202539252785017\n",
            "BEST TEST LOSS:  1.1913004556916795\n",
            "1\n",
            "Epoch 32: | Loss: 1.21005 | Acc: 0.536\n",
            "Test acc:  53.35429769392034\n",
            "Test loss:  1.2140560903639164\n",
            "BEST TEST LOSS:  1.1913004556916795\n",
            "2\n",
            "Epoch 33: | Loss: 1.20906 | Acc: 0.539\n",
            "Test acc:  54.44743935309974\n",
            "Test loss:  1.1897617201760131\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1897617201760131\n",
            "0\n",
            "Epoch 34: | Loss: 1.20222 | Acc: 0.542\n",
            "Test acc:  53.713686732554656\n",
            "Test loss:  1.1976034568165832\n",
            "BEST TEST LOSS:  1.1897617201760131\n",
            "1\n",
            "Epoch 35: | Loss: 1.19863 | Acc: 0.541\n",
            "Test acc:  54.17789757412399\n",
            "Test loss:  1.1840322804900836\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1840322804900836\n",
            "0\n",
            "Epoch 36: | Loss: 1.19560 | Acc: 0.542\n",
            "Test acc:  53.264450434261754\n",
            "Test loss:  1.1972074250005327\n",
            "BEST TEST LOSS:  1.1840322804900836\n",
            "1\n",
            "Epoch 37: | Loss: 1.19500 | Acc: 0.543\n",
            "Test acc:  54.731955675351905\n",
            "Test loss:  1.172994317311161\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.172994317311161\n",
            "0\n",
            "Epoch 38: | Loss: 1.19289 | Acc: 0.541\n",
            "Test acc:  53.8334830787661\n",
            "Test loss:  1.1870778534772262\n",
            "BEST TEST LOSS:  1.172994317311161\n",
            "1\n",
            "Epoch 39: | Loss: 1.18918 | Acc: 0.544\n",
            "Test acc:  54.22282120395327\n",
            "Test loss:  1.180669033864759\n",
            "BEST TEST LOSS:  1.172994317311161\n",
            "2\n",
            "Epoch 40: | Loss: 1.18645 | Acc: 0.544\n",
            "Test acc:  55.18119197364481\n",
            "Test loss:  1.1683470713642408\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1683470713642408\n",
            "0\n",
            "Epoch 41: | Loss: 1.18255 | Acc: 0.548\n",
            "Test acc:  55.16621743036837\n",
            "Test loss:  1.1628056427217879\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1628056427217879\n",
            "0\n",
            "Epoch 42: | Loss: 1.17892 | Acc: 0.547\n",
            "Test acc:  55.10631925726265\n",
            "Test loss:  1.161416860683909\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.161416860683909\n",
            "0\n",
            "Epoch 43: | Loss: 1.17946 | Acc: 0.550\n",
            "Test acc:  55.300988319856245\n",
            "Test loss:  1.166932023358795\n",
            "BEST TEST LOSS:  1.161416860683909\n",
            "1\n",
            "Epoch 44: | Loss: 1.17530 | Acc: 0.550\n",
            "Test acc:  54.19287211740041\n",
            "Test loss:  1.1771820024499353\n",
            "BEST TEST LOSS:  1.161416860683909\n",
            "2\n",
            "Epoch 45: | Loss: 1.17552 | Acc: 0.550\n",
            "Test acc:  54.53728661275831\n",
            "Test loss:  1.176135649096291\n",
            "Early stopping at epoch 46\n",
            "BEST TEST LOSS:  1.161416860683909\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.80910 | Acc: 0.259\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8001182304238372\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8001182304238372\n",
            "0\n",
            "Epoch 1: | Loss: 1.80550 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8074287153639883\n",
            "BEST TEST LOSS:  1.8001182304238372\n",
            "1\n",
            "Epoch 2: | Loss: 1.80381 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7973107751810327\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7973107751810327\n",
            "0\n",
            "Epoch 3: | Loss: 1.72495 | Acc: 0.297\n",
            "Test acc:  41.83887391434561\n",
            "Test loss:  1.5189402733208999\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5189402733208999\n",
            "0\n",
            "Epoch 4: | Loss: 1.43763 | Acc: 0.431\n",
            "Test acc:  46.705600479185385\n",
            "Test loss:  1.3335465592033457\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3335465592033457\n",
            "0\n",
            "Epoch 5: | Loss: 1.32181 | Acc: 0.483\n",
            "Test acc:  49.79035639412998\n",
            "Test loss:  1.2607943291934032\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2607943291934032\n",
            "0\n",
            "Epoch 6: | Loss: 1.26918 | Acc: 0.512\n",
            "Test acc:  52.03653788559449\n",
            "Test loss:  1.2299633273538553\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2299633273538553\n",
            "0\n",
            "Epoch 7: | Loss: 1.23377 | Acc: 0.529\n",
            "Test acc:  53.69871218927823\n",
            "Test loss:  1.2136639469074753\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2136639469074753\n",
            "0\n",
            "Epoch 8: | Loss: 1.21796 | Acc: 0.535\n",
            "Test acc:  54.357592093441156\n",
            "Test loss:  1.18908029794693\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.18908029794693\n",
            "0\n",
            "Epoch 9: | Loss: 1.19648 | Acc: 0.543\n",
            "Test acc:  52.785265049416\n",
            "Test loss:  1.2075512960272015\n",
            "BEST TEST LOSS:  1.18908029794693\n",
            "1\n",
            "Epoch 10: | Loss: 1.18473 | Acc: 0.547\n",
            "Test acc:  53.39922132374962\n",
            "Test loss:  1.2005749114279478\n",
            "BEST TEST LOSS:  1.18908029794693\n",
            "2\n",
            "Epoch 11: | Loss: 1.16965 | Acc: 0.553\n",
            "Test acc:  55.70530098831986\n",
            "Test loss:  1.1482556709703409\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1482556709703409\n",
            "0\n",
            "Epoch 12: | Loss: 1.15767 | Acc: 0.557\n",
            "Test acc:  55.82509733453129\n",
            "Test loss:  1.1443493332502976\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1443493332502976\n",
            "0\n",
            "Epoch 13: | Loss: 1.15496 | Acc: 0.559\n",
            "Test acc:  55.64540281521414\n",
            "Test loss:  1.1599386458127003\n",
            "BEST TEST LOSS:  1.1443493332502976\n",
            "1\n",
            "Epoch 14: | Loss: 1.13942 | Acc: 0.563\n",
            "Test acc:  55.70530098831986\n",
            "Test loss:  1.1551863641109106\n",
            "BEST TEST LOSS:  1.1443493332502976\n",
            "2\n",
            "Epoch 15: | Loss: 1.13134 | Acc: 0.565\n",
            "Test acc:  55.94489368074274\n",
            "Test loss:  1.132333275844466\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.132333275844466\n",
            "0\n",
            "Epoch 16: | Loss: 1.11732 | Acc: 0.571\n",
            "Test acc:  55.55555555555556\n",
            "Test loss:  1.1514594672985796\n",
            "BEST TEST LOSS:  1.132333275844466\n",
            "1\n",
            "Epoch 17: | Loss: 1.11602 | Acc: 0.572\n",
            "Test acc:  56.82839173405211\n",
            "Test loss:  1.1257719363806382\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1257719363806382\n",
            "0\n",
            "Epoch 18: | Loss: 1.10764 | Acc: 0.576\n",
            "Test acc:  57.292602575621444\n",
            "Test loss:  1.108589913485185\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.108589913485185\n",
            "0\n",
            "Epoch 19: | Loss: 1.10342 | Acc: 0.579\n",
            "Test acc:  56.43905360886493\n",
            "Test loss:  1.134450523358471\n",
            "BEST TEST LOSS:  1.108589913485185\n",
            "1\n",
            "Epoch 20: | Loss: 1.09224 | Acc: 0.580\n",
            "Test acc:  56.99311171009285\n",
            "Test loss:  1.118132379819762\n",
            "BEST TEST LOSS:  1.108589913485185\n",
            "2\n",
            "Epoch 21: | Loss: 1.08454 | Acc: 0.585\n",
            "Test acc:  56.963162623539986\n",
            "Test loss:  1.1102902816151672\n",
            "Early stopping at epoch 22\n",
            "BEST TEST LOSS:  1.108589913485185\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.81068 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8008684639660817\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8008684639660817\n",
            "0\n",
            "Epoch 1: | Loss: 1.80463 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.801453169786705\n",
            "BEST TEST LOSS:  1.8008684639660817\n",
            "1\n",
            "Epoch 2: | Loss: 1.80378 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7987480051112625\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7987480051112625\n",
            "0\n",
            "Epoch 3: | Loss: 1.80377 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.799291655702411\n",
            "BEST TEST LOSS:  1.7987480051112625\n",
            "1\n",
            "Epoch 4: | Loss: 1.80362 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8013967500542694\n",
            "BEST TEST LOSS:  1.7987480051112625\n",
            "2\n",
            "Epoch 5: | Loss: 1.80287 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7986883959680233\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7986883959680233\n",
            "0\n",
            "Epoch 6: | Loss: 1.80354 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7984977465755534\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7984977465755534\n",
            "0\n",
            "Epoch 7: | Loss: 1.80330 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7995891166183184\n",
            "BEST TEST LOSS:  1.7984977465755534\n",
            "1\n",
            "Epoch 8: | Loss: 1.80305 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7982515411556892\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7982515411556892\n",
            "0\n",
            "Epoch 9: | Loss: 1.80311 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7995585608032514\n",
            "BEST TEST LOSS:  1.7982515411556892\n",
            "1\n",
            "Epoch 10: | Loss: 1.80321 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.79968054564494\n",
            "BEST TEST LOSS:  1.7982515411556892\n",
            "2\n",
            "Epoch 11: | Loss: 1.80301 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8005537379462764\n",
            "Early stopping at epoch 12\n",
            "BEST TEST LOSS:  1.7982515411556892\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.80932 | Acc: 0.258\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8011332322966378\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8011332322966378\n",
            "0\n",
            "Epoch 1: | Loss: 1.80500 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7999161436872662\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7999161436872662\n",
            "0\n",
            "Epoch 2: | Loss: 1.80492 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8014355268118516\n",
            "BEST TEST LOSS:  1.7999161436872662\n",
            "1\n",
            "Epoch 3: | Loss: 1.80442 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8003294400449068\n",
            "BEST TEST LOSS:  1.7999161436872662\n",
            "2\n",
            "Epoch 4: | Loss: 1.80487 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7999970440594655\n",
            "Early stopping at epoch 5\n",
            "BEST TEST LOSS:  1.7999161436872662\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.81065 | Acc: 0.259\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8003271773176373\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8003271773176373\n",
            "0\n",
            "Epoch 1: | Loss: 1.80498 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7996379024577591\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7996379024577591\n",
            "0\n",
            "Epoch 2: | Loss: 1.80435 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8005333823977776\n",
            "BEST TEST LOSS:  1.7996379024577591\n",
            "1\n",
            "Epoch 3: | Loss: 1.80397 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7997044077459372\n",
            "BEST TEST LOSS:  1.7996379024577591\n",
            "2\n",
            "Epoch 4: | Loss: 1.80337 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7998840269052758\n",
            "Early stopping at epoch 5\n",
            "BEST TEST LOSS:  1.7996379024577591\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.81018 | Acc: 0.257\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.807798243918509\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.807798243918509\n",
            "0\n",
            "Epoch 1: | Loss: 1.80612 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8013484680427696\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8013484680427696\n",
            "0\n",
            "Epoch 2: | Loss: 1.80533 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.798511972967184\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.798511972967184\n",
            "0\n",
            "Epoch 3: | Loss: 1.80507 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8002240995191179\n",
            "BEST TEST LOSS:  1.798511972967184\n",
            "1\n",
            "Epoch 4: | Loss: 1.80452 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.8074791184011496\n",
            "BEST TEST LOSS:  1.798511972967184\n",
            "2\n",
            "Epoch 5: | Loss: 1.80477 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.799837105679062\n",
            "Early stopping at epoch 6\n",
            "BEST TEST LOSS:  1.798511972967184\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.81163 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7919192799815424\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7919192799815424\n",
            "0\n",
            "Epoch 1: | Loss: 1.80291 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.791817687175892\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.791817687175892\n",
            "0\n",
            "Epoch 2: | Loss: 1.80260 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.791036981123465\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.791036981123465\n",
            "0\n",
            "Epoch 3: | Loss: 1.80248 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7908420165379841\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7908420165379841\n",
            "0\n",
            "Epoch 4: | Loss: 1.80131 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7891046029550057\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7891046029550057\n",
            "0\n",
            "Epoch 5: | Loss: 1.80100 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7855810633412115\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7855810633412115\n",
            "0\n",
            "Epoch 6: | Loss: 1.79659 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7824817454373394\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7824817454373394\n",
            "0\n",
            "Epoch 7: | Loss: 1.78762 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7605949110454984\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7605949110454984\n",
            "0\n",
            "Epoch 8: | Loss: 1.74791 | Acc: 0.271\n",
            "Test acc:  28.481581311769993\n",
            "Test loss:  1.683400202680517\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.683400202680517\n",
            "0\n",
            "Epoch 9: | Loss: 1.63001 | Acc: 0.349\n",
            "Test acc:  31.626235399820306\n",
            "Test loss:  1.5796336189464286\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5796336189464286\n",
            "0\n",
            "Epoch 10: | Loss: 1.54464 | Acc: 0.380\n",
            "Test acc:  37.54117999401018\n",
            "Test loss:  1.507927159468333\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.507927159468333\n",
            "0\n",
            "Epoch 11: | Loss: 1.51321 | Acc: 0.407\n",
            "Test acc:  41.31476489967056\n",
            "Test loss:  1.472880902113738\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.472880902113738\n",
            "0\n",
            "Epoch 12: | Loss: 1.48344 | Acc: 0.428\n",
            "Test acc:  43.33632824198862\n",
            "Test loss:  1.4452013395450733\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.4452013395450733\n",
            "0\n",
            "Epoch 13: | Loss: 1.45608 | Acc: 0.440\n",
            "Test acc:  41.554357592093446\n",
            "Test loss:  1.421557033503497\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.421557033503497\n",
            "0\n",
            "Epoch 14: | Loss: 1.43552 | Acc: 0.443\n",
            "Test acc:  44.21982629529799\n",
            "Test loss:  1.3951288836973685\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3951288836973685\n",
            "0\n",
            "Epoch 15: | Loss: 1.42033 | Acc: 0.445\n",
            "Test acc:  45.19317160826595\n",
            "Test loss:  1.3809829001073484\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3809829001073484\n",
            "0\n",
            "Epoch 16: | Loss: 1.40912 | Acc: 0.452\n",
            "Test acc:  45.8670260557053\n",
            "Test loss:  1.3706790032210174\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3706790032210174\n",
            "0\n",
            "Epoch 17: | Loss: 1.39562 | Acc: 0.458\n",
            "Test acc:  46.705600479185385\n",
            "Test loss:  1.3611052632331848\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3611052632331848\n",
            "0\n",
            "Epoch 18: | Loss: 1.38060 | Acc: 0.463\n",
            "Test acc:  46.675651392632524\n",
            "Test loss:  1.3456242481867473\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3456242481867473\n",
            "0\n",
            "Epoch 19: | Loss: 1.37010 | Acc: 0.470\n",
            "Test acc:  47.693920335429766\n",
            "Test loss:  1.3347768629038776\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3347768629038776\n",
            "0\n",
            "Epoch 20: | Loss: 1.35744 | Acc: 0.476\n",
            "Test acc:  48.39772386942198\n",
            "Test loss:  1.318788159776617\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.318788159776617\n",
            "0\n",
            "Epoch 21: | Loss: 1.34866 | Acc: 0.480\n",
            "Test acc:  47.78376759508835\n",
            "Test loss:  1.3164844192840435\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3164844192840435\n",
            "0\n",
            "Epoch 22: | Loss: 1.33968 | Acc: 0.477\n",
            "Test acc:  49.16142557651992\n",
            "Test loss:  1.2948993179533217\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2948993179533217\n",
            "0\n",
            "Epoch 23: | Loss: 1.32872 | Acc: 0.486\n",
            "Test acc:  49.79035639412998\n",
            "Test loss:  1.3009450590168987\n",
            "BEST TEST LOSS:  1.2948993179533217\n",
            "1\n",
            "Epoch 24: | Loss: 1.32219 | Acc: 0.492\n",
            "Test acc:  49.53578915843067\n",
            "Test loss:  1.2828160171155576\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2828160171155576\n",
            "0\n",
            "Epoch 25: | Loss: 1.31246 | Acc: 0.495\n",
            "Test acc:  50.32943995208146\n",
            "Test loss:  1.2709146208233304\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2709146208233304\n",
            "0\n",
            "Epoch 26: | Loss: 1.30515 | Acc: 0.498\n",
            "Test acc:  50.344414495357896\n",
            "Test loss:  1.262312392393748\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.262312392393748\n",
            "0\n",
            "Epoch 27: | Loss: 1.29911 | Acc: 0.500\n",
            "Test acc:  49.43096735549566\n",
            "Test loss:  1.2786760904170849\n",
            "BEST TEST LOSS:  1.262312392393748\n",
            "1\n",
            "Epoch 28: | Loss: 1.29406 | Acc: 0.503\n",
            "Test acc:  50.913447139862235\n",
            "Test loss:  1.2676896982722812\n",
            "BEST TEST LOSS:  1.262312392393748\n",
            "2\n",
            "Epoch 29: | Loss: 1.28644 | Acc: 0.504\n",
            "Test acc:  50.524109014675055\n",
            "Test loss:  1.260190765062968\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.260190765062968\n",
            "0\n",
            "Epoch 30: | Loss: 1.28123 | Acc: 0.511\n",
            "Test acc:  52.081461515423776\n",
            "Test loss:  1.2405290382879752\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2405290382879752\n",
            "0\n",
            "Epoch 31: | Loss: 1.27372 | Acc: 0.512\n",
            "Test acc:  52.06648697214735\n",
            "Test loss:  1.2329332342854253\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2329332342854253\n",
            "0\n",
            "Epoch 32: | Loss: 1.27217 | Acc: 0.511\n",
            "Test acc:  52.20125786163522\n",
            "Test loss:  1.2398280368910894\n",
            "BEST TEST LOSS:  1.2329332342854253\n",
            "1\n",
            "Epoch 33: | Loss: 1.26292 | Acc: 0.517\n",
            "Test acc:  51.94669062593591\n",
            "Test loss:  1.230587950459233\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.230587950459233\n",
            "0\n",
            "Epoch 34: | Loss: 1.26005 | Acc: 0.519\n",
            "Test acc:  52.56064690026954\n",
            "Test loss:  1.2207475216300399\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2207475216300399\n",
            "0\n",
            "Epoch 35: | Loss: 1.25491 | Acc: 0.520\n",
            "Test acc:  52.57562144354597\n",
            "Test loss:  1.2175541873331424\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2175541873331424\n",
            "0\n",
            "Epoch 36: | Loss: 1.25351 | Acc: 0.522\n",
            "Test acc:  51.93171608265948\n",
            "Test loss:  1.2247572386706318\n",
            "BEST TEST LOSS:  1.2175541873331424\n",
            "1\n",
            "Epoch 37: | Loss: 1.24584 | Acc: 0.523\n",
            "Test acc:  51.96166516921233\n",
            "Test loss:  1.2153138739091378\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2153138739091378\n",
            "0\n",
            "Epoch 38: | Loss: 1.24478 | Acc: 0.523\n",
            "Test acc:  52.63551961665169\n",
            "Test loss:  1.2135111888249714\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2135111888249714\n",
            "0\n",
            "Epoch 39: | Loss: 1.23811 | Acc: 0.527\n",
            "Test acc:  53.20455226115604\n",
            "Test loss:  1.206905530558692\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.206905530558692\n",
            "0\n",
            "Epoch 40: | Loss: 1.23693 | Acc: 0.528\n",
            "Test acc:  53.54896675651393\n",
            "Test loss:  1.2045678540512368\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2045678540512368\n",
            "0\n",
            "Epoch 41: | Loss: 1.23318 | Acc: 0.527\n",
            "Test acc:  52.45582509733453\n",
            "Test loss:  1.21314658831667\n",
            "BEST TEST LOSS:  1.2045678540512368\n",
            "1\n",
            "Epoch 42: | Loss: 1.23127 | Acc: 0.527\n",
            "Test acc:  53.50404312668463\n",
            "Test loss:  1.2069800893465679\n",
            "BEST TEST LOSS:  1.2045678540512368\n",
            "2\n",
            "Epoch 43: | Loss: 1.23057 | Acc: 0.529\n",
            "Test acc:  53.15962863132675\n",
            "Test loss:  1.207037991947598\n",
            "Early stopping at epoch 44\n",
            "BEST TEST LOSS:  1.2045678540512368\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.81089 | Acc: 0.257\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7996664886121396\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7996664886121396\n",
            "0\n",
            "Epoch 1: | Loss: 1.80512 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7913935979207356\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7913935979207356\n",
            "0\n",
            "Epoch 2: | Loss: 1.80452 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7920300739782828\n",
            "BEST TEST LOSS:  1.7913935979207356\n",
            "1\n",
            "Epoch 3: | Loss: 1.80333 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7911092925954748\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7911092925954748\n",
            "0\n",
            "Epoch 4: | Loss: 1.69040 | Acc: 0.312\n",
            "Test acc:  34.98053309374064\n",
            "Test loss:  1.6064294543531206\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6064294543531206\n",
            "0\n",
            "Epoch 5: | Loss: 1.47971 | Acc: 0.422\n",
            "Test acc:  44.54926624737946\n",
            "Test loss:  1.3944303415439747\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3944303415439747\n",
            "0\n",
            "Epoch 6: | Loss: 1.36870 | Acc: 0.462\n",
            "Test acc:  48.32285115303983\n",
            "Test loss:  1.2921203705999587\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2921203705999587\n",
            "0\n",
            "Epoch 7: | Loss: 1.30422 | Acc: 0.491\n",
            "Test acc:  50.479185384845756\n",
            "Test loss:  1.2440337075127497\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2440337075127497\n",
            "0\n",
            "Epoch 8: | Loss: 1.27156 | Acc: 0.512\n",
            "Test acc:  51.57232704402516\n",
            "Test loss:  1.2220043738683064\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2220043738683064\n",
            "0\n",
            "Epoch 9: | Loss: 1.24566 | Acc: 0.523\n",
            "Test acc:  51.81191973644804\n",
            "Test loss:  1.2100962819876495\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2100962819876495\n",
            "0\n",
            "Epoch 10: | Loss: 1.23106 | Acc: 0.531\n",
            "Test acc:  52.57562144354597\n",
            "Test loss:  1.1966171452292689\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1966171452292689\n",
            "0\n",
            "Epoch 11: | Loss: 1.21467 | Acc: 0.535\n",
            "Test acc:  54.10302485774184\n",
            "Test loss:  1.1857068251680445\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1857068251680445\n",
            "0\n",
            "Epoch 12: | Loss: 1.21022 | Acc: 0.538\n",
            "Test acc:  53.57891584306679\n",
            "Test loss:  1.2066621272652238\n",
            "BEST TEST LOSS:  1.1857068251680445\n",
            "1\n",
            "Epoch 13: | Loss: 1.19638 | Acc: 0.539\n",
            "Test acc:  54.41749026654688\n",
            "Test loss:  1.167544765604867\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.167544765604867\n",
            "0\n",
            "Epoch 14: | Loss: 1.18666 | Acc: 0.544\n",
            "Test acc:  54.14794848757113\n",
            "Test loss:  1.1668873385146812\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1668873385146812\n",
            "0\n",
            "Epoch 15: | Loss: 1.18174 | Acc: 0.547\n",
            "Test acc:  55.01647199760408\n",
            "Test loss:  1.156526443031099\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.156526443031099\n",
            "0\n",
            "Epoch 16: | Loss: 1.17485 | Acc: 0.550\n",
            "Test acc:  54.80682839173405\n",
            "Test loss:  1.1558186853373493\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1558186853373493\n",
            "0\n",
            "Epoch 17: | Loss: 1.15993 | Acc: 0.557\n",
            "Test acc:  55.54058101227912\n",
            "Test loss:  1.1391363088731412\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1391363088731412\n",
            "0\n",
            "Epoch 18: | Loss: 1.16203 | Acc: 0.553\n",
            "Test acc:  54.74693021862833\n",
            "Test loss:  1.1554135945108202\n",
            "BEST TEST LOSS:  1.1391363088731412\n",
            "1\n",
            "Epoch 19: | Loss: 1.14908 | Acc: 0.559\n",
            "Test acc:  56.00479185384846\n",
            "Test loss:  1.1322304805119832\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1322304805119832\n",
            "0\n",
            "Epoch 20: | Loss: 1.14736 | Acc: 0.559\n",
            "Test acc:  56.094639113507036\n",
            "Test loss:  1.1302104459868536\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1302104459868536\n",
            "0\n",
            "Epoch 21: | Loss: 1.13985 | Acc: 0.561\n",
            "Test acc:  55.61545372866128\n",
            "Test loss:  1.131444819547512\n",
            "BEST TEST LOSS:  1.1302104459868536\n",
            "1\n",
            "Epoch 22: | Loss: 1.13552 | Acc: 0.565\n",
            "Test acc:  56.51392632524708\n",
            "Test loss:  1.1191749925966616\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1191749925966616\n",
            "0\n",
            "Epoch 23: | Loss: 1.13052 | Acc: 0.567\n",
            "Test acc:  55.959868224019175\n",
            "Test loss:  1.1268349179515131\n",
            "BEST TEST LOSS:  1.1191749925966616\n",
            "1\n",
            "Epoch 24: | Loss: 1.12853 | Acc: 0.569\n",
            "Test acc:  55.81012279125487\n",
            "Test loss:  1.1276705662409465\n",
            "BEST TEST LOSS:  1.1191749925966616\n",
            "2\n",
            "Epoch 25: | Loss: 1.11984 | Acc: 0.572\n",
            "Test acc:  56.19946091644204\n",
            "Test loss:  1.1229180218996826\n",
            "Early stopping at epoch 26\n",
            "BEST TEST LOSS:  1.1191749925966616\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.81586 | Acc: 0.259\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7941582688578852\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7941582688578852\n",
            "0\n",
            "Epoch 1: | Loss: 1.80296 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7903909374166418\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7903909374166418\n",
            "0\n",
            "Epoch 2: | Loss: 1.80289 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7916881949813277\n",
            "BEST TEST LOSS:  1.7903909374166418\n",
            "1\n",
            "Epoch 3: | Loss: 1.80366 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7929422148951777\n",
            "BEST TEST LOSS:  1.7903909374166418\n",
            "2\n",
            "Epoch 4: | Loss: 1.80304 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7892680565516155\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7892680565516155\n",
            "0\n",
            "Epoch 5: | Loss: 1.80295 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.794295695092943\n",
            "BEST TEST LOSS:  1.7892680565516155\n",
            "1\n",
            "Epoch 6: | Loss: 1.80306 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7896402058777985\n",
            "BEST TEST LOSS:  1.7892680565516155\n",
            "2\n",
            "Epoch 7: | Loss: 1.80307 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.789887750590289\n",
            "Early stopping at epoch 8\n",
            "BEST TEST LOSS:  1.7892680565516155\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.81041 | Acc: 0.258\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7939962060363204\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7939962060363204\n",
            "0\n",
            "Epoch 1: | Loss: 1.80580 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7933500077989366\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7933500077989366\n",
            "0\n",
            "Epoch 2: | Loss: 1.80421 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.790544483396742\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.790544483396742\n",
            "0\n",
            "Epoch 3: | Loss: 1.80408 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7940327238153528\n",
            "BEST TEST LOSS:  1.790544483396742\n",
            "1\n",
            "Epoch 4: | Loss: 1.80407 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7904709974924724\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7904709974924724\n",
            "0\n",
            "Epoch 5: | Loss: 1.80525 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.789028039685002\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.789028039685002\n",
            "0\n",
            "Epoch 6: | Loss: 1.80436 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7894151387391266\n",
            "BEST TEST LOSS:  1.789028039685002\n",
            "1\n",
            "Epoch 7: | Loss: 1.80387 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.794054009296276\n",
            "BEST TEST LOSS:  1.789028039685002\n",
            "2\n",
            "Epoch 8: | Loss: 1.80341 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7891913034297802\n",
            "Early stopping at epoch 9\n",
            "BEST TEST LOSS:  1.789028039685002\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.82884 | Acc: 0.258\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.794990685251024\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.794990685251024\n",
            "0\n",
            "Epoch 1: | Loss: 1.80433 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7939406545073897\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7939406545073897\n",
            "0\n",
            "Epoch 2: | Loss: 1.80544 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7917839995136968\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7917839995136968\n",
            "0\n",
            "Epoch 3: | Loss: 1.80309 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7924761992913705\n",
            "BEST TEST LOSS:  1.7917839995136968\n",
            "1\n",
            "Epoch 4: | Loss: 1.80391 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7926316614504214\n",
            "BEST TEST LOSS:  1.7917839995136968\n",
            "2\n",
            "Epoch 5: | Loss: 1.80326 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7904884947670832\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7904884947670832\n",
            "0\n",
            "Epoch 6: | Loss: 1.80305 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7922589116626315\n",
            "BEST TEST LOSS:  1.7904884947670832\n",
            "1\n",
            "Epoch 7: | Loss: 1.80390 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7912974975727223\n",
            "BEST TEST LOSS:  1.7904884947670832\n",
            "2\n",
            "Epoch 8: | Loss: 1.80358 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7895944869076763\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7895944869076763\n",
            "0\n",
            "Epoch 9: | Loss: 1.80280 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7963235201659027\n",
            "BEST TEST LOSS:  1.7895944869076763\n",
            "1\n",
            "Epoch 10: | Loss: 1.80261 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.790186255066483\n",
            "BEST TEST LOSS:  1.7895944869076763\n",
            "2\n",
            "Epoch 11: | Loss: 1.80287 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7898835782651548\n",
            "Early stopping at epoch 12\n",
            "BEST TEST LOSS:  1.7895944869076763\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.81001 | Acc: 0.255\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7958143463841192\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7958143463841192\n",
            "0\n",
            "Epoch 1: | Loss: 1.80548 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.799205395910475\n",
            "BEST TEST LOSS:  1.7958143463841192\n",
            "1\n",
            "Epoch 2: | Loss: 1.80418 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7895378139283922\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7895378139283922\n",
            "0\n",
            "Epoch 3: | Loss: 1.80469 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7908417295526575\n",
            "BEST TEST LOSS:  1.7895378139283922\n",
            "1\n",
            "Epoch 4: | Loss: 1.80381 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7930458828254983\n",
            "BEST TEST LOSS:  1.7895378139283922\n",
            "2\n",
            "Epoch 5: | Loss: 1.80438 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.792604675999394\n",
            "Early stopping at epoch 6\n",
            "BEST TEST LOSS:  1.7895378139283922\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.82730 | Acc: 0.259\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7764244845935278\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7764244845935278\n",
            "0\n",
            "Epoch 1: | Loss: 1.80278 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7775187407221114\n",
            "BEST TEST LOSS:  1.7764244845935278\n",
            "1\n",
            "Epoch 2: | Loss: 1.80402 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7781681673867362\n",
            "BEST TEST LOSS:  1.7764244845935278\n",
            "2\n",
            "Epoch 3: | Loss: 1.80268 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7717343994549342\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7717343994549342\n",
            "0\n",
            "Epoch 4: | Loss: 1.80146 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.775220240865435\n",
            "BEST TEST LOSS:  1.7717343994549342\n",
            "1\n",
            "Epoch 5: | Loss: 1.80156 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.770208580153329\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.770208580153329\n",
            "0\n",
            "Epoch 6: | Loss: 1.80172 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7739811284201485\n",
            "BEST TEST LOSS:  1.770208580153329\n",
            "1\n",
            "Epoch 7: | Loss: 1.79974 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.770013962473188\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.770013962473188\n",
            "0\n",
            "Epoch 8: | Loss: 1.79818 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7662190198898315\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7662190198898315\n",
            "0\n",
            "Epoch 9: | Loss: 1.79632 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7619327051298959\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7619327051298959\n",
            "0\n",
            "Epoch 10: | Loss: 1.79072 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7500617504119873\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7500617504119873\n",
            "0\n",
            "Epoch 11: | Loss: 1.77795 | Acc: 0.263\n",
            "Test acc:  25.83108715184187\n",
            "Test loss:  1.731047706944602\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.731047706944602\n",
            "0\n",
            "Epoch 12: | Loss: 1.74798 | Acc: 0.280\n",
            "Test acc:  27.5381850853549\n",
            "Test loss:  1.6793669291904993\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6793669291904993\n",
            "0\n",
            "Epoch 13: | Loss: 1.67804 | Acc: 0.331\n",
            "Test acc:  36.64270739742438\n",
            "Test loss:  1.5833721118313926\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5833721118313926\n",
            "0\n",
            "Epoch 14: | Loss: 1.59074 | Acc: 0.372\n",
            "Test acc:  37.496256364180894\n",
            "Test loss:  1.5352612137794495\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5352612137794495\n",
            "0\n",
            "Epoch 15: | Loss: 1.55390 | Acc: 0.378\n",
            "Test acc:  37.675950883498054\n",
            "Test loss:  1.4961296660559518\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.4961296660559518\n",
            "0\n",
            "Epoch 16: | Loss: 1.54233 | Acc: 0.382\n",
            "Test acc:  39.11350703803534\n",
            "Test loss:  1.4971270901816232\n",
            "BEST TEST LOSS:  1.4961296660559518\n",
            "1\n",
            "Epoch 17: | Loss: 1.53209 | Acc: 0.390\n",
            "Test acc:  39.77238694219826\n",
            "Test loss:  1.4879012831619807\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.4879012831619807\n",
            "0\n",
            "Epoch 18: | Loss: 1.52626 | Acc: 0.401\n",
            "Test acc:  40.326445043426176\n",
            "Test loss:  1.4816448518208094\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.4816448518208094\n",
            "0\n",
            "Epoch 19: | Loss: 1.51270 | Acc: 0.407\n",
            "Test acc:  40.2365977837676\n",
            "Test loss:  1.4513462313583918\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.4513462313583918\n",
            "0\n",
            "Epoch 20: | Loss: 1.49872 | Acc: 0.416\n",
            "Test acc:  41.95867026055705\n",
            "Test loss:  1.4382197175707137\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.4382197175707137\n",
            "0\n",
            "Epoch 21: | Loss: 1.48164 | Acc: 0.427\n",
            "Test acc:  43.486073674752916\n",
            "Test loss:  1.4193405849593026\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.4193405849593026\n",
            "0\n",
            "Epoch 22: | Loss: 1.46235 | Acc: 0.433\n",
            "Test acc:  44.085055405810124\n",
            "Test loss:  1.4144733675888606\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.4144733675888606\n",
            "0\n",
            "Epoch 23: | Loss: 1.44418 | Acc: 0.444\n",
            "Test acc:  45.447738843965254\n",
            "Test loss:  1.3817909828254156\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3817909828254156\n",
            "0\n",
            "Epoch 24: | Loss: 1.42650 | Acc: 0.446\n",
            "Test acc:  45.717280622941\n",
            "Test loss:  1.3885589284556252\n",
            "BEST TEST LOSS:  1.3817909828254156\n",
            "1\n",
            "Epoch 25: | Loss: 1.40901 | Acc: 0.451\n",
            "Test acc:  46.0167714884696\n",
            "Test loss:  1.3561605193785258\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3561605193785258\n",
            "0\n",
            "Epoch 26: | Loss: 1.40079 | Acc: 0.456\n",
            "Test acc:  45.956873315363886\n",
            "Test loss:  1.3529573849269323\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3529573849269323\n",
            "0\n",
            "Epoch 27: | Loss: 1.38983 | Acc: 0.461\n",
            "Test acc:  46.4660077867625\n",
            "Test loss:  1.3347188106604986\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3347188106604986\n",
            "0\n",
            "Epoch 28: | Loss: 1.37445 | Acc: 0.468\n",
            "Test acc:  48.02336028751123\n",
            "Test loss:  1.3139470645359583\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3139470645359583\n",
            "0\n",
            "Epoch 29: | Loss: 1.36789 | Acc: 0.471\n",
            "Test acc:  48.4576220425277\n",
            "Test loss:  1.3088456647736686\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3088456647736686\n",
            "0\n",
            "Epoch 30: | Loss: 1.35490 | Acc: 0.478\n",
            "Test acc:  49.086552860137765\n",
            "Test loss:  1.2986325238432204\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2986325238432204\n",
            "0\n",
            "Epoch 31: | Loss: 1.34379 | Acc: 0.482\n",
            "Test acc:  48.24797843665768\n",
            "Test loss:  1.2757915258407593\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2757915258407593\n",
            "0\n",
            "Epoch 32: | Loss: 1.33692 | Acc: 0.488\n",
            "Test acc:  48.697214734950585\n",
            "Test loss:  1.2774018602711814\n",
            "BEST TEST LOSS:  1.2757915258407593\n",
            "1\n",
            "Epoch 33: | Loss: 1.32712 | Acc: 0.491\n",
            "Test acc:  50.56903264450434\n",
            "Test loss:  1.2711095809936523\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2711095809936523\n",
            "0\n",
            "Epoch 34: | Loss: 1.31855 | Acc: 0.498\n",
            "Test acc:  49.83528002395927\n",
            "Test loss:  1.2533371831689561\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2533371831689561\n",
            "0\n",
            "Epoch 35: | Loss: 1.31503 | Acc: 0.497\n",
            "Test acc:  50.26954177897574\n",
            "Test loss:  1.2545828138078963\n",
            "BEST TEST LOSS:  1.2533371831689561\n",
            "1\n",
            "Epoch 36: | Loss: 1.30630 | Acc: 0.501\n",
            "Test acc:  51.33273435160227\n",
            "Test loss:  1.241632001740592\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.241632001740592\n",
            "0\n",
            "Epoch 37: | Loss: 1.30019 | Acc: 0.503\n",
            "Test acc:  49.685534591194966\n",
            "Test loss:  1.23853833760534\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.23853833760534\n",
            "0\n",
            "Epoch 38: | Loss: 1.29129 | Acc: 0.509\n",
            "Test acc:  48.86193471099132\n",
            "Test loss:  1.2444734019892556\n",
            "BEST TEST LOSS:  1.23853833760534\n",
            "1\n",
            "Epoch 39: | Loss: 1.28827 | Acc: 0.506\n",
            "Test acc:  50.77867625037437\n",
            "Test loss:  1.2267825922795705\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2267825922795705\n",
            "0\n",
            "Epoch 40: | Loss: 1.28946 | Acc: 0.508\n",
            "Test acc:  51.108116202455825\n",
            "Test loss:  1.2231431135109492\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2231431135109492\n",
            "0\n",
            "Epoch 41: | Loss: 1.27723 | Acc: 0.516\n",
            "Test acc:  52.26115603474094\n",
            "Test loss:  1.211813428572246\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.211813428572246\n",
            "0\n",
            "Epoch 42: | Loss: 1.27358 | Acc: 0.517\n",
            "Test acc:  52.21623240491166\n",
            "Test loss:  1.2148022949695587\n",
            "BEST TEST LOSS:  1.211813428572246\n",
            "1\n",
            "Epoch 43: | Loss: 1.26756 | Acc: 0.517\n",
            "Test acc:  51.66217430368374\n",
            "Test loss:  1.20786395243236\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.20786395243236\n",
            "0\n",
            "Epoch 44: | Loss: 1.27500 | Acc: 0.515\n",
            "Test acc:  52.17130877508236\n",
            "Test loss:  1.2084959234510149\n",
            "BEST TEST LOSS:  1.20786395243236\n",
            "1\n",
            "Epoch 45: | Loss: 1.26249 | Acc: 0.518\n",
            "Test acc:  52.695417789757414\n",
            "Test loss:  1.2012961208820343\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2012961208820343\n",
            "0\n",
            "Epoch 46: | Loss: 1.25902 | Acc: 0.520\n",
            "Test acc:  52.03653788559449\n",
            "Test loss:  1.2063989426408495\n",
            "BEST TEST LOSS:  1.2012961208820343\n",
            "1\n",
            "Epoch 47: | Loss: 1.26038 | Acc: 0.521\n",
            "Test acc:  52.45582509733453\n",
            "Test loss:  1.1989532198224748\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1989532198224748\n",
            "0\n",
            "Epoch 48: | Loss: 1.25455 | Acc: 0.522\n",
            "Test acc:  52.920035938903865\n",
            "Test loss:  1.190454546894346\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.190454546894346\n",
            "0\n",
            "Epoch 49: | Loss: 1.24919 | Acc: 0.523\n",
            "Test acc:  52.26115603474094\n",
            "Test loss:  1.2063526894365038\n",
            "BEST TEST LOSS:  1.190454546894346\n",
            "1\n",
            "Epoch 50: | Loss: 1.24972 | Acc: 0.523\n",
            "Test acc:  52.63551961665169\n",
            "Test loss:  1.2090246507099696\n",
            "BEST TEST LOSS:  1.190454546894346\n",
            "2\n",
            "Epoch 51: | Loss: 1.24648 | Acc: 0.526\n",
            "Test acc:  52.66546870320455\n",
            "Test loss:  1.1863796008484704\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1863796008484704\n",
            "0\n",
            "Epoch 52: | Loss: 1.25170 | Acc: 0.523\n",
            "Test acc:  52.23120694818808\n",
            "Test loss:  1.2040118532521384\n",
            "BEST TEST LOSS:  1.1863796008484704\n",
            "1\n",
            "Epoch 53: | Loss: 1.25270 | Acc: 0.520\n",
            "Test acc:  52.11141060197664\n",
            "Test loss:  1.2124006705624717\n",
            "BEST TEST LOSS:  1.1863796008484704\n",
            "2\n",
            "Epoch 54: | Loss: 1.24228 | Acc: 0.527\n",
            "Test acc:  52.7403414195867\n",
            "Test loss:  1.1789063321692603\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1789063321692603\n",
            "0\n",
            "Epoch 55: | Loss: 1.23926 | Acc: 0.527\n",
            "Test acc:  52.93501048218029\n",
            "Test loss:  1.1892954536846705\n",
            "BEST TEST LOSS:  1.1789063321692603\n",
            "1\n",
            "Epoch 56: | Loss: 1.24249 | Acc: 0.524\n",
            "Test acc:  52.54567235699311\n",
            "Test loss:  1.1910066774913244\n",
            "BEST TEST LOSS:  1.1789063321692603\n",
            "2\n",
            "Epoch 57: | Loss: 1.23395 | Acc: 0.528\n",
            "Test acc:  52.51572327044025\n",
            "Test loss:  1.1827875333172935\n",
            "Early stopping at epoch 58\n",
            "BEST TEST LOSS:  1.1789063321692603\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.81355 | Acc: 0.253\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7865369745663233\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7865369745663233\n",
            "0\n",
            "Epoch 1: | Loss: 1.80359 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7792359931128365\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7792359931128365\n",
            "0\n",
            "Epoch 2: | Loss: 1.80305 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7725095067705428\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7725095067705428\n",
            "0\n",
            "Epoch 3: | Loss: 1.79862 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7585713011877877\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7585713011877877\n",
            "0\n",
            "Epoch 4: | Loss: 1.72030 | Acc: 0.299\n",
            "Test acc:  34.4115004492363\n",
            "Test loss:  1.5313311112778527\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5313311112778527\n",
            "0\n",
            "Epoch 5: | Loss: 1.53777 | Acc: 0.389\n",
            "Test acc:  40.670859538784065\n",
            "Test loss:  1.4481488977159773\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.4481488977159773\n",
            "0\n",
            "Epoch 6: | Loss: 1.47022 | Acc: 0.425\n",
            "Test acc:  44.44444444444444\n",
            "Test loss:  1.3775934534413474\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3775934534413474\n",
            "0\n",
            "Epoch 7: | Loss: 1.40415 | Acc: 0.449\n",
            "Test acc:  45.41778975741239\n",
            "Test loss:  1.30567039336477\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.30567039336477\n",
            "0\n",
            "Epoch 8: | Loss: 1.34401 | Acc: 0.478\n",
            "Test acc:  49.44594189877209\n",
            "Test loss:  1.2510359180825097\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2510359180825097\n",
            "0\n",
            "Epoch 9: | Loss: 1.30735 | Acc: 0.497\n",
            "Test acc:  47.079964061096135\n",
            "Test loss:  1.321126788854599\n",
            "BEST TEST LOSS:  1.2510359180825097\n",
            "1\n",
            "Epoch 10: | Loss: 1.30335 | Acc: 0.496\n",
            "Test acc:  48.921832884097036\n",
            "Test loss:  1.2566528533186232\n",
            "BEST TEST LOSS:  1.2510359180825097\n",
            "2\n",
            "Epoch 11: | Loss: 1.27625 | Acc: 0.508\n",
            "Test acc:  51.66217430368374\n",
            "Test loss:  1.2005229677472795\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2005229677472795\n",
            "0\n",
            "Epoch 12: | Loss: 1.25139 | Acc: 0.522\n",
            "Test acc:  51.96166516921233\n",
            "Test loss:  1.1970996473516737\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1970996473516737\n",
            "0\n",
            "Epoch 13: | Loss: 1.23965 | Acc: 0.524\n",
            "Test acc:  52.17130877508236\n",
            "Test loss:  1.1882272022111076\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1882272022111076\n",
            "0\n",
            "Epoch 14: | Loss: 1.23001 | Acc: 0.529\n",
            "Test acc:  52.41090146750524\n",
            "Test loss:  1.19297955930233\n",
            "BEST TEST LOSS:  1.1882272022111076\n",
            "1\n",
            "Epoch 15: | Loss: 1.21679 | Acc: 0.530\n",
            "Test acc:  52.57562144354597\n",
            "Test loss:  1.1842052042484283\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1842052042484283\n",
            "0\n",
            "Epoch 16: | Loss: 1.21200 | Acc: 0.534\n",
            "Test acc:  53.96825396825397\n",
            "Test loss:  1.1565111322062356\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1565111322062356\n",
            "0\n",
            "Epoch 17: | Loss: 1.20511 | Acc: 0.539\n",
            "Test acc:  52.54567235699311\n",
            "Test loss:  1.1907474909509932\n",
            "BEST TEST LOSS:  1.1565111322062356\n",
            "1\n",
            "Epoch 18: | Loss: 1.20821 | Acc: 0.538\n",
            "Test acc:  53.39922132374962\n",
            "Test loss:  1.167753326041358\n",
            "BEST TEST LOSS:  1.1565111322062356\n",
            "2\n",
            "Epoch 19: | Loss: 1.20065 | Acc: 0.539\n",
            "Test acc:  53.21952680443246\n",
            "Test loss:  1.1638174610478538\n",
            "Early stopping at epoch 20\n",
            "BEST TEST LOSS:  1.1565111322062356\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.82993 | Acc: 0.241\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7729144181524004\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7729144181524004\n",
            "0\n",
            "Epoch 1: | Loss: 1.80377 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7777027147156852\n",
            "BEST TEST LOSS:  1.7729144181524004\n",
            "1\n",
            "Epoch 2: | Loss: 1.80240 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7751614110810416\n",
            "BEST TEST LOSS:  1.7729144181524004\n",
            "2\n",
            "Epoch 3: | Loss: 1.80259 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7737964051110404\n",
            "Early stopping at epoch 4\n",
            "BEST TEST LOSS:  1.7729144181524004\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.81351 | Acc: 0.251\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.777310814176287\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.777310814176287\n",
            "0\n",
            "Epoch 1: | Loss: 1.80421 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.779926938670022\n",
            "BEST TEST LOSS:  1.777310814176287\n",
            "1\n",
            "Epoch 2: | Loss: 1.80515 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7861465215682983\n",
            "BEST TEST LOSS:  1.777310814176287\n",
            "2\n",
            "Epoch 3: | Loss: 1.80419 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7827835849353246\n",
            "Early stopping at epoch 4\n",
            "BEST TEST LOSS:  1.777310814176287\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.82230 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.782139607838222\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.782139607838222\n",
            "0\n",
            "Epoch 1: | Loss: 1.80406 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.77402035679136\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.77402035679136\n",
            "0\n",
            "Epoch 2: | Loss: 1.80424 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7714791127613612\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7714791127613612\n",
            "0\n",
            "Epoch 3: | Loss: 1.80397 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7806127497128077\n",
            "BEST TEST LOSS:  1.7714791127613612\n",
            "1\n",
            "Epoch 4: | Loss: 1.80243 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7748490486826216\n",
            "BEST TEST LOSS:  1.7714791127613612\n",
            "2\n",
            "Epoch 5: | Loss: 1.80392 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7795399597712926\n",
            "Early stopping at epoch 6\n",
            "BEST TEST LOSS:  1.7714791127613612\n",
            "3\n",
            "True\n",
            "0\n",
            "Epoch 0: | Loss: 1.81201 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7861132536615645\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7861132536615645\n",
            "0\n",
            "Epoch 1: | Loss: 1.80452 | Acc: 0.258\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7772264310291834\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7772264310291834\n",
            "0\n",
            "Epoch 2: | Loss: 1.80580 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7745559896741594\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7745559896741594\n",
            "0\n",
            "Epoch 3: | Loss: 1.80407 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7784921101161413\n",
            "BEST TEST LOSS:  1.7745559896741594\n",
            "1\n",
            "Epoch 4: | Loss: 1.80351 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7741488133158003\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7741488133158003\n",
            "0\n",
            "Epoch 5: | Loss: 1.80408 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7728718859808785\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7728718859808785\n",
            "0\n",
            "Epoch 6: | Loss: 1.80323 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7721833501543318\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7721833501543318\n",
            "0\n",
            "Epoch 7: | Loss: 1.80462 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.777673397745405\n",
            "BEST TEST LOSS:  1.7721833501543318\n",
            "1\n",
            "Epoch 8: | Loss: 1.80294 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7741112964493888\n",
            "BEST TEST LOSS:  1.7721833501543318\n",
            "2\n",
            "Epoch 9: | Loss: 1.80368 | Acc: 0.260\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7727993982178825\n",
            "Early stopping at epoch 10\n",
            "BEST TEST LOSS:  1.7721833501543318\n",
            "3\n",
            "True\n"
          ]
        }
      ]
    }
  ]
}