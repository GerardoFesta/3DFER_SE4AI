{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-ayZGpMjJ5b",
        "outputId": "2abb588b-1028-41be-f2a9-c83a2b7d3905"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gxEYvyT9VvFn"
      },
      "outputs": [],
      "source": [
        "\n",
        "import sys\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/drive/Shareddrives/Datasets SEFAI/training_set.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/Shareddrives/Datasets SEFAI/test_set.csv\")"
      ],
      "metadata": {
        "id": "JJIDU6EQikcd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#Questo commento serve per provare il funzionamento dei commit con colab\n",
        "\n",
        "batch_size = 1024"
      ],
      "metadata": {
        "id": "2d2X4ugqp8p_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X_array, Y_array, transform=None):\n",
        "        self.X = X_array\n",
        "        self.Y = Y_array\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.X[index]\n",
        "        label = self.Y[index]\n",
        "\n",
        "        # Esegui le trasformazioni se definite\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "V3LOWu8VnFhg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_df['landmarks'] = test_df['landmarks'].apply(lambda lab: eval(lab))\n",
        "\n",
        "train_df['landmarks'] = train_df['landmarks'].apply(lambda lab: eval(lab))\n",
        "print(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoNOY_Cek50t",
        "outputId": "ed54e5d6-0967-434f-c7f3-d40842dadb56"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      nome  \\\n",
            "0        train/angry/Training_12391352.jpg   \n",
            "1        train/angry/Training_52407046.jpg   \n",
            "2        train/angry/Training_20666200.jpg   \n",
            "3        train/angry/Training_11533347.jpg   \n",
            "4        train/angry/Training_60003551.jpg   \n",
            "...                                    ...   \n",
            "26700  train/disgust/Training_63164084.jpg   \n",
            "26701  train/disgust/Training_25610374.jpg   \n",
            "26702  train/disgust/Training_67023235.jpg   \n",
            "26703  train/disgust/Training_61032772.jpg   \n",
            "26704  train/disgust/Training_96306068.jpg   \n",
            "\n",
            "                                               landmarks    label  \n",
            "0      [[0.5751925706863403, 0.5731657147407532, -0.1...    angry  \n",
            "1      [[0.43962034583091736, 0.7553703784942627, -0....    angry  \n",
            "2      [[0.6029075384140015, 0.5643556118011475, -0.0...    angry  \n",
            "3      [[0.5550940036773682, 0.7429446578025818, -0.0...    angry  \n",
            "4      [[0.5235995054244995, 0.8211154937744141, -0.0...    angry  \n",
            "...                                                  ...      ...  \n",
            "26700  [[0.5719150304794312, 0.8125964403152466, -0.0...  disgust  \n",
            "26701  [[0.462147057056427, 0.7353857755661011, -0.06...  disgust  \n",
            "26702  [[0.5251359343528748, 0.7221382856369019, -0.0...  disgust  \n",
            "26703  [[0.4942273497581482, 0.7102353572845459, -0.0...  disgust  \n",
            "26704  [[0.5139249563217163, 0.7120318412780762, -0.1...  disgust  \n",
            "\n",
            "[26705 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_df.at[0,\"landmarks\"]))\n",
        "\n",
        "label_dict = {\"angry\":0, \"sad\": 1, \"neutral\": 2, \"surprise\": 3, \"disgust\": 4, \"fear\": 5, \"happy\": 6}\n",
        "\n",
        "test_df['label'] = test_df['label'].apply(lambda lab: label_dict[lab])\n",
        "\n",
        "train_df['label'] = train_df['label'].apply(lambda lab: label_dict[lab])\n",
        "\n",
        "array_train = train_df['landmarks'].to_numpy()\n",
        "X_train = np.stack([np.array(lst) for lst in array_train])\n",
        "y_train = train_df['label'].to_numpy()\n",
        "array_test = test_df['landmarks'].to_numpy()\n",
        "X_test = np.stack([np.array(lst) for lst in array_test])\n",
        "y_test = test_df['label'].to_numpy()\n",
        "\n"
      ],
      "metadata": {
        "id": "d_CnpJjOpL0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b376923f-4d06-48c2-ec97-c0606f22be3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(X_train, y_train, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "test_dataset = CustomDataset(X_test, y_test, transform=transforms.ToTensor())\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print( X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "0v6rz_t6HLhc",
        "outputId": "98af5d55-632c-4d93-ff01-776e8f8e5606",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26705, 478, 3) (26705,) (6678, 478, 3) (6678,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(preds, labels):\n",
        "  probabilities = torch.nn.functional.softmax(preds, dim=1)\n",
        "  _, predicted = torch.max(probabilities, dim=1)\n",
        "  n_correct = (predicted==labels).sum().float()\n",
        "\n",
        "  acc =n_correct / labels.shape[0]\n",
        "  acc= torch.round(acc*100)\n",
        "  return acc, n_correct;"
      ],
      "metadata": {
        "id": "diuf1n84oLjV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiClassificator(nn.Module):\n",
        "  def __init__(self, in_size: int, hidden_size: int, num_classes: int):\n",
        "    super(MultiClassificator, self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(in_size, 1024, dtype=torch.float64)\n",
        "    self.fc2 = nn.Linear(1024, 500, dtype=torch.float64)\n",
        "    self.fc3 = nn.Linear(500, 100, dtype=torch.float64)\n",
        "    self.fc4 = nn.Linear(100, num_classes, dtype=torch.float64)\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    b = x.shape[0]\n",
        "    x = x.view(b,-1)\n",
        "\n",
        "    out = self.fc1(x)\n",
        "    out = F.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    out = F.relu(out)\n",
        "    out = self.fc3(out)\n",
        "    out = F.relu(out)\n",
        "    out = self.fc4(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "Sd3NpgPrWae6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiClassificator(478*3, 1024,  7)\n",
        "print(model)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "9NbcBvkUY_AD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a368f159-74b3-43ba-c387-583798e00373"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultiClassificator(\n",
            "  (fc1): Linear(in_features=1434, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=500, bias=True)\n",
            "  (fc3): Linear(in_features=500, out_features=100, bias=True)\n",
            "  (fc4): Linear(in_features=100, out_features=7, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patience = 3\n",
        "\n",
        "acc_list_train=[]\n",
        "acc_list_test=[]\n",
        "\n",
        "\n",
        "n_total_steps = len(train_loader)\n",
        "\n",
        "\n",
        "best_loss = 100\n",
        "counter=0\n",
        "stop=False\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        print(counter)\n",
        "        if stop:\n",
        "          print(stop)\n",
        "          break\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0\n",
        "        seen = 0\n",
        "        for images, labels in train_loader:\n",
        "\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "\n",
        "          outputs = model(images)\n",
        "\n",
        "          loss = criterion(outputs, labels)\n",
        "\n",
        "          _, acc = accuracy(outputs, labels)\n",
        "          seen +=labels.shape[0]\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "          running_acc += acc\n",
        "\n",
        "        print (f'Epoch [{epoch}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Acc: {running_acc/seen:.4f}')\n",
        "        acc_list_train.append(running_acc/len(train_loader))\n",
        "        model.eval()\n",
        "\n",
        "        tot_corrette = 0\n",
        "        tot_eseguite = 0\n",
        "        running_test_loss = 0\n",
        "        val_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "          for images, labels in test_loader:\n",
        "              images = images.to(device)\n",
        "              labels = labels.to(device)\n",
        "\n",
        "              outputs = model(images)\n",
        "              test_loss = criterion(outputs, labels)\n",
        "              _, n_corrette=accuracy(outputs, labels)\n",
        "\n",
        "              running_test_loss += test_loss.item()\n",
        "              tot_corrette+=n_corrette.item()\n",
        "              tot_eseguite+=labels.shape[0]\n",
        "\n",
        "          test_acc=100* (tot_corrette/tot_eseguite)\n",
        "          val_loss = running_test_loss / len(test_loader)\n",
        "          acc_list_test.append(test_acc)\n",
        "          print(\"Test acc: \", test_acc)\n",
        "          print(\"Test loss: \", val_loss)\n",
        "\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "          print(\"MIGLIORATO\")\n",
        "          torch.save(model.state_dict(), 'model_weights.pth')\n",
        "          best_loss = val_loss\n",
        "          best_model_train_acc=running_acc/seen\n",
        "          best_model_test_acc=test_acc\n",
        "          best_model_test_loss=val_loss\n",
        "          best_model_train_loss=running_loss / len(train_loader)\n",
        "          counter = 0\n",
        "          # Salva i pesi del modello se la validation loss è migliorata\n",
        "          torch.save(model.state_dict(), 'best_model.pt')\n",
        "        else:\n",
        "          counter += 1\n",
        "        # Verifica se raggiunto il criterio di early stopping\n",
        "          if counter >= patience:\n",
        "              print(f'Early stopping at epoch {epoch+1}')\n",
        "              stop=True\n",
        "        print(\"BEST TEST LOSS: \", best_loss)"
      ],
      "metadata": {
        "id": "hIYbJl_ddGfx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b426476c-a4ff-46c6-c431-e3de889a6c13"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Epoch [0/100], Loss: 1.8179, Acc: 0.2557\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7773912359270627\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7773912359270627\n",
            "0\n",
            "Epoch [1/100], Loss: 1.7841, Acc: 0.2611\n",
            "Test acc:  25.666367175801135\n",
            "Test loss:  1.7258684606116026\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7258684606116026\n",
            "0\n",
            "Epoch [2/100], Loss: 1.7175, Acc: 0.3054\n",
            "Test acc:  37.61605271039233\n",
            "Test loss:  1.558388263953232\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.558388263953232\n",
            "0\n",
            "Epoch [3/100], Loss: 1.6005, Acc: 0.3685\n",
            "Test acc:  40.491165019466905\n",
            "Test loss:  1.5389430849449994\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5389430849449994\n",
            "0\n",
            "Epoch [4/100], Loss: 1.5340, Acc: 0.3995\n",
            "Test acc:  42.15333932315065\n",
            "Test loss:  1.4789878845635858\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.4789878845635858\n",
            "0\n",
            "Epoch [5/100], Loss: 1.4805, Acc: 0.4231\n",
            "Test acc:  42.54267744833783\n",
            "Test loss:  1.411448215830996\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.411448215830996\n",
            "0\n",
            "Epoch [6/100], Loss: 1.4826, Acc: 0.4260\n",
            "Test acc:  41.85384845762204\n",
            "Test loss:  1.4173915199859912\n",
            "BEST TEST LOSS:  1.411448215830996\n",
            "1\n",
            "Epoch [7/100], Loss: 1.4498, Acc: 0.4417\n",
            "Test acc:  38.57442348008386\n",
            "Test loss:  1.561639520924961\n",
            "BEST TEST LOSS:  1.411448215830996\n",
            "2\n",
            "Epoch [8/100], Loss: 1.4643, Acc: 0.4304\n",
            "Test acc:  46.82539682539682\n",
            "Test loss:  1.3567639526446804\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3567639526446804\n",
            "0\n",
            "Epoch [9/100], Loss: 1.4231, Acc: 0.4547\n",
            "Test acc:  45.073375262054505\n",
            "Test loss:  1.3453720538614593\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3453720538614593\n",
            "0\n",
            "Epoch [10/100], Loss: 1.4189, Acc: 0.4585\n",
            "Test acc:  47.33453129679545\n",
            "Test loss:  1.3357980693232345\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3357980693232345\n",
            "0\n",
            "Epoch [11/100], Loss: 1.4254, Acc: 0.4539\n",
            "Test acc:  45.118298891883796\n",
            "Test loss:  1.377986622807186\n",
            "BEST TEST LOSS:  1.3357980693232345\n",
            "1\n",
            "Epoch [12/100], Loss: 1.4039, Acc: 0.4608\n",
            "Test acc:  46.21144055106319\n",
            "Test loss:  1.3310429266002541\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3310429266002541\n",
            "0\n",
            "Epoch [13/100], Loss: 1.3927, Acc: 0.4705\n",
            "Test acc:  44.78885893980233\n",
            "Test loss:  1.3606908781007834\n",
            "BEST TEST LOSS:  1.3310429266002541\n",
            "1\n",
            "Epoch [14/100], Loss: 1.3820, Acc: 0.4710\n",
            "Test acc:  47.499251272836176\n",
            "Test loss:  1.3390625526240518\n",
            "BEST TEST LOSS:  1.3310429266002541\n",
            "2\n",
            "Epoch [15/100], Loss: 1.3792, Acc: 0.4734\n",
            "Test acc:  47.079964061096135\n",
            "Test loss:  1.338209826238756\n",
            "Early stopping at epoch 16\n",
            "BEST TEST LOSS:  1.3310429266002541\n",
            "3\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "model = MultiClassificator(478*3, 1024,  7)\n",
        "model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Calcola le metriche sul test dataset\n",
        "model.eval()  # Imposta il modello in modalità di valutazione (non addestramento)\n",
        "test_predictions = []\n",
        "test_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(torch.nn.functional.softmax(outputs, dim=1), 1)\n",
        "        test_predictions.extend(predictions.cpu().numpy())\n",
        "        test_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy = accuracy_score(test_labels, test_predictions)\n",
        "precision = precision_score(test_labels, test_predictions, average=None)\n",
        "f1 = f1_score(test_labels, test_predictions, average=None)\n",
        "#auc_roc = roc_auc_score(test_labels, test_predictions, multi_class='ovr')\n",
        "classification_rep = classification_report(test_labels, test_predictions)\n",
        "\n",
        "print(\"Test Metrics:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1 Score:\", f1)\n",
        "#print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GAw98jHttc4V",
        "outputId": "700d9737-b4be-42d7-8ca7-342084b6b352",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics:\n",
            "Accuracy: 0.46211440551063193\n",
            "Precision: [0.23924731 0.36801752 0.37774817 0.38711776 0.         0.25409836\n",
            " 0.65741155]\n",
            "F1 Score: [0.14530612 0.33267327 0.42218913 0.5133736  0.         0.05832549\n",
            " 0.74385609]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.10      0.15       853\n",
            "           1       0.37      0.30      0.33      1107\n",
            "           2       0.38      0.48      0.42      1185\n",
            "           3       0.39      0.76      0.51       781\n",
            "           4       0.00      0.00      0.00        97\n",
            "           5       0.25      0.03      0.06       941\n",
            "           6       0.66      0.86      0.74      1714\n",
            "\n",
            "    accuracy                           0.46      6678\n",
            "   macro avg       0.33      0.36      0.32      6678\n",
            "weighted avg       0.41      0.46      0.41      6678\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe\n",
        "\n",
        "import zipfile\n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/content/drive/Shareddrives/Datasets SEFAI/scraped_pictures.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall() #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qr8wuefHY2Qo",
        "outputId": "fab953e9-16ca-4159-a1ee-9dac4785d600"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.8/33.8 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.3.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.22.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.7.0.72)\n",
            "Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.20.3)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.1 sounddevice-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mediapipe as mp\n",
        "import glob, os\n",
        "import cv2\n",
        "\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "label_dict = {\"angry\":0, \"sad\": 1, \"neutral\": 2, \"surprise\": 3, \"disgust\": 4, \"fear\": 5, \"happy\": 6}\n",
        "label_arr=[]\n",
        "images = []\n",
        "with mp_face_mesh.FaceMesh(\n",
        "    static_image_mode=True,\n",
        "    max_num_faces=1,\n",
        "    refine_landmarks=True,\n",
        "    min_detection_confidence=0.5) as face_mesh:\n",
        "\n",
        "    for root, dirs, files in os.walk(\"photos\"):\n",
        "      for dir in dirs:\n",
        "        if(not dir==\".ipynb_checkpoints\"):\n",
        "          label=label_dict[dir]\n",
        "          for _file in glob.glob(\"photos/\"+dir+\"/*.*\"):\n",
        "              image = cv2.imread(_file)\n",
        "          # Convert the BGR image to RGB before processing.\n",
        "              #print(_file)\n",
        "              results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "\n",
        "              annotated_image = image.copy()\n",
        "              if(results.multi_face_landmarks!=None):\n",
        "                for face_landmarks in results.multi_face_landmarks:\n",
        "                  #print('face_landmarks:', face_landmarks)\n",
        "                  mp_drawing.draw_landmarks(\n",
        "                      image=annotated_image,\n",
        "                      landmark_list=face_landmarks,\n",
        "                      connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                      landmark_drawing_spec=None,\n",
        "                      connection_drawing_spec=mp_drawing_styles\n",
        "                      .get_default_face_mesh_tesselation_style())\n",
        "                  mp_drawing.draw_landmarks(\n",
        "                      image=annotated_image,\n",
        "                      landmark_list=face_landmarks,\n",
        "                      connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
        "                      landmark_drawing_spec=None,\n",
        "                      connection_drawing_spec=mp_drawing_styles\n",
        "                      .get_default_face_mesh_contours_style())\n",
        "                  mp_drawing.draw_landmarks(\n",
        "                      image=annotated_image,\n",
        "                      landmark_list=face_landmarks,\n",
        "                      connections=mp_face_mesh.FACEMESH_IRISES,\n",
        "                      landmark_drawing_spec=None,\n",
        "                      connection_drawing_spec=mp_drawing_styles\n",
        "                      .get_default_face_mesh_iris_connections_style())\n",
        "                points_array = np.array(face_landmarks)\n",
        "\n",
        "                x_array=[]\n",
        "                y_array=[]\n",
        "                z_array=[]\n",
        "\n",
        "                landmark_matrix = []\n",
        "                for data_point in face_landmarks.landmark:\n",
        "                  landmark_matrix.append([data_point.x, data_point.y, data_point.z])\n",
        "\n",
        "                label_arr.append(label)\n",
        "                images.append(landmark_matrix)\n"
      ],
      "metadata": {
        "id": "p30CaQkpYgLM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.array(images)\n",
        "labels = np.array(label_arr)\n",
        "scraped_dataset = CustomDataset(images, labels, transform=transforms.ToTensor())\n",
        "\n",
        "scraped_loader = DataLoader(scraped_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "bUSq4lmJY4yR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiClassificator(478*3, 1024,  7)\n",
        "model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Calcola le metriche sul test dataset\n",
        "model.eval()  # Imposta il modello in modalità di valutazione (non addestramento)\n",
        "test_predictions = []\n",
        "test_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in scraped_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(torch.nn.functional.softmax(outputs, dim=1), 1)\n",
        "        test_predictions.extend(predictions.cpu().numpy())\n",
        "        test_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy = accuracy_score(test_labels, test_predictions)\n",
        "precision = precision_score(test_labels, test_predictions, average=None)\n",
        "f1 = f1_score(test_labels, test_predictions, average=None)\n",
        "#auc_roc = roc_auc_score(test_labels, test_predictions, multi_class='ovr')\n",
        "classification_rep = classification_report(test_labels, test_predictions)\n",
        "\n",
        "print(\"Test Metrics:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1 Score:\", f1)\n",
        "#print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"Classification Report:\\n\", classification_rep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUyg5HykZEQZ",
        "outputId": "fac226cb-4182-434d-b1bd-cdda85fc0da9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics:\n",
            "Accuracy: 0.3079019073569482\n",
            "Precision: [0.1625     0.21568627 0.39583333 0.24096386 0.         0.\n",
            " 0.56818182]\n",
            "F1 Score: [0.17931034 0.23655914 0.48717949 0.29850746 0.         0.\n",
            " 0.6097561 ]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      0.20      0.18        65\n",
            "           1       0.22      0.26      0.24        42\n",
            "           2       0.40      0.63      0.49        30\n",
            "           3       0.24      0.39      0.30        51\n",
            "           4       0.00      0.00      0.00        74\n",
            "           5       0.00      0.00      0.00        29\n",
            "           6       0.57      0.66      0.61        76\n",
            "\n",
            "    accuracy                           0.31       367\n",
            "   macro avg       0.23      0.31      0.26       367\n",
            "weighted avg       0.24      0.31      0.27       367\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}