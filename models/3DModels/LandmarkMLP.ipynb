{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GerardoFesta/3DFER_SE4AI/blob/main/models/3DModels/LandmarkMLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports, mlflow setup and unzip"
      ],
      "metadata": {
        "id": "-POnNILnMlji"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gF9evhd59oN",
        "outputId": "9568d802-b712-4a12-ffd8-2769b9350dba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mlflow\n",
        "!databricks configure --host https://community.cloud.databricks.com/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq_wgdU6Cy3Y",
        "outputId": "d4104cba-c5cd-410e-d195-56250848666a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Username: gfesta24@gmail.com\n",
            "Password: \n",
            "Repeat for confirmation: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "4a6IY4ju5_rL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we set the paths, so change them to load the Landmarks. You can mine the landmark with Landmark Extraction file in our 3DTransformations folder"
      ],
      "metadata": {
        "id": "igQkhryiM_Lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"/content/drive/Shareddrives/Datasets SEFAI/training_set.csv\")\n",
        "test_df = pd.read_csv(\"/content/drive/Shareddrives/Datasets SEFAI/test_set.csv\")"
      ],
      "metadata": {
        "id": "YFTcKSb46Cn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "wELOhOKpNWvT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "batch_size = 1024"
      ],
      "metadata": {
        "id": "MS9rFg--6E5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X_array, Y_array, transform=None):\n",
        "        self.X = X_array\n",
        "        self.Y = Y_array\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.X[index]\n",
        "        label = self.Y[index]\n",
        "\n",
        "        # Esegui le trasformazioni se definite\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "KTaDM-eD6KP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is needed to extract the np.array from the csv"
      ],
      "metadata": {
        "id": "hqwPxIcDNfV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['landmarks'] = test_df['landmarks'].apply(lambda lab: eval(lab))\n",
        "\n",
        "train_df['landmarks'] = train_df['landmarks'].apply(lambda lab: eval(lab))\n",
        "print(train_df)"
      ],
      "metadata": {
        "id": "jWcyIhAK6Rlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_df.at[0,\"landmarks\"]))\n",
        "\n",
        "label_dict = {\"angry\":0, \"sad\": 1, \"neutral\": 2, \"surprise\": 3, \"disgust\": 4, \"fear\": 5, \"happy\": 6}\n",
        "\n",
        "test_df['label'] = test_df['label'].apply(lambda lab: label_dict[lab])\n",
        "\n",
        "train_df['label'] = train_df['label'].apply(lambda lab: label_dict[lab])\n",
        "\n",
        "array_train = train_df['landmarks'].to_numpy()\n",
        "X_train = np.stack([np.array(lst) for lst in array_train])\n",
        "y_train = train_df['label'].to_numpy()\n",
        "array_test = test_df['landmarks'].to_numpy()\n",
        "X_test = np.stack([np.array(lst) for lst in array_test])\n",
        "y_test = test_df['label'].to_numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rf2Uoe1O6W33",
        "outputId": "dc3a2e2f-cf4b-4a83-821c-6ae26be08aeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CustomDataset(X_train, y_train, transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "test_dataset = CustomDataset(X_test, y_test, transform=transforms.ToTensor())\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print( X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v1v5ZFw6cRl",
        "outputId": "a1e82e3d-cc45-4877-bbea-9b27b3e5e628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26705, 478, 3) (26705,) (6678, 478, 3) (6678,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "eP0Z9hSTNn6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(preds, labels):\n",
        "  probabilities = torch.nn.functional.softmax(preds, dim=1)\n",
        "  _, predicted = torch.max(probabilities, dim=1)\n",
        "  n_correct = (predicted==labels).sum().float()\n",
        "\n",
        "  acc =n_correct / labels.shape[0]\n",
        "  acc= torch.round(acc*100)\n",
        "  return acc, n_correct;"
      ],
      "metadata": {
        "id": "heFf79s36c_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiClassificator(nn.Module):\n",
        "  def __init__(self, in_size: int, hidden_size: int, num_classes: int):\n",
        "    super(MultiClassificator, self).__init__()\n",
        "\n",
        "    self.fc1 = nn.Linear(in_size, 1024, dtype=torch.float64)\n",
        "    self.fc2 = nn.Linear(1024, 500, dtype=torch.float64)\n",
        "    self.fc3 = nn.Linear(500, 100, dtype=torch.float64)\n",
        "    self.fc4 = nn.Linear(100, num_classes, dtype=torch.float64)\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    b = x.shape[0]\n",
        "    x = x.view(b,-1)\n",
        "\n",
        "    out = self.fc1(x)\n",
        "    out = F.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    out = F.relu(out)\n",
        "    out = self.fc3(out)\n",
        "    out = F.relu(out)\n",
        "    out = self.fc4(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "kknRuaJ06jyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training loop"
      ],
      "metadata": {
        "id": "SAqx656EOOVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "mlflow.set_tracking_uri(\"databricks\")\n",
        "mlflow.set_experiment(\"/Users/gfesta24@gmail.com/LandmarkMLP\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHzglvLD6rL-",
        "outputId": "2555c19e-919f-4f01-8c7c-749600f854a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/3698710157086970', creation_time=1687350733677, experiment_id='3698710157086970', last_update_time=1687352897667, lifecycle_stage='active', name='/Users/gfesta24@gmail.com/LandmarkMLP', tags={'mlflow.experiment.sourceName': '/Users/gfesta24@gmail.com/LandmarkMLP',\n",
              " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
              " 'mlflow.ownerEmail': 'gfesta24@gmail.com',\n",
              " 'mlflow.ownerId': '1923923806180228'}>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'batch_size': [64, 128, 256, 512],'lr': [0.0001, 0.001], \"decay\":[0, 0.001, 0.01]}\n",
        "expanded_grid = ParameterGrid(param_grid)\n",
        "client = mlflow.tracking.MlflowClient()\n",
        "experiment = client.get_experiment_by_name(\"/Users/gfesta24@gmail.com/LandmarkMLP\")\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for i in range(len(expanded_grid)):\n",
        "\n",
        "  runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id], filter_string=\" and \".join([f\"params.{k} = '{v}'\" for k, v in expanded_grid[i].items()]))\n",
        "  if not len(runs) == 0:\n",
        "    print(\"RUN: \", [f\"params.{k} = '{v}'\" for k, v in expanded_grid[i].items()], \" già completata\" )\n",
        "  else:\n",
        "    train_loader = DataLoader(train_dataset, batch_size=expanded_grid[i]['batch_size'], shuffle=True)\n",
        "\n",
        "    test_loader = DataLoader(test_dataset, batch_size=expanded_grid[i]['batch_size'], shuffle=False)\n",
        "\n",
        "    model = MultiClassificator(478*3, 1024,  7)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=expanded_grid[i]['lr'], weight_decay=expanded_grid[i]['decay'])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model.to(device)\n",
        "\n",
        "    mlflow.start_run()\n",
        "\n",
        "    mlflow.set_tag(\"model_name\", \"LandmarkMLP\")\n",
        "    mlflow.log_param(\"lr\", expanded_grid[i]['lr'])\n",
        "    mlflow.log_param(\"batch_size\", expanded_grid[i]['batch_size'])\n",
        "    mlflow.log_param(\"decay\", expanded_grid[i]['decay'])\n",
        "\n",
        "    acc_list_train=[]\n",
        "    acc_list_test=[]\n",
        "    num_epochs = 100\n",
        "    best_loss = 1000\n",
        "    patience=3\n",
        "    counter = 0\n",
        "    stop = False\n",
        "\n",
        "    # Training loop\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            print(counter)\n",
        "            if stop:\n",
        "              print(stop)\n",
        "              break\n",
        "            running_loss = 0.0\n",
        "            running_acc = 0\n",
        "            seen = 0\n",
        "            for images, labels in train_loader:\n",
        "\n",
        "              images = images.to(device)\n",
        "              labels = labels.to(device)\n",
        "\n",
        "\n",
        "              outputs = model(images)\n",
        "\n",
        "              loss = criterion(outputs, labels)\n",
        "\n",
        "              _, acc = accuracy(outputs, labels)\n",
        "              seen +=labels.shape[0]\n",
        "\n",
        "              optimizer.zero_grad()\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "              running_loss += loss.item()\n",
        "              running_acc += acc\n",
        "\n",
        "            print (f'Epoch [{epoch}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Acc: {running_acc/seen:.4f}')\n",
        "            acc_list_train.append(running_acc/len(train_loader))\n",
        "            mlflow.log_metric(\"train_loss\", running_loss / len(train_loader), step=epoch)\n",
        "            mlflow.log_metric(\"train_acc\", running_acc/seen, step=epoch)\n",
        "            model.eval()\n",
        "\n",
        "            tot_corrette = 0\n",
        "            tot_eseguite = 0\n",
        "            running_test_loss = 0\n",
        "            val_loss = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "              for images, labels in test_loader:\n",
        "                  images = images.to(device)\n",
        "                  labels = labels.to(device)\n",
        "\n",
        "                  outputs = model(images)\n",
        "                  test_loss = criterion(outputs, labels)\n",
        "                  _, n_corrette=accuracy(outputs, labels)\n",
        "\n",
        "                  running_test_loss += test_loss.item()\n",
        "                  tot_corrette+=n_corrette.item()\n",
        "                  tot_eseguite+=labels.shape[0]\n",
        "\n",
        "              test_acc=100* (tot_corrette/tot_eseguite)\n",
        "              val_loss = running_test_loss / len(test_loader)\n",
        "              acc_list_test.append(test_acc)\n",
        "              print(\"Test acc: \", test_acc)\n",
        "              print(\"Test loss: \", val_loss)\n",
        "              mlflow.log_metric(\"test_acc\", test_acc, step=epoch)\n",
        "              mlflow.log_metric(\"test_loss\", val_loss, step=epoch)\n",
        "\n",
        "\n",
        "            if val_loss < best_loss:\n",
        "              print(\"MIGLIORATO\")\n",
        "              torch.save(model.state_dict(), 'model_weights.pth')\n",
        "              best_loss = val_loss\n",
        "              best_model_train_acc=running_acc/seen\n",
        "              best_model_test_acc=test_acc\n",
        "              best_model_test_loss=val_loss\n",
        "              best_model_train_loss=running_loss / len(train_loader)\n",
        "              counter = 0\n",
        "              # Salva i pesi del modello se la validation loss è migliorata\n",
        "              torch.save(model.state_dict(), 'best_model.pt')\n",
        "            else:\n",
        "              counter += 1\n",
        "            # Verifica se raggiunto il criterio di early stopping\n",
        "              if counter >= patience:\n",
        "                  print(f'Early stopping at epoch {epoch+1}')\n",
        "                  mlflow.set_tag(\"Epochs_stopped\", epoch+1)\n",
        "                  mlflow.log_artifact(\"best_model.pt\")\n",
        "                  mlflow.log_metric(\"best_test_acc\", best_model_test_acc)\n",
        "                  mlflow.log_metric(\"best_test_loss\", best_model_test_loss)\n",
        "                  mlflow.log_metric(\"best_train_acc\", best_model_train_acc)\n",
        "                  mlflow.log_metric(\"best_train_loss\", best_model_train_loss)\n",
        "                  mlflow.end_run()\n",
        "                  stop=True\n",
        "            print(\"BEST TEST LOSS: \", best_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxA-q3WW8iOx",
        "outputId": "00707d43-0d7b-49a4-ea81-0ba7c2e1f665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUN:  [\"params.lr = '0.0001'\", \"params.decay = '0'\", \"params.batch_size = '64'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.001'\", \"params.decay = '0'\", \"params.batch_size = '64'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.0001'\", \"params.decay = '0.001'\", \"params.batch_size = '64'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.001'\", \"params.decay = '0.001'\", \"params.batch_size = '64'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.0001'\", \"params.decay = '0.01'\", \"params.batch_size = '64'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.001'\", \"params.decay = '0.01'\", \"params.batch_size = '64'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.0001'\", \"params.decay = '0'\", \"params.batch_size = '128'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.001'\", \"params.decay = '0'\", \"params.batch_size = '128'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.0001'\", \"params.decay = '0.001'\", \"params.batch_size = '128'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.001'\", \"params.decay = '0.001'\", \"params.batch_size = '128'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.0001'\", \"params.decay = '0.01'\", \"params.batch_size = '128'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.001'\", \"params.decay = '0.01'\", \"params.batch_size = '128'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.0001'\", \"params.decay = '0'\", \"params.batch_size = '256'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.001'\", \"params.decay = '0'\", \"params.batch_size = '256'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.0001'\", \"params.decay = '0.001'\", \"params.batch_size = '256'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.001'\", \"params.decay = '0.001'\", \"params.batch_size = '256'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.0001'\", \"params.decay = '0.01'\", \"params.batch_size = '256'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.001'\", \"params.decay = '0.01'\", \"params.batch_size = '256'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.0001'\", \"params.decay = '0'\", \"params.batch_size = '512'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.001'\", \"params.decay = '0'\", \"params.batch_size = '512'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.0001'\", \"params.decay = '0.001'\", \"params.batch_size = '512'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.001'\", \"params.decay = '0.001'\", \"params.batch_size = '512'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.0001'\", \"params.decay = '0.01'\", \"params.batch_size = '512'\"]  già completata\n",
            "RUN:  [\"params.lr = '0.001'\", \"params.decay = '0.01'\", \"params.batch_size = '512'\"]  già completata\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "V3Og98azPKdb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "model = MultiClassificator(478*3, 1024,  7)\n",
        "model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Calcola le metriche sul test dataset\n",
        "model.eval()  # Imposta il modello in modalità di valutazione (non addestramento)\n",
        "test_predictions = []\n",
        "test_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(torch.nn.functional.softmax(outputs, dim=1), 1)\n",
        "        test_predictions.extend(predictions.cpu().numpy())\n",
        "        test_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "accuracy = accuracy_score(test_labels, test_predictions)\n",
        "precision = precision_score(test_labels, test_predictions, average=None)\n",
        "f1 = f1_score(test_labels, test_predictions, average=None)\n",
        "#auc_roc = roc_auc_score(test_labels, test_predictions, multi_class='ovr')\n",
        "classification_rep = classification_report(test_labels, test_predictions)\n",
        "\n",
        "print(\"Test Metrics:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1 Score:\", f1)\n",
        "#print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"Classification Report:\\n\", classification_rep)"
      ],
      "metadata": {
        "id": "y9sw3LlV-RK6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}