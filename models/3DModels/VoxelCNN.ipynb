{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GerardoFesta/3DFER_SE4AI/blob/main/models/3DModels/VoxelCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wQY5oZcsfnf",
        "outputId": "0b0817dc-92ab-48e5-96a2-a5d0181e4b7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mlflow\n",
        "!databricks configure --host https://community.cloud.databricks.com/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOo2RTYRDoub",
        "outputId": "f36b7dc6-0556-4c6b-d1b4-38f30a69d2b3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Username: gfesta24@gmail.com\n",
            "Password: \n",
            "Repeat for confirmation: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.model_selection import ParameterGrid"
      ],
      "metadata": {
        "id": "kDQsV4Ersjxk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = np.load('/content/drive/Shareddrives/Datasets SEFAI/voxel_train_dataset.npz')\n",
        "test_df = np.load('/content/drive/Shareddrives/Datasets SEFAI/voxel_test_dataset.npz')"
      ],
      "metadata": {
        "id": "j2PFiOads0Tp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X_array, Y_array, transform=None):\n",
        "        self.X = X_array\n",
        "        self.Y = Y_array\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.X[index]\n",
        "        label = self.Y[index]\n",
        "\n",
        "        # Esegui le trasformazioni se definite\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "q3E2RQbjvyQ7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "mlflow.set_tracking_uri(\"databricks\")\n",
        "mlflow.set_experiment(\"/Users/gfesta24@gmail.com/Voxels3DCNN\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT8dV3hDEqYI",
        "outputId": "2d239e84-d903-40af-ba22-2fe80a3870af"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/2211619870750348', creation_time=1686564463983, experiment_id='2211619870750348', last_update_time=1687873600055, lifecycle_stage='active', name='/Users/gfesta24@gmail.com/Voxels3DCNN', tags={'mlflow.experiment.sourceName': '/Users/gfesta24@gmail.com/Voxels3DCNN',\n",
              " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
              " 'mlflow.ownerEmail': 'gfesta24@gmail.com',\n",
              " 'mlflow.ownerId': '1923923806180228'}>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train= train_df['data']\n",
        "X_test = test_df['data']\n",
        "y_train = train_df['labels']\n",
        "y_test = test_df['labels']\n"
      ],
      "metadata": {
        "id": "s5V8JQ_7tKOz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "train_dataset = CustomDataset(X_train, y_train, transform=transforms.ToTensor())\n",
        "\n",
        "test_dataset = CustomDataset(X_test, y_test, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size=64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "Ch6KCfL9uFa2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(preds, labels):\n",
        "  probabilities = torch.nn.functional.softmax(preds, dim=1)\n",
        "  _, predicted = torch.max(probabilities, dim=1)\n",
        "  n_correct = (predicted==labels).sum().float()\n",
        "\n",
        "  acc =n_correct / labels.shape[0]\n",
        "  acc= torch.round(acc*100)\n",
        "  return acc, n_correct;"
      ],
      "metadata": {
        "id": "xoBlSQbPxg14"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(MyModel, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv3d(1, 32, kernel_size=(5, 5, 3), stride=1, padding=(2, 2, 1))\n",
        "        self.batchnorm1 = nn.BatchNorm3d(32)\n",
        "        self.conv2 = nn.Conv3d(32, 64, kernel_size=(3, 3, 3), stride=1, padding=0)\n",
        "        self.batchnorm2 = nn.BatchNorm3d(64)\n",
        "        self.conv3 = nn.Conv3d(64, 128, kernel_size=(3, 3, 3), stride=1, padding=0)\n",
        "        self.batchnorm3 = nn.BatchNorm3d(128)\n",
        "\n",
        "        self.maxpool = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(3456, 512)\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc3 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.batchnorm3(x)\n",
        "        #x = self.maxpool(x)\n",
        "\n",
        "        # Calcolo dinamico della dimensione dell'input per fc1\n",
        "        batch_size = x.size(0)\n",
        "        #print(x.shape)\n",
        "        x = self.flatten(x)  # Flatten\n",
        "        #print(x.shape)\n",
        "        x = self.fc1(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "6Nhg1FOrKPWa"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.end_run()"
      ],
      "metadata": {
        "id": "2UsVipO7Oxw3"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'batch_size': [64, 128, 256, 512],'lr': [0.01, 0.001], \"momentum\":[0.7, 0.8, 0.9], \"decay\":[0.001, 0.01, 0.1]}\n",
        "expanded_grid = ParameterGrid(param_grid)\n",
        "client = mlflow.tracking.MlflowClient()\n",
        "experiment = client.get_experiment_by_name(\"/Users/gfesta24@gmail.com/Voxels3DCNN\")\n",
        "\n",
        "\n",
        "for i in range(len(expanded_grid)):\n",
        "\n",
        "  runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id], filter_string=\" and \".join([f\"params.{k} = '{v}'\" for k, v in expanded_grid[i].items()] + [\"tags.model_name = 'VoxelCNN3layer'\"]))\n",
        "\n",
        "  train_loader = DataLoader(train_dataset, batch_size=expanded_grid[i]['batch_size'], shuffle=True)\n",
        "\n",
        "  test_loader = DataLoader(test_dataset, batch_size=expanded_grid[i]['batch_size'], shuffle=False)\n",
        "\n",
        "  if len(runs) == 0:\n",
        "\n",
        "\n",
        "    best_loss=100\n",
        "    best_model_train_acc=0\n",
        "    best_model_test_acc=0\n",
        "    best_model_test_loss=0\n",
        "    best_model_train_loss=0\n",
        "    min_delta=0\n",
        "    patience=3\n",
        "    model = MyModel(num_classes = 7)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=expanded_grid[i]['lr'], momentum =expanded_grid[i]['momentum'])\n",
        "\n",
        "\n",
        "    mlflow.start_run()\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    num_epochs = 100\n",
        "    acc_list_train=[]\n",
        "    acc_list_test=[]\n",
        "    model.train()\n",
        "\n",
        "    mlflow.set_tag(\"model_name\", \"VoxelCNN3layer\")\n",
        "    mlflow.log_param(\"lr\", expanded_grid[i]['lr'])\n",
        "    mlflow.log_param(\"momentum\", expanded_grid[i]['momentum'])\n",
        "    mlflow.log_param(\"batch_size\", expanded_grid[i]['batch_size'])\n",
        "    mlflow.log_param(\"decay\", expanded_grid[i]['decay'])\n",
        "    best_loss = 100\n",
        "    counter=0\n",
        "    stop=False\n",
        "    for epoch in range(num_epochs):\n",
        "        if stop:\n",
        "          break\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        tot_seen = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch = torch.reshape(X_batch, (X_batch.shape[0], 1, 24, 24, 24))\n",
        "            X_batch = X_batch.type(torch.cuda.FloatTensor)\n",
        "            #manda i batch al device\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            #azzera gradiente\n",
        "            optimizer.zero_grad()\n",
        "            #predict\n",
        "            y_pred = model(X_batch)\n",
        "\n",
        "\n",
        "            #print(y_batch.shape)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            _,acc = accuracy(y_pred, y_batch)\n",
        "            #backpropagation della loss\n",
        "            loss.backward()\n",
        "            #ottimizzazione\n",
        "            optimizer.step()\n",
        "\n",
        "            #somma della loss e dell'accuracy per il batch\n",
        "            running_loss += loss.item()\n",
        "            running_acc += acc\n",
        "            tot_seen += len(y_batch)\n",
        "\n",
        "\n",
        "        print(f'Epoch {epoch}: | Loss: {running_loss/len(train_loader):.5f} | Acc: {running_acc/tot_seen:.3f}')\n",
        "        acc_list_train.append(running_acc/len(train_loader))\n",
        "        mlflow.log_metric(\"train_loss\", running_loss / len(train_loader), step=epoch)\n",
        "        mlflow.log_metric(\"train_acc\", running_acc/tot_seen, step=epoch)\n",
        "        tot_corrette = 0\n",
        "        tot_eseguite = 0\n",
        "        running_test_loss = 0\n",
        "        val_loss = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "          for images, labels in test_loader:\n",
        "              images = torch.reshape(images, (images.shape[0], 1, 24, 24, 24))\n",
        "              images = images.type(torch.cuda.FloatTensor)\n",
        "              images = images.to(device)\n",
        "              labels = labels.to(device)\n",
        "\n",
        "              outputs = model(images)\n",
        "              test_loss = criterion(outputs, labels)\n",
        "              _, n_corrette=accuracy(outputs, labels)\n",
        "\n",
        "              running_test_loss += test_loss.item()\n",
        "              tot_corrette+=n_corrette.item()\n",
        "              tot_eseguite+=labels.shape[0]\n",
        "\n",
        "          test_acc=100* (tot_corrette/tot_eseguite)\n",
        "          val_loss = running_test_loss / len(test_loader)\n",
        "          acc_list_test.append(test_acc)\n",
        "          print(\"Test acc: \", test_acc)\n",
        "          print(\"Test loss: \", val_loss)\n",
        "\n",
        "          mlflow.log_metric(\"test_acc\", test_acc, step=epoch)\n",
        "          mlflow.log_metric(\"test_loss\", val_loss, step=epoch)\n",
        "\n",
        "\n",
        "        if val_loss < best_loss - min_delta:\n",
        "          print(\"MIGLIORATO\")\n",
        "          best_loss = val_loss\n",
        "          best_model_train_acc=running_acc/tot_seen\n",
        "          best_model_test_acc=test_acc\n",
        "          best_model_test_loss=val_loss\n",
        "          best_model_train_loss=running_loss / len(train_loader)\n",
        "          counter = 0\n",
        "          # Salva i pesi del modello se la validation loss è migliorata\n",
        "          torch.save(model.state_dict(), 'best_model.pt')\n",
        "        else:\n",
        "          counter += 1\n",
        "        # Verifica se raggiunto il criterio di early stopping\n",
        "          if counter >= patience:\n",
        "              print(f'Early stopping at epoch {epoch+1}')\n",
        "              stop=True\n",
        "        print(\"BEST TEST LOSS: \", best_loss)\n",
        "\n",
        "    mlflow.set_tag(\"Epochs_stopped\", epoch+1)\n",
        "    mlflow.log_artifact(\"best_model.pt\")\n",
        "    mlflow.log_metric(\"best_test_acc\", best_model_test_acc)\n",
        "    mlflow.log_metric(\"best_test_loss\", best_model_test_loss)\n",
        "    mlflow.log_metric(\"best_train_acc\", best_model_train_acc)\n",
        "    mlflow.log_metric(\"best_train_loss\", best_model_train_loss)\n",
        "    mlflow.end_run()\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "    PATH = './cnn.pth'\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "    torch.cuda.empty_cache()\n",
        "  else:\n",
        "    print(\"RUN: \", [f\"params.{k} = '{v}'\" for k, v in expanded_grid[i].items()], \" già completata\" )\n",
        "\n"
      ],
      "metadata": {
        "id": "W6WnDqFXyrce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_artifact_with_lowest_metric(experiment_id, metric_name, artifact_name):\n",
        "    runs = mlflow.search_runs(experiment_ids=[experiment_id]).sort_values(f\"{metric_name}\")\n",
        "    lowest_metric_run = runs.iloc[0]\n",
        "\n",
        "    run_id = lowest_metric_run.run_id\n",
        "    artifact_uri = mlflow.get_artifact_uri(run_id)\n",
        "\n",
        "    artifact_path = f\"{artifact_uri}/{artifact_name}\"\n",
        "    return run_id, artifact_path\n",
        "\n",
        "# Specifica l'ID del tuo esperimento e i nomi delle metrica e dell'artefatto\n",
        "experiment_id = '2211619870750348'\n",
        "metric_name = 'metrics.best_test_loss'\n",
        "artifact_name = 'model_weights'\n",
        "\n",
        "run_id, artifact_path = get_artifact_with_lowest_metric(experiment_id, metric_name, artifact_name)\n",
        "\n",
        "print(\"Artifatto 'model_weights' nella run con la metrica 'best_test_acc' più bassa:\")\n",
        "print(artifact_path)"
      ],
      "metadata": {
        "id": "XsP06PVbfts_",
        "outputId": "ebea766c-5220-4fba-a9d7-8c3365b643f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artifatto 'model_weights' nella run con la metrica 'best_test_acc' più bassa:\n",
            "dbfs:/databricks/mlflow-tracking/2211619870750348/137d06ac01004b218edc78dfbe21decb/artifacts/c13f76e3c6cc477eaa3a1136718faf02/model_weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.artifacts.download_artifacts(run_id=run_id, dst_path=\"/content/artefatto\")"
      ],
      "metadata": {
        "id": "I6TRrpTEhLlA",
        "outputId": "64122b03-75fc-4687-b594-d720ad01ade7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/artefatto/'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model= MyModel(num_classes = 7)\n",
        "model.load_state_dict(torch.load(\"/content/artefatto/best_model.pt\"))\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Calcola le metriche sul test dataset\n",
        "model.eval()  # Imposta il modello in modalità di valutazione (non addestramento)\n",
        "test_predictions = []\n",
        "test_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = torch.reshape(images, (images.shape[0], 1, 24, 24, 24))\n",
        "        images = images.type(torch.cuda.FloatTensor)\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(torch.nn.functional.softmax(outputs, dim=1), 1)\n",
        "        test_predictions.extend(predictions.cpu().numpy())\n",
        "        test_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(test_labels, test_predictions)\n",
        "precision = precision_score(test_labels, test_predictions, average=None)\n",
        "recall = recall_score(test_labels, test_predictions, average=None)\n",
        "f1 = f1_score(test_labels, test_predictions, average=None)\n",
        "#auc_roc = roc_auc_score(test_labels, test_predictions, multi_class='ovr')\n",
        "classification_rep = classification_report(test_labels, test_predictions)\n",
        "\n",
        "print(\"Test Metrics:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1 Score:\", f1)\n",
        "#print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "\n",
        "# Lista delle etichette delle classi\n",
        "#class_labels = ['Class 0', 'Class 1', 'Class 2', 'Class 3', 'Class 4', 'Class 5', 'Class 6']\n",
        "class_labels=[9,9,9,9,9,9,9]\n",
        "for label in [\"angry\", \"disgust\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]:\n",
        "  class_labels[train_dataset.class_to_idx[label]]=label\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Crea il grafico a barre per la precisione\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(class_labels, precision)\n",
        "plt.title('Precision per Class')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Precision')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Crea il grafico a barre per il recall\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(class_labels, recall)\n",
        "plt.title('Recall per Class')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Recall')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Crea il grafico a barre per l'F1-score\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(class_labels, f1)\n",
        "plt.title('F1 Score per Class')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LR0_tU7nhkYj",
        "outputId": "51ef34d9-3768-44d5-8a0a-2fd35a2e96e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics:\n",
            "Accuracy: 0.48233003893381254\n",
            "Precision: [0.40037951 0.41835358 0.32838354 0.62106703 0.         0.36\n",
            " 0.64626463]\n",
            "F1 Score: [0.3057971  0.33549784 0.43704122 0.6005291  0.         0.06916427\n",
            " 0.7296748 ]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.25      0.31       853\n",
            "           1       0.42      0.28      0.34      1107\n",
            "           2       0.33      0.65      0.44      1185\n",
            "           3       0.62      0.58      0.60       781\n",
            "           4       0.00      0.00      0.00        97\n",
            "           5       0.36      0.04      0.07       941\n",
            "           6       0.65      0.84      0.73      1714\n",
            "\n",
            "    accuracy                           0.48      6678\n",
            "   macro avg       0.40      0.38      0.35      6678\n",
            "weighted avg       0.47      0.48      0.44      6678\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-441bd357959e>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"angry\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"disgust\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fear\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"happy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"neutral\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sad\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"surprise\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0mclass_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'CustomDataset' object has no attribute 'class_to_idx'"
          ]
        }
      ]
    }
  ]
}