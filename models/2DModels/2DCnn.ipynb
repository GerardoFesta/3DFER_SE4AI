{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GerardoFesta/3DFER_SE4AI/blob/main/models/2DModels/2DCnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "import zipfile\n"
      ],
      "metadata": {
        "id": "nt82bh71Me7J",
        "outputId": "b9a4a162-257d-476a-e996-022d2ec8d2f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile('drive/Shareddrives/Datasets SEFAI/fer2013.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall() #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "x3PzBCC76kDU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JyI6JfnaBNPU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#Questo commento serve per provare il funzionamento dei commit con colab"
      ],
      "metadata": {
        "id": "C5AbMnPdCehg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Loading**"
      ],
      "metadata": {
        "id": "pZUeJ0PHEVAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"train\" # Directory containing the training data\n",
        "test_dir = \"test\"  # Directory containing the validation data\n",
        "\n",
        "# Define the transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "train_dataset = ImageFolder(train_dir, transform=train_transform)\n",
        "test_dataset = ImageFolder(test_dir, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "bl34X6SU93Vf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rete convolutiva**"
      ],
      "metadata": {
        "id": "AfkDTdOnczbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(preds, labels):\n",
        "  probabilities = torch.nn.functional.softmax(preds, dim=1)\n",
        "  _, predicted = torch.max(probabilities, 1)\n",
        "  n_correct = (predicted==labels).sum().float()\n",
        "\n",
        "  acc =n_correct / labels.shape[0]\n",
        "  acc= torch.round(acc*100)\n",
        "  return acc, n_correct;\n"
      ],
      "metadata": {
        "id": "iJyvVmbzJXVO"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.dropout2 = nn.Dropout(0.25)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(256)\n",
        "        self.relu5 = nn.ReLU()\n",
        "\n",
        "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(256)\n",
        "        self.relu6 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "        self.dropout3 = nn.Dropout(0.25)\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 256)\n",
        "\n",
        "        self.bn7 = nn.BatchNorm1d(256)\n",
        "        self.relu7 = nn.ReLU()\n",
        "\n",
        "        self.dropout4 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc2 = nn.Linear(256, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.dropout1(x)\n",
        "        #print(\"dropout1 \", x.shape)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        #print(\"conv4 \", x.shape)\n",
        "        x = self.bn4(x)\n",
        "        x = self.relu4(x)\n",
        "\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.bn5(x)\n",
        "        x = self.relu5(x)\n",
        "\n",
        "        x = self.conv6(x)\n",
        "        #print(\"conv6 \", x.shape)\n",
        "        x = self.bn6(x)\n",
        "        x = self.relu6(x)\n",
        "\n",
        "        x = self.pool3(x)\n",
        "        x = self.dropout3(x)\n",
        "        #print(\"dropout3 \", x.shape)\n",
        "        x = x.view(-1, 256 * 6 * 6)\n",
        "        #print(x.shape)\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn7(x)\n",
        "        x = self.relu7(x)\n",
        "        x = self.dropout4(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "E5qDv9UfZonY"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "U8n88ptP5Esw",
        "outputId": "ac1caba9-be53-4295-8a8e-f12bf49debe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu1): ReLU()\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu2): ReLU()\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout1): Dropout(p=0.25, inplace=False)\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu3): ReLU()\n",
              "  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu4): ReLU()\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout2): Dropout(p=0.25, inplace=False)\n",
              "  (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu5): ReLU()\n",
              "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu6): ReLU()\n",
              "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout3): Dropout(p=0.25, inplace=False)\n",
              "  (fc1): Linear(in_features=9216, out_features=256, bias=True)\n",
              "  (bn7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu7): ReLU()\n",
              "  (dropout4): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=256, out_features=7, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_list_train=[]\n",
        "acc_list_test=[]\n",
        "num_epochs = 100\n",
        "best_loss = 1000\n",
        "patience=3\n",
        "counter = 0\n",
        "stop = False\n",
        "\n",
        "# Training loop\n",
        "best_accuracy = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(counter)\n",
        "    if stop:\n",
        "      print(stop)\n",
        "      break\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    total_correct = 0\n",
        "    seen = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, acc = accuracy(outputs, labels)\n",
        "        total_correct += acc\n",
        "        seen +=labels.shape[0]\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    train_accuracy = total_correct / seen\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    print (f'Epoch [{epoch}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Acc: {total_correct/seen:.4f}')\n",
        "\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    seen = 0\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            _, acc = accuracy(outputs, labels)\n",
        "            total_correct += acc\n",
        "            seen +=labels.shape[0]\n",
        "\n",
        "    test_accuracy = total_correct / seen\n",
        "    test_loss = running_loss / len(test_loader)\n",
        "    print(\"Test acc: \", test_accuracy)\n",
        "    print(\"Test loss: \", test_loss)\n",
        "\n",
        "    if test_loss < best_loss:\n",
        "          print(\"MIGLIORATO\")\n",
        "          torch.save(model.state_dict(), 'model_weights.pth')\n",
        "          best_loss = test_loss\n",
        "          best_model_train_acc=train_accuracy\n",
        "          best_model_test_acc=test_accuracy\n",
        "          best_model_test_loss=test_loss\n",
        "          best_model_train_loss=running_loss / len(train_loader)\n",
        "          counter = 0\n",
        "          # Salva i pesi del modello se la validation loss è migliorata\n",
        "          torch.save(model.state_dict(), 'best_model.pt')\n",
        "    else:\n",
        "        counter += 1\n",
        "        # Verifica se raggiunto il criterio di early stopping\n",
        "        if counter >= patience:\n",
        "              print(f'Early stopping at epoch {epoch+1}')\n",
        "              stop=True\n",
        "    print(\"BEST TEST LOSS: \", best_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{50}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "0keHfEhx7LK5",
        "outputId": "e6c1949e-f224-4ebd-f80f-d2c7557c8773",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Epoch [0/100], Loss: 1.7808, Acc: 0.2945\n",
            "Test acc:  tensor(0.3643, device='cuda:0')\n",
            "Test loss:  1.6546207740243557\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6546207740243557\n",
            "Epoch 1/50, Train Loss: 1.7808, Train Accuracy: 0.2945, Test Accuracy: 0.3643, Test Loss: 1.6546\n",
            "0\n",
            "Epoch [1/100], Loss: 1.5593, Acc: 0.3930\n",
            "Test acc:  tensor(0.4505, device='cuda:0')\n",
            "Test loss:  1.4296913605875674\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.4296913605875674\n",
            "Epoch 2/50, Train Loss: 1.5593, Train Accuracy: 0.3930, Test Accuracy: 0.4505, Test Loss: 1.4297\n",
            "0\n",
            "Epoch [2/100], Loss: 1.4465, Acc: 0.4446\n",
            "Test acc:  tensor(0.4694, device='cuda:0')\n",
            "Test loss:  1.3858080664567187\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.3858080664567187\n",
            "Epoch 3/50, Train Loss: 1.4465, Train Accuracy: 0.4446, Test Accuracy: 0.4694, Test Loss: 1.3858\n",
            "0\n",
            "Epoch [3/100], Loss: 1.3787, Acc: 0.4695\n",
            "Test acc:  tensor(0.5128, device='cuda:0')\n",
            "Test loss:  1.2827130107753044\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2827130107753044\n",
            "Epoch 4/50, Train Loss: 1.3787, Train Accuracy: 0.4695, Test Accuracy: 0.5128, Test Loss: 1.2827\n",
            "0\n",
            "Epoch [4/100], Loss: 1.3255, Acc: 0.4940\n",
            "Test acc:  tensor(0.5265, device='cuda:0')\n",
            "Test loss:  1.234517964641605\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.234517964641605\n",
            "Epoch 5/50, Train Loss: 1.3255, Train Accuracy: 0.4940, Test Accuracy: 0.5265, Test Loss: 1.2345\n",
            "0\n",
            "Epoch [5/100], Loss: 1.2849, Acc: 0.5125\n",
            "Test acc:  tensor(0.5326, device='cuda:0')\n",
            "Test loss:  1.219948376438259\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.219948376438259\n",
            "Epoch 6/50, Train Loss: 1.2849, Train Accuracy: 0.5125, Test Accuracy: 0.5326, Test Loss: 1.2199\n",
            "0\n",
            "Epoch [6/100], Loss: 1.2509, Acc: 0.5218\n",
            "Test acc:  tensor(0.5371, device='cuda:0')\n",
            "Test loss:  1.2045856914689055\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.2045856914689055\n",
            "Epoch 7/50, Train Loss: 1.2509, Train Accuracy: 0.5218, Test Accuracy: 0.5371, Test Loss: 1.2046\n",
            "0\n",
            "Epoch [7/100], Loss: 1.2194, Acc: 0.5360\n",
            "Test acc:  tensor(0.5539, device='cuda:0')\n",
            "Test loss:  1.1625267678657465\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1625267678657465\n",
            "Epoch 8/50, Train Loss: 1.2194, Train Accuracy: 0.5360, Test Accuracy: 0.5539, Test Loss: 1.1625\n",
            "0\n",
            "Epoch [8/100], Loss: 1.2072, Acc: 0.5376\n",
            "Test acc:  tensor(0.5553, device='cuda:0')\n",
            "Test loss:  1.1485820180546922\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1485820180546922\n",
            "Epoch 9/50, Train Loss: 1.2072, Train Accuracy: 0.5376, Test Accuracy: 0.5553, Test Loss: 1.1486\n",
            "0\n",
            "Epoch [9/100], Loss: 1.1770, Acc: 0.5542\n",
            "Test acc:  tensor(0.5722, device='cuda:0')\n",
            "Test loss:  1.1190787930931665\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.1190787930931665\n",
            "Epoch 10/50, Train Loss: 1.1770, Train Accuracy: 0.5542, Test Accuracy: 0.5722, Test Loss: 1.1191\n",
            "0\n",
            "Epoch [10/100], Loss: 1.1609, Acc: 0.5582\n",
            "Test acc:  tensor(0.5818, device='cuda:0')\n",
            "Test loss:  1.107408278547557\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.107408278547557\n",
            "Epoch 11/50, Train Loss: 1.1609, Train Accuracy: 0.5582, Test Accuracy: 0.5818, Test Loss: 1.1074\n",
            "0\n",
            "Epoch [11/100], Loss: 1.1380, Acc: 0.5700\n",
            "Test acc:  tensor(0.5762, device='cuda:0')\n",
            "Test loss:  1.1122240780201633\n",
            "BEST TEST LOSS:  1.107408278547557\n",
            "Epoch 12/50, Train Loss: 1.1380, Train Accuracy: 0.5700, Test Accuracy: 0.5762, Test Loss: 1.1122\n",
            "1\n",
            "Epoch [12/100], Loss: 1.1234, Acc: 0.5724\n",
            "Test acc:  tensor(0.5834, device='cuda:0')\n",
            "Test loss:  1.0975401615147042\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.0975401615147042\n",
            "Epoch 13/50, Train Loss: 1.1234, Train Accuracy: 0.5724, Test Accuracy: 0.5834, Test Loss: 1.0975\n",
            "0\n",
            "Epoch [13/100], Loss: 1.1063, Acc: 0.5831\n",
            "Test acc:  tensor(0.5907, device='cuda:0')\n",
            "Test loss:  1.0763381015410465\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.0763381015410465\n",
            "Epoch 14/50, Train Loss: 1.1063, Train Accuracy: 0.5831, Test Accuracy: 0.5907, Test Loss: 1.0763\n",
            "0\n",
            "Epoch [14/100], Loss: 1.0899, Acc: 0.5864\n",
            "Test acc:  tensor(0.5985, device='cuda:0')\n",
            "Test loss:  1.0626296804542035\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.0626296804542035\n",
            "Epoch 15/50, Train Loss: 1.0899, Train Accuracy: 0.5864, Test Accuracy: 0.5985, Test Loss: 1.0626\n",
            "0\n",
            "Epoch [15/100], Loss: 1.0838, Acc: 0.5907\n",
            "Test acc:  tensor(0.6007, device='cuda:0')\n",
            "Test loss:  1.0528090648946509\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.0528090648946509\n",
            "Epoch 16/50, Train Loss: 1.0838, Train Accuracy: 0.5907, Test Accuracy: 0.6007, Test Loss: 1.0528\n",
            "0\n",
            "Epoch [16/100], Loss: 1.0676, Acc: 0.5953\n",
            "Test acc:  tensor(0.6014, device='cuda:0')\n",
            "Test loss:  1.0459255452177165\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.0459255452177165\n",
            "Epoch 17/50, Train Loss: 1.0676, Train Accuracy: 0.5953, Test Accuracy: 0.6014, Test Loss: 1.0459\n",
            "0\n",
            "Epoch [17/100], Loss: 1.0584, Acc: 0.6010\n",
            "Test acc:  tensor(0.6048, device='cuda:0')\n",
            "Test loss:  1.057538341895669\n",
            "BEST TEST LOSS:  1.0459255452177165\n",
            "Epoch 18/50, Train Loss: 1.0584, Train Accuracy: 0.6010, Test Accuracy: 0.6048, Test Loss: 1.0575\n",
            "1\n",
            "Epoch [18/100], Loss: 1.0405, Acc: 0.6065\n",
            "Test acc:  tensor(0.6071, device='cuda:0')\n",
            "Test loss:  1.057749537371956\n",
            "BEST TEST LOSS:  1.0459255452177165\n",
            "Epoch 19/50, Train Loss: 1.0405, Train Accuracy: 0.6065, Test Accuracy: 0.6071, Test Loss: 1.0577\n",
            "2\n",
            "Epoch [19/100], Loss: 1.0388, Acc: 0.6082\n",
            "Test acc:  tensor(0.5896, device='cuda:0')\n",
            "Test loss:  1.0871101537373213\n",
            "Early stopping at epoch 20\n",
            "BEST TEST LOSS:  1.0459255452177165\n",
            "Epoch 20/50, Train Loss: 1.0388, Train Accuracy: 0.6082, Test Accuracy: 0.5896, Test Loss: 1.0871\n",
            "3\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "model = CNN()\n",
        "model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
        "model.eval()\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "# Calcola le metriche sul test dataset\n",
        "model.eval()  # Imposta il modello in modalità di valutazione (non addestramento)\n",
        "test_predictions = []\n",
        "test_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predictions = torch.max(torch.nn.functional.softmax(outputs, dim=1), 1)\n",
        "        test_predictions.extend(predictions.cpu().numpy())\n",
        "        test_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(test_labels, test_predictions)\n",
        "precision = precision_score(test_labels, test_predictions, average=None)\n",
        "f1 = f1_score(test_labels, test_predictions, average=None)\n",
        "#auc_roc = roc_auc_score(test_labels, test_predictions, multi_class='ovr')\n",
        "classification_rep = classification_report(test_labels, test_predictions)\n",
        "\n",
        "print(\"Test Metrics:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"F1 Score:\", f1)\n",
        "#print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"Classification Report:\\n\", classification_rep)"
      ],
      "metadata": {
        "id": "8riSTwGlFTJD",
        "outputId": "ad0cc272-6251-43ee-dad7-1e9b2744a9fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics:\n",
            "Accuracy: 0.6014210086375035\n",
            "Precision: [0.5019305  0.73469388 0.43829787 0.77926078 0.5499232  0.47184774\n",
            " 0.71037628]\n",
            "F1 Score: [0.52156469 0.45       0.35743204 0.81569049 0.56489152 0.47448166\n",
            " 0.7295082 ]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.54      0.52       958\n",
            "           1       0.73      0.32      0.45       111\n",
            "           2       0.44      0.30      0.36      1024\n",
            "           3       0.78      0.86      0.82      1774\n",
            "           4       0.55      0.58      0.56      1233\n",
            "           5       0.47      0.48      0.47      1247\n",
            "           6       0.71      0.75      0.73       831\n",
            "\n",
            "    accuracy                           0.60      7178\n",
            "   macro avg       0.60      0.55      0.56      7178\n",
            "weighted avg       0.59      0.60      0.59      7178\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install grad-cam"
      ],
      "metadata": {
        "id": "I7CKokYNqRCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "\n",
        "target_layers = [model.conv6]\n",
        "input_image_path = '/content/test/happy/PrivateTest_10077120.jpg'\n",
        "input_image = Image.open(input_image_path)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "\n",
        "input_tensor = transform(input_image).unsqueeze(0)\n",
        "\n",
        "immagine =cv2.imread('/content/test/happy/PrivateTest_10077120.jpg')\n",
        "# Normalizzazione dell'immagine di input\n",
        "input_image = immagine.astype(np.float32) / 255.0\n",
        "\n",
        "\n",
        "# Construct the CAM object once, and then re-use it on many images:\n",
        "cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)\n",
        "\n",
        "# You can also use it within a with statement, to make sure it is freed,\n",
        "# In case you need to re-create it inside an outer loop:\n",
        "# with GradCAM(model=model, target_layers=target_layers, use_cuda=args.use_cuda) as cam:\n",
        "#   ...\n",
        "\n",
        "# We have to specify the target we want to generate\n",
        "# the Class Activation Maps for.\n",
        "# If targets is None, the highest scoring category\n",
        "# will be used for every image in the batch.\n",
        "# Here we use ClassifierOutputTarget, but you can define your own custom targets\n",
        "# That are, for example, combinations of categories, or specific outputs in a non standard model.\n",
        "\n",
        "targets = [ClassifierOutputTarget(6)]\n",
        "\n",
        "# You can also pass aug_smooth=True and eigen_smooth=True, to apply smoothing.\n",
        "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
        "\n",
        "# In this example grayscale_cam has only one image in the batch:\n",
        "grayscale_cam = grayscale_cam[0, :]\n",
        "visualization = show_cam_on_image(input_image, grayscale_cam, use_rgb=True)"
      ],
      "metadata": {
        "id": "zG-fSvn2qZZf"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(visualization)"
      ],
      "metadata": {
        "id": "dY452FNMsfW7",
        "outputId": "46ad1f80-ac3b-4c35-ec84-4f9a50f79d33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=48x48 at 0x7FE05347F790>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}