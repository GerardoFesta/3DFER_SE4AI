{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GerardoFesta/3DFER_SE4AI/blob/main/models/2DModels/2DCnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "import zipfile\n"
      ],
      "metadata": {
        "id": "nt82bh71Me7J",
        "outputId": "503377a9-9414-4cce-fcaa-974ac63114c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile('drive/Shareddrives/Datasets SEFAI/fer2013.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall() #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "x3PzBCC76kDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JyI6JfnaBNPU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "#Questo commento serve per provare il funzionamento dei commit con colab"
      ],
      "metadata": {
        "id": "C5AbMnPdCehg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Loading**"
      ],
      "metadata": {
        "id": "pZUeJ0PHEVAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"train\" # Directory containing the training data\n",
        "test_dir = \"test\"  # Directory containing the validation data\n",
        "\n",
        "# Define the transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "train_dataset = ImageFolder(train_dir, transform=train_transform)\n",
        "test_dataset = ImageFolder(test_dir, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "bl34X6SU93Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rete convolutiva**"
      ],
      "metadata": {
        "id": "AfkDTdOnczbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(preds, labels):\n",
        "  probabilities = torch.nn.functional.softmax(preds, dim=1)\n",
        "  _, predicted = torch.max(probabilities, 1)\n",
        "  n_correct = (predicted==labels).sum().float()\n",
        "\n",
        "  acc =n_correct / labels.shape[0]\n",
        "  acc= torch.round(acc*100)\n",
        "  return acc, n_correct;\n"
      ],
      "metadata": {
        "id": "iJyvVmbzJXVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.dropout2 = nn.Dropout(0.25)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.dropout3 = nn.Dropout(0.25)\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 256)\n",
        "\n",
        "        self.bn7 = nn.BatchNorm1d(256)\n",
        "\n",
        "        self.dropout4 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc2 = nn.Linear(256, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = nn.ReLU()(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = nn.ReLU()(x)\n",
        "\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = nn.ReLU()(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        x = nn.ReLU()(x)\n",
        "\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.bn5(x)\n",
        "        x = nn.ReLU()(x)\n",
        "\n",
        "        x = self.conv6(x)\n",
        "        x = self.bn6(x)\n",
        "        x = nn.ReLU()(x)\n",
        "\n",
        "        x = self.pool(x)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = x.view(-1, 256 * 6 * 6)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.bn7(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.dropout4(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "E5qDv9UfZonY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "U8n88ptP5Esw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training loop\n",
        "best_accuracy = 0.0\n",
        "\n",
        "for epoch in range(50):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    total_correct = 0\n",
        "    seen = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, acc = accuracy(outputs, labels)\n",
        "        total_correct += acc\n",
        "        seen +=labels.shape[0]\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    train_accuracy = total_correct / seen\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    seen = 0\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "            _, acc = accuracy(outputs, labels)\n",
        "            total_correct += acc\n",
        "            seen +=labels.shape[0]\n",
        "\n",
        "    test_accuracy = total_correct / seen\n",
        "    test_loss = running_loss / len(test_loader)\n",
        "    if test_accuracy > best_accuracy:\n",
        "        best_accuracy = test_accuracy\n",
        "        torch.save(model.state_dict(), 'model_weights.pth')\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{50}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}, Test Loss: {test_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "0keHfEhx7LK5",
        "outputId": "0d7c6798-475c-4265-f1c8-2019e22d3f8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Train Loss: 1.7688, Train Accuracy: 0.2911, Test Accuracy: 0.3895, Test Loss: 1.5819\n",
            "Epoch 2/50, Train Loss: 1.5638, Train Accuracy: 0.3932, Test Accuracy: 0.4448, Test Loss: 1.4690\n",
            "Epoch 3/50, Train Loss: 1.4494, Train Accuracy: 0.4431, Test Accuracy: 0.4862, Test Loss: 1.3410\n",
            "Epoch 4/50, Train Loss: 1.3784, Train Accuracy: 0.4721, Test Accuracy: 0.4925, Test Loss: 1.3102\n",
            "Epoch 5/50, Train Loss: 1.3289, Train Accuracy: 0.4955, Test Accuracy: 0.5192, Test Loss: 1.2572\n",
            "Epoch 6/50, Train Loss: 1.2868, Train Accuracy: 0.5102, Test Accuracy: 0.5191, Test Loss: 1.2321\n",
            "Epoch 7/50, Train Loss: 1.2553, Train Accuracy: 0.5213, Test Accuracy: 0.5166, Test Loss: 1.2343\n",
            "Epoch 8/50, Train Loss: 1.2275, Train Accuracy: 0.5347, Test Accuracy: 0.5486, Test Loss: 1.1764\n",
            "Epoch 9/50, Train Loss: 1.1988, Train Accuracy: 0.5444, Test Accuracy: 0.5541, Test Loss: 1.1546\n",
            "Epoch 10/50, Train Loss: 1.1817, Train Accuracy: 0.5498, Test Accuracy: 0.5554, Test Loss: 1.1463\n",
            "Epoch 11/50, Train Loss: 1.1598, Train Accuracy: 0.5610, Test Accuracy: 0.5783, Test Loss: 1.1052\n",
            "Epoch 12/50, Train Loss: 1.1415, Train Accuracy: 0.5670, Test Accuracy: 0.5759, Test Loss: 1.1050\n",
            "Epoch 13/50, Train Loss: 1.1280, Train Accuracy: 0.5737, Test Accuracy: 0.5798, Test Loss: 1.0905\n",
            "Epoch 14/50, Train Loss: 1.1104, Train Accuracy: 0.5797, Test Accuracy: 0.5807, Test Loss: 1.0919\n",
            "Epoch 15/50, Train Loss: 1.0917, Train Accuracy: 0.5872, Test Accuracy: 0.5932, Test Loss: 1.0685\n",
            "Epoch 16/50, Train Loss: 1.0830, Train Accuracy: 0.5910, Test Accuracy: 0.5938, Test Loss: 1.0802\n",
            "Epoch 17/50, Train Loss: 1.0680, Train Accuracy: 0.5958, Test Accuracy: 0.6069, Test Loss: 1.0501\n",
            "Epoch 18/50, Train Loss: 1.0602, Train Accuracy: 0.5994, Test Accuracy: 0.6034, Test Loss: 1.0555\n",
            "Epoch 19/50, Train Loss: 1.0488, Train Accuracy: 0.6041, Test Accuracy: 0.6049, Test Loss: 1.0429\n",
            "Epoch 20/50, Train Loss: 1.0370, Train Accuracy: 0.6108, Test Accuracy: 0.6027, Test Loss: 1.0463\n",
            "Epoch 21/50, Train Loss: 1.0233, Train Accuracy: 0.6160, Test Accuracy: 0.6043, Test Loss: 1.0410\n",
            "Epoch 22/50, Train Loss: 1.0179, Train Accuracy: 0.6152, Test Accuracy: 0.6174, Test Loss: 1.0213\n",
            "Epoch 23/50, Train Loss: 1.0039, Train Accuracy: 0.6186, Test Accuracy: 0.6137, Test Loss: 1.0176\n",
            "Epoch 24/50, Train Loss: 0.9908, Train Accuracy: 0.6285, Test Accuracy: 0.6158, Test Loss: 1.0162\n",
            "Epoch 25/50, Train Loss: 0.9829, Train Accuracy: 0.6308, Test Accuracy: 0.6188, Test Loss: 1.0119\n",
            "Epoch 26/50, Train Loss: 0.9779, Train Accuracy: 0.6302, Test Accuracy: 0.6077, Test Loss: 1.0333\n",
            "Epoch 27/50, Train Loss: 0.9719, Train Accuracy: 0.6345, Test Accuracy: 0.6209, Test Loss: 1.0170\n",
            "Epoch 28/50, Train Loss: 0.9578, Train Accuracy: 0.6395, Test Accuracy: 0.6272, Test Loss: 1.0030\n",
            "Epoch 29/50, Train Loss: 0.9532, Train Accuracy: 0.6409, Test Accuracy: 0.6191, Test Loss: 1.0246\n",
            "Epoch 30/50, Train Loss: 0.9401, Train Accuracy: 0.6476, Test Accuracy: 0.6259, Test Loss: 0.9987\n",
            "Epoch 31/50, Train Loss: 0.9331, Train Accuracy: 0.6481, Test Accuracy: 0.6233, Test Loss: 1.0052\n",
            "Epoch 32/50, Train Loss: 0.9285, Train Accuracy: 0.6512, Test Accuracy: 0.6296, Test Loss: 1.0064\n",
            "Epoch 33/50, Train Loss: 0.9172, Train Accuracy: 0.6577, Test Accuracy: 0.6344, Test Loss: 0.9806\n",
            "Epoch 34/50, Train Loss: 0.9144, Train Accuracy: 0.6539, Test Accuracy: 0.6317, Test Loss: 0.9935\n",
            "Epoch 35/50, Train Loss: 0.9087, Train Accuracy: 0.6594, Test Accuracy: 0.6318, Test Loss: 0.9831\n",
            "Epoch 36/50, Train Loss: 0.8978, Train Accuracy: 0.6643, Test Accuracy: 0.6322, Test Loss: 0.9815\n",
            "Epoch 37/50, Train Loss: 0.8900, Train Accuracy: 0.6686, Test Accuracy: 0.6358, Test Loss: 0.9761\n",
            "Epoch 38/50, Train Loss: 0.8835, Train Accuracy: 0.6694, Test Accuracy: 0.6347, Test Loss: 0.9876\n",
            "Epoch 39/50, Train Loss: 0.8816, Train Accuracy: 0.6703, Test Accuracy: 0.6397, Test Loss: 0.9753\n",
            "Epoch 40/50, Train Loss: 0.8703, Train Accuracy: 0.6747, Test Accuracy: 0.6392, Test Loss: 0.9776\n",
            "Epoch 41/50, Train Loss: 0.8632, Train Accuracy: 0.6783, Test Accuracy: 0.6350, Test Loss: 0.9962\n",
            "Epoch 42/50, Train Loss: 0.8528, Train Accuracy: 0.6806, Test Accuracy: 0.6360, Test Loss: 0.9831\n",
            "Epoch 43/50, Train Loss: 0.8523, Train Accuracy: 0.6817, Test Accuracy: 0.6417, Test Loss: 0.9704\n",
            "Epoch 44/50, Train Loss: 0.8461, Train Accuracy: 0.6852, Test Accuracy: 0.6442, Test Loss: 0.9627\n",
            "Epoch 45/50, Train Loss: 0.8437, Train Accuracy: 0.6833, Test Accuracy: 0.6513, Test Loss: 0.9630\n",
            "Epoch 46/50, Train Loss: 0.8316, Train Accuracy: 0.6906, Test Accuracy: 0.6449, Test Loss: 0.9624\n",
            "Epoch 47/50, Train Loss: 0.8274, Train Accuracy: 0.6910, Test Accuracy: 0.6460, Test Loss: 0.9776\n",
            "Epoch 48/50, Train Loss: 0.8108, Train Accuracy: 0.6934, Test Accuracy: 0.6463, Test Loss: 0.9681\n",
            "Epoch 49/50, Train Loss: 0.8145, Train Accuracy: 0.6951, Test Accuracy: 0.6463, Test Loss: 0.9617\n",
            "Epoch 50/50, Train Loss: 0.8069, Train Accuracy: 0.6986, Test Accuracy: 0.6493, Test Loss: 0.9571\n"
          ]
        }
      ]
    }
  ]
}