{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPPv6KRx7ZTCYEX9mAm5/Pu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GerardoFesta/3DFER_SE4AI/blob/main/VoxelCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wQY5oZcsfnf",
        "outputId": "f5b0bf30-9aaa-4486-9c09-0d22b15b299a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mlflow\n",
        "!databricks configure --host https://community.cloud.databricks.com/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOo2RTYRDoub",
        "outputId": "4098ad01-80a9-45b7-f3dc-e0c19943e9d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Username: gfesta24@gmail.com\n",
            "Password: \n",
            "Repeat for confirmation: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.model_selection import ParameterGrid"
      ],
      "metadata": {
        "id": "kDQsV4Ersjxk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = np.load('/content/drive/Shareddrives/Datasets SEFAI/voxel_train_dataset.npz')\n",
        "test_df = np.load('/content/drive/Shareddrives/Datasets SEFAI/voxel_test_dataset.npz')"
      ],
      "metadata": {
        "id": "j2PFiOads0Tp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X_array, Y_array, transform=None):\n",
        "        self.X = X_array\n",
        "        self.Y = Y_array\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.X[index]\n",
        "        label = self.Y[index] \n",
        "\n",
        "        # Esegui le trasformazioni se definite\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "q3E2RQbjvyQ7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "mlflow.set_tracking_uri(\"databricks\")\n",
        "mlflow.set_experiment(\"/Users/gfesta24@gmail.com/Voxels3DCNN\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT8dV3hDEqYI",
        "outputId": "0eb3faa7-97dc-4d9f-b69a-c69537cedc67"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/2211619870750348', creation_time=1686564463983, experiment_id='2211619870750348', last_update_time=1686564463983, lifecycle_stage='active', name='/Users/gfesta24@gmail.com/Voxels3DCNN', tags={'mlflow.experiment.sourceName': '/Users/gfesta24@gmail.com/Voxels3DCNN',\n",
              " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
              " 'mlflow.ownerEmail': 'gfesta24@gmail.com',\n",
              " 'mlflow.ownerId': '1923923806180228'}>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train= train_df['data']\n",
        "X_test = test_df['data']\n",
        "y_train = train_df['labels']\n",
        "y_test = test_df['labels']\n",
        "\n",
        "X_full = np.concatenate((X_train, X_test), axis=0)\n",
        "y_full = np.concatenate((y_train, y_test), axis=0)\n"
      ],
      "metadata": {
        "id": "s5V8JQ_7tKOz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.33, random_state=42, stratify=y_full)\n",
        "\n",
        "train_dataset = CustomDataset(X_train, y_train, transform=transforms.ToTensor())\n",
        "\n",
        "test_dataset = CustomDataset(X_test, y_test, transform=transforms.ToTensor())\n",
        "\n",
        "batch_size=64\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "Ch6KCfL9uFa2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(preds, labels):\n",
        "  probabilities = torch.nn.functional.softmax(preds, dim=1)\n",
        "  _, predicted = torch.max(probabilities, dim=1)\n",
        "  n_correct = (predicted==labels).sum().float()\n",
        "\n",
        "  acc =n_correct / labels.shape[0]\n",
        "  acc= torch.round(acc*100)\n",
        "  return acc, n_correct;"
      ],
      "metadata": {
        "id": "xoBlSQbPxg14"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(MyModel, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv3d(1, 32, kernel_size=(5, 5, 3), stride=1, padding=(2, 2, 1))\n",
        "        self.batchnorm1 = nn.BatchNorm3d(32)\n",
        "        self.maxpool1 = nn.MaxPool3d(kernel_size=(3, 3, 2), stride=(2, 2, 2))\n",
        "        \n",
        "        self.conv2 = nn.Conv3d(32, 32, kernel_size=(3, 3, 3), stride=1, padding=0)\n",
        "        self.batchnorm2 = nn.BatchNorm3d(32)\n",
        "        self.maxpool2 = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
        "        \n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(2560, 128)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.maxpool1(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "\n",
        "        #print(x.shape)\n",
        "        x = self.flatten(x)\n",
        "        #print(x.shape)\n",
        "        x = self.fc1(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uGNaNRWvxdLR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.end_run()"
      ],
      "metadata": {
        "id": "2UsVipO7Oxw3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'batch_size': [64, 128, 256, 512],'lr': [0.01, 0.001, 0.0001], \"momentum\":[0.7, 0.8, 0.9], \"decay\":[0.001, 0.01, 0.1]}\n",
        "expanded_grid = ParameterGrid(param_grid)\n",
        "client = mlflow.tracking.MlflowClient()\n",
        "experiment = client.get_experiment_by_name(\"/Users/gfesta24@gmail.com/Voxels3DCNN\")\n",
        "\n",
        "\n",
        "for i in range(len(expanded_grid)):\n",
        "  runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id], filter_string=\" and \".join([f\"params.{k} = '{v}'\" for k, v in expanded_grid[i].items()]))\n",
        "  train_loader = DataLoader(train_dataset, batch_size=expanded_grid[i]['batch_size'], shuffle=True)\n",
        "    \n",
        "  test_loader = DataLoader(test_dataset, batch_size=expanded_grid[i]['batch_size'], shuffle=False)\n",
        "\n",
        "  if len(runs) == 0:\n",
        "\n",
        "\n",
        "    best_loss=100\n",
        "    best_model_train_acc=0\n",
        "    best_model_test_acc=0\n",
        "    best_model_test_loss=0\n",
        "    best_model_train_loss=0\n",
        "    min_delta=0\n",
        "    patience=3\n",
        "    model = MyModel(num_classes = 7)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=expanded_grid[i]['lr'], momentum =expanded_grid[i]['momentum'])\n",
        "\n",
        "\n",
        "    mlflow.start_run()\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    num_epochs = 100\n",
        "    acc_list_train=[]\n",
        "    acc_list_test=[]    \n",
        "    model.train()\n",
        "\n",
        "    mlflow.set_tag(\"model_name\", \"ResNet50\")\n",
        "    mlflow.log_param(\"lr\", expanded_grid[i]['lr'])\n",
        "    mlflow.log_param(\"momentum\", expanded_grid[i]['momentum'])\n",
        "    mlflow.log_param(\"batch_size\", expanded_grid[i]['batch_size'])\n",
        "    mlflow.log_param(\"decay\", expanded_grid[i]['decay'])\n",
        "    best_loss = 100\n",
        "    counter=0\n",
        "    stop=False\n",
        "    for epoch in range(num_epochs):  \n",
        "        if stop:\n",
        "          break\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        tot_seen = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch = torch.reshape(X_batch, (X_batch.shape[0], 1, 24, 24, 24))\n",
        "            X_batch = X_batch.type(torch.cuda.FloatTensor)\n",
        "            #manda i batch al device \n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            #azzera gradiente\n",
        "            optimizer.zero_grad()\n",
        "            #predict\n",
        "            y_pred = model(X_batch)\n",
        "            \n",
        "\n",
        "            #print(y_batch.shape)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            _,acc = accuracy(y_pred, y_batch)\n",
        "            #backpropagation della loss\n",
        "            loss.backward()\n",
        "            #ottimizzazione\n",
        "            optimizer.step()\n",
        "            \n",
        "            #somma della loss e dell'accuracy per il batch\n",
        "            running_loss += loss.item()\n",
        "            running_acc += acc\n",
        "            tot_seen += len(y_batch)                    \n",
        "            \n",
        "        \n",
        "        print(f'Epoch {epoch}: | Loss: {running_loss/len(train_loader):.5f} | Acc: {running_acc/tot_seen:.3f}')\n",
        "        acc_list_train.append(running_acc/len(train_loader))\n",
        "        mlflow.log_metric(\"train_loss\", running_loss / len(train_loader), step=epoch)\n",
        "        mlflow.log_metric(\"train_acc\", running_acc/tot_seen, step=epoch)\n",
        "        tot_corrette = 0\n",
        "        tot_eseguite = 0\n",
        "        running_test_loss = 0\n",
        "        val_loss = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "\n",
        "          for images, labels in test_loader:\n",
        "              images = torch.reshape(images, (images.shape[0], 1, 24, 24, 24))\n",
        "              images = images.type(torch.cuda.FloatTensor)\n",
        "              images = images.to(device)\n",
        "              labels = labels.to(device)\n",
        "            \n",
        "              outputs = model(images)\n",
        "              test_loss = criterion(outputs, labels)\n",
        "              _, n_corrette=accuracy(outputs, labels)\n",
        "              \n",
        "              running_test_loss += test_loss.item() \n",
        "              tot_corrette+=n_corrette.item()\n",
        "              tot_eseguite+=labels.shape[0]\n",
        "\n",
        "          test_acc=100* (tot_corrette/tot_eseguite)\n",
        "          val_loss = running_test_loss / len(test_loader)\n",
        "          acc_list_test.append(test_acc)\n",
        "          print(\"Test acc: \", test_acc)\n",
        "          print(\"Test loss: \", val_loss)\n",
        "          \n",
        "          mlflow.log_metric(\"test_acc\", test_acc, step=epoch)\n",
        "          mlflow.log_metric(\"test_loss\", val_loss, step=epoch)\n",
        "          \n",
        "          \n",
        "        if val_loss < best_loss - min_delta:\n",
        "          print(\"MIGLIORATO\")\n",
        "          best_loss = val_loss\n",
        "          best_model_train_acc=running_acc/tot_seen\n",
        "          best_model_test_acc=test_acc\n",
        "          best_model_test_loss=val_loss\n",
        "          best_model_train_loss=running_loss / len(train_loader)\n",
        "          counter = 0\n",
        "          # Salva i pesi del modello se la validation loss è migliorata\n",
        "          torch.save(model.state_dict(), 'best_model.pt')\n",
        "        else:\n",
        "          counter += 1\n",
        "        # Verifica se raggiunto il criterio di early stopping\n",
        "          if counter >= patience:\n",
        "              print(f'Early stopping at epoch {epoch+1}')\n",
        "              stop=True\n",
        "        print(\"BEST TEST LOSS: \", best_loss)\n",
        "\n",
        "    mlflow.set_tag(\"Epochs_stopped\", epoch+1)\n",
        "    mlflow.log_artifact(\"best_model.pt\")\n",
        "    mlflow.log_metric(\"best_test_acc\", best_model_test_acc)\n",
        "    mlflow.log_metric(\"best_test_loss\", best_model_test_loss)\n",
        "    mlflow.log_metric(\"best_train_acc\", best_model_train_acc)\n",
        "    mlflow.log_metric(\"best_train_loss\", best_model_train_loss)\n",
        "    mlflow.end_run()\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "    PATH = './cnn.pth'\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "    torch.cuda.empty_cache()\n",
        "  else:\n",
        "    print(\"RUN: \", [f\"params.{k} = '{v}'\" for k, v in expanded_grid[i].items()], \" già completata\" )\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6WnDqFXyrce",
        "outputId": "afa5de79-8782-4ecf-f8b5-eb63dcc0b531"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: | Loss: 1.80042 | Acc: 0.267\n",
            "Test acc:  27.067259689570662\n",
            "Test loss:  1.7811005377356028\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7811005377356028\n",
            "Epoch 1: | Loss: 1.75978 | Acc: 0.291\n",
            "Test acc:  30.289552509757645\n",
            "Test loss:  1.732993905254871\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.732993905254871\n",
            "Epoch 2: | Loss: 1.71957 | Acc: 0.312\n",
            "Test acc:  29.754016519923752\n",
            "Test loss:  1.755112903655609\n",
            "BEST TEST LOSS:  1.732993905254871\n",
            "Epoch 3: | Loss: 1.69195 | Acc: 0.330\n",
            "Test acc:  32.90369429064173\n",
            "Test loss:  1.700087672024104\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.700087672024104\n",
            "Epoch 4: | Loss: 1.67311 | Acc: 0.341\n",
            "Test acc:  33.66615231006626\n",
            "Test loss:  1.6852704582875864\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6852704582875864\n",
            "Epoch 5: | Loss: 1.65020 | Acc: 0.350\n",
            "Test acc:  36.00798765544159\n",
            "Test loss:  1.6449159941921345\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6449159941921345\n",
            "Epoch 6: | Loss: 1.63093 | Acc: 0.362\n",
            "Test acc:  36.03521829899247\n",
            "Test loss:  1.6498729596937323\n",
            "BEST TEST LOSS:  1.6449159941921345\n",
            "Epoch 7: | Loss: 1.60285 | Acc: 0.372\n",
            "Test acc:  37.64182626849414\n",
            "Test loss:  1.6202964024736701\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6202964024736701\n",
            "Epoch 8: | Loss: 1.58576 | Acc: 0.383\n",
            "Test acc:  37.44213488245439\n",
            "Test loss:  1.6134893039747469\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6134893039747469\n",
            "Epoch 9: | Loss: 1.56723 | Acc: 0.389\n",
            "Test acc:  37.977670872288286\n",
            "Test loss:  1.6056899142403134\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6056899142403134\n",
            "Epoch 10: | Loss: 1.55793 | Acc: 0.397\n",
            "Test acc:  38.11382409004266\n",
            "Test loss:  1.6084031355863362\n",
            "BEST TEST LOSS:  1.6056899142403134\n",
            "Epoch 11: | Loss: 1.54056 | Acc: 0.406\n",
            "Test acc:  38.26813107016429\n",
            "Test loss:  1.6086154879862173\n",
            "BEST TEST LOSS:  1.6056899142403134\n",
            "Epoch 12: | Loss: 1.52979 | Acc: 0.407\n",
            "Test acc:  38.92166651538531\n",
            "Test loss:  1.5994718233284924\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5994718233284924\n",
            "Epoch 13: | Loss: 1.51801 | Acc: 0.414\n",
            "Test acc:  38.558591268040296\n",
            "Test loss:  1.5986351009049167\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5986351009049167\n",
            "Epoch 14: | Loss: 1.50251 | Acc: 0.421\n",
            "Test acc:  39.01243532722157\n",
            "Test loss:  1.615409110322853\n",
            "BEST TEST LOSS:  1.5986351009049167\n",
            "Epoch 15: | Loss: 1.50041 | Acc: 0.420\n",
            "Test acc:  40.18335299990923\n",
            "Test loss:  1.5908912213551516\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5908912213551516\n",
            "Epoch 16: | Loss: 1.48141 | Acc: 0.425\n",
            "Test acc:  38.73105201052918\n",
            "Test loss:  1.601890948466483\n",
            "BEST TEST LOSS:  1.5908912213551516\n",
            "Epoch 17: | Loss: 1.46411 | Acc: 0.437\n",
            "Test acc:  38.413361169102295\n",
            "Test loss:  1.5995586607497552\n",
            "BEST TEST LOSS:  1.5908912213551516\n",
            "Epoch 18: | Loss: 1.45272 | Acc: 0.440\n",
            "Test acc:  39.675047653626216\n",
            "Test loss:  1.606249614258033\n",
            "Early stopping at epoch 19\n",
            "BEST TEST LOSS:  1.5908912213551516\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.81819 | Acc: 0.259\n",
            "Test acc:  26.949260234183537\n",
            "Test loss:  1.8153101185153675\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8153101185153675\n",
            "Epoch 1: | Loss: 1.78387 | Acc: 0.274\n",
            "Test acc:  27.058182808387038\n",
            "Test loss:  1.77779860234674\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.77779860234674\n",
            "Epoch 2: | Loss: 1.76577 | Acc: 0.284\n",
            "Test acc:  29.14586548062086\n",
            "Test loss:  1.7601505958965058\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7601505958965058\n",
            "Epoch 3: | Loss: 1.75460 | Acc: 0.287\n",
            "Test acc:  29.445402559680495\n",
            "Test loss:  1.7453519464228195\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7453519464228195\n",
            "Epoch 4: | Loss: 1.73380 | Acc: 0.296\n",
            "Test acc:  30.67078151946991\n",
            "Test loss:  1.722298263814408\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.722298263814408\n",
            "Epoch 5: | Loss: 1.71253 | Acc: 0.318\n",
            "Test acc:  32.18662067713534\n",
            "Test loss:  1.6981892041388276\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6981892041388276\n",
            "Epoch 6: | Loss: 1.69398 | Acc: 0.325\n",
            "Test acc:  32.27738948897159\n",
            "Test loss:  1.691726804468673\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.691726804468673\n",
            "Epoch 7: | Loss: 1.66795 | Acc: 0.342\n",
            "Test acc:  34.23799582463465\n",
            "Test loss:  1.664193234002659\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.664193234002659\n",
            "Epoch 8: | Loss: 1.64919 | Acc: 0.346\n",
            "Test acc:  33.88399745847327\n",
            "Test loss:  1.6763200181068023\n",
            "BEST TEST LOSS:  1.664193234002659\n",
            "Epoch 9: | Loss: 1.64754 | Acc: 0.354\n",
            "Test acc:  35.254606517200685\n",
            "Test loss:  1.6519761106182385\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6519761106182385\n",
            "Epoch 10: | Loss: 1.62131 | Acc: 0.363\n",
            "Test acc:  35.98983389307434\n",
            "Test loss:  1.6334163660258916\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6334163660258916\n",
            "Epoch 11: | Loss: 1.60707 | Acc: 0.370\n",
            "Test acc:  36.643369338295365\n",
            "Test loss:  1.6257769220826255\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6257769220826255\n",
            "Epoch 12: | Loss: 1.58943 | Acc: 0.377\n",
            "Test acc:  37.333212308250886\n",
            "Test loss:  1.6129383358652192\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6129383358652192\n",
            "Epoch 13: | Loss: 1.57305 | Acc: 0.385\n",
            "Test acc:  37.650903149677774\n",
            "Test loss:  1.6116000951370062\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6116000951370062\n",
            "Epoch 14: | Loss: 1.55631 | Acc: 0.395\n",
            "Test acc:  37.92320958518653\n",
            "Test loss:  1.6080625877214993\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6080625877214993\n",
            "Epoch 15: | Loss: 1.54458 | Acc: 0.402\n",
            "Test acc:  38.5222837433058\n",
            "Test loss:  1.607115826854816\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.607115826854816\n",
            "Epoch 16: | Loss: 1.54000 | Acc: 0.398\n",
            "Test acc:  36.715984387764365\n",
            "Test loss:  1.6159709519733583\n",
            "BEST TEST LOSS:  1.607115826854816\n",
            "Epoch 17: | Loss: 1.51710 | Acc: 0.408\n",
            "Test acc:  38.39520740673505\n",
            "Test loss:  1.598364032072828\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.598364032072828\n",
            "Epoch 18: | Loss: 1.50389 | Acc: 0.419\n",
            "Test acc:  39.793047109013344\n",
            "Test loss:  1.5928908221294424\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5928908221294424\n",
            "Epoch 19: | Loss: 1.49815 | Acc: 0.417\n",
            "Test acc:  39.057819733139695\n",
            "Test loss:  1.5924518363324205\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5924518363324205\n",
            "Epoch 20: | Loss: 1.48140 | Acc: 0.426\n",
            "Test acc:  39.302895525097576\n",
            "Test loss:  1.587777834407167\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.587777834407167\n",
            "Epoch 21: | Loss: 1.46926 | Acc: 0.429\n",
            "Test acc:  40.410275029499864\n",
            "Test loss:  1.5935858281361575\n",
            "BEST TEST LOSS:  1.587777834407167\n",
            "Epoch 22: | Loss: 1.46354 | Acc: 0.431\n",
            "Test acc:  38.92166651538531\n",
            "Test loss:  1.6021312378734522\n",
            "BEST TEST LOSS:  1.587777834407167\n",
            "Epoch 23: | Loss: 1.44732 | Acc: 0.437\n",
            "Test acc:  39.992738495053096\n",
            "Test loss:  1.6218375484378351\n",
            "Early stopping at epoch 24\n",
            "BEST TEST LOSS:  1.587777834407167\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.82625 | Acc: 0.261\n",
            "Test acc:  27.040029046019786\n",
            "Test loss:  1.7906510740346302\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7906510740346302\n",
            "Epoch 1: | Loss: 1.78932 | Acc: 0.274\n",
            "Test acc:  26.776799491694653\n",
            "Test loss:  1.7858897709433055\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7858897709433055\n",
            "Epoch 2: | Loss: 1.78346 | Acc: 0.271\n",
            "Test acc:  27.221566669692294\n",
            "Test loss:  1.7819024758531867\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7819024758531867\n",
            "Epoch 3: | Loss: 1.77947 | Acc: 0.274\n",
            "Test acc:  27.55741127348643\n",
            "Test loss:  1.7835771313981514\n",
            "BEST TEST LOSS:  1.7819024758531867\n",
            "Epoch 4: | Loss: 1.77874 | Acc: 0.275\n",
            "Test acc:  27.702641372424434\n",
            "Test loss:  1.780897325173968\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.780897325173968\n",
            "Epoch 5: | Loss: 1.77543 | Acc: 0.275\n",
            "Test acc:  27.493873105201054\n",
            "Test loss:  1.7878803786514812\n",
            "BEST TEST LOSS:  1.780897325173968\n",
            "Epoch 6: | Loss: 1.77102 | Acc: 0.277\n",
            "Test acc:  27.94771716438232\n",
            "Test loss:  1.7832492073147284\n",
            "BEST TEST LOSS:  1.780897325173968\n",
            "Epoch 7: | Loss: 1.77022 | Acc: 0.275\n",
            "Test acc:  27.53018062993555\n",
            "Test loss:  1.7754934867682484\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7754934867682484\n",
            "Epoch 8: | Loss: 1.76724 | Acc: 0.278\n",
            "Test acc:  27.484796224017426\n",
            "Test loss:  1.7704436021044074\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7704436021044074\n",
            "Epoch 9: | Loss: 1.75531 | Acc: 0.280\n",
            "Test acc:  27.439411818099302\n",
            "Test loss:  1.7774437204261735\n",
            "BEST TEST LOSS:  1.7704436021044074\n",
            "Epoch 10: | Loss: 1.75260 | Acc: 0.279\n",
            "Test acc:  28.96432785694835\n",
            "Test loss:  1.7553640900319711\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7553640900319711\n",
            "Epoch 11: | Loss: 1.73450 | Acc: 0.289\n",
            "Test acc:  29.862939094127256\n",
            "Test loss:  1.740844326212227\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.740844326212227\n",
            "Epoch 12: | Loss: 1.71997 | Acc: 0.304\n",
            "Test acc:  31.45139330126169\n",
            "Test loss:  1.7021145772382704\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7021145772382704\n",
            "Epoch 13: | Loss: 1.70671 | Acc: 0.318\n",
            "Test acc:  29.890169737678136\n",
            "Test loss:  1.7301992129728285\n",
            "BEST TEST LOSS:  1.7021145772382704\n",
            "Epoch 14: | Loss: 1.67966 | Acc: 0.333\n",
            "Test acc:  32.822002359989106\n",
            "Test loss:  1.6971342983962483\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6971342983962483\n",
            "Epoch 15: | Loss: 1.66324 | Acc: 0.338\n",
            "Test acc:  33.1760007261505\n",
            "Test loss:  1.6833499277258195\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6833499277258195\n",
            "Epoch 16: | Loss: 1.65288 | Acc: 0.344\n",
            "Test acc:  32.694926023418354\n",
            "Test loss:  1.687324591454743\n",
            "BEST TEST LOSS:  1.6833499277258195\n",
            "Epoch 17: | Loss: 1.63464 | Acc: 0.357\n",
            "Test acc:  35.96260324952346\n",
            "Test loss:  1.651671177389994\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.651671177389994\n",
            "Epoch 18: | Loss: 1.61457 | Acc: 0.365\n",
            "Test acc:  36.32567849686848\n",
            "Test loss:  1.6396779607486174\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6396779607486174\n",
            "Epoch 19: | Loss: 1.59070 | Acc: 0.380\n",
            "Test acc:  36.72506126894799\n",
            "Test loss:  1.6321810063599163\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6321810063599163\n",
            "Epoch 20: | Loss: 1.57566 | Acc: 0.389\n",
            "Test acc:  36.95198329853862\n",
            "Test loss:  1.6190311054273836\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6190311054273836\n",
            "Epoch 21: | Loss: 1.55681 | Acc: 0.397\n",
            "Test acc:  38.28628483253154\n",
            "Test loss:  1.605689411907527\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.605689411907527\n",
            "Epoch 22: | Loss: 1.53439 | Acc: 0.404\n",
            "Test acc:  38.240900426613415\n",
            "Test loss:  1.5851659319993388\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5851659319993388\n",
            "Epoch 23: | Loss: 1.51437 | Acc: 0.410\n",
            "Test acc:  38.96705092130344\n",
            "Test loss:  1.5865171231286375\n",
            "BEST TEST LOSS:  1.5851659319993388\n",
            "Epoch 24: | Loss: 1.50406 | Acc: 0.415\n",
            "Test acc:  38.74012889171281\n",
            "Test loss:  1.5879630422316535\n",
            "BEST TEST LOSS:  1.5851659319993388\n",
            "Epoch 25: | Loss: 1.48216 | Acc: 0.424\n",
            "Test acc:  38.558591268040296\n",
            "Test loss:  1.6348399537147125\n",
            "Early stopping at epoch 26\n",
            "BEST TEST LOSS:  1.5851659319993388\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.81038 | Acc: 0.261\n",
            "Test acc:  27.42125805573205\n",
            "Test loss:  1.7809956087542407\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7809956087542407\n",
            "Epoch 1: | Loss: 1.76372 | Acc: 0.284\n",
            "Test acc:  29.708632114005628\n",
            "Test loss:  1.752747764477151\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.752747764477151\n",
            "Epoch 2: | Loss: 1.74268 | Acc: 0.298\n",
            "Test acc:  30.3803213215939\n",
            "Test loss:  1.7376027210599425\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7376027210599425\n",
            "Epoch 3: | Loss: 1.72457 | Acc: 0.311\n",
            "Test acc:  30.61632023236816\n",
            "Test loss:  1.7285061220213167\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7285061220213167\n",
            "Epoch 4: | Loss: 1.70558 | Acc: 0.324\n",
            "Test acc:  32.17754379595171\n",
            "Test loss:  1.7105555079575907\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7105555079575907\n",
            "Epoch 5: | Loss: 1.68373 | Acc: 0.333\n",
            "Test acc:  33.11246255786512\n",
            "Test loss:  1.6890052288253872\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6890052288253872\n",
            "Epoch 6: | Loss: 1.65822 | Acc: 0.347\n",
            "Test acc:  34.55568666606154\n",
            "Test loss:  1.669781205282046\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.669781205282046\n",
            "Epoch 7: | Loss: 1.63347 | Acc: 0.362\n",
            "Test acc:  36.16229463556322\n",
            "Test loss:  1.6467462991703452\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6467462991703452\n",
            "Epoch 8: | Loss: 1.61120 | Acc: 0.371\n",
            "Test acc:  36.1532177543796\n",
            "Test loss:  1.6314033462822093\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6314033462822093\n",
            "Epoch 9: | Loss: 1.58992 | Acc: 0.383\n",
            "Test acc:  36.63429245711174\n",
            "Test loss:  1.6265982106930947\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6265982106930947\n",
            "Epoch 10: | Loss: 1.57235 | Acc: 0.388\n",
            "Test acc:  36.543523645275485\n",
            "Test loss:  1.6222061297797055\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6222061297797055\n",
            "Epoch 11: | Loss: 1.55095 | Acc: 0.397\n",
            "Test acc:  37.623672506126894\n",
            "Test loss:  1.6081309814673628\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6081309814673628\n",
            "Epoch 12: | Loss: 1.53850 | Acc: 0.400\n",
            "Test acc:  37.46936552600527\n",
            "Test loss:  1.609703432617849\n",
            "BEST TEST LOSS:  1.6081309814673628\n",
            "Epoch 13: | Loss: 1.52609 | Acc: 0.410\n",
            "Test acc:  38.222746664246166\n",
            "Test loss:  1.6005112160147958\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6005112160147958\n",
            "Epoch 14: | Loss: 1.51006 | Acc: 0.417\n",
            "Test acc:  38.340746119633295\n",
            "Test loss:  1.5910982141605001\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5910982141605001\n",
            "Epoch 15: | Loss: 1.49709 | Acc: 0.424\n",
            "Test acc:  38.540437505673054\n",
            "Test loss:  1.589768519291299\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.589768519291299\n",
            "Epoch 16: | Loss: 1.48454 | Acc: 0.427\n",
            "Test acc:  39.03966597077244\n",
            "Test loss:  1.598179272144516\n",
            "BEST TEST LOSS:  1.589768519291299\n",
            "Epoch 17: | Loss: 1.46694 | Acc: 0.434\n",
            "Test acc:  38.67659072342743\n",
            "Test loss:  1.6032297728378648\n",
            "BEST TEST LOSS:  1.589768519291299\n",
            "Epoch 18: | Loss: 1.45144 | Acc: 0.438\n",
            "Test acc:  39.66597077244259\n",
            "Test loss:  1.5797398400444516\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5797398400444516\n",
            "Epoch 19: | Loss: 1.43546 | Acc: 0.445\n",
            "Test acc:  38.440591812653174\n",
            "Test loss:  1.581836807245464\n",
            "BEST TEST LOSS:  1.5797398400444516\n",
            "Epoch 20: | Loss: 1.42406 | Acc: 0.456\n",
            "Test acc:  39.80212399019697\n",
            "Test loss:  1.5923098759844123\n",
            "BEST TEST LOSS:  1.5797398400444516\n",
            "Epoch 21: | Loss: 1.40640 | Acc: 0.458\n",
            "Test acc:  39.02151220840519\n",
            "Test loss:  1.5961664439625822\n",
            "Early stopping at epoch 22\n",
            "BEST TEST LOSS:  1.5797398400444516\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.80763 | Acc: 0.262\n",
            "Test acc:  27.702641372424434\n",
            "Test loss:  1.778302224385256\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.778302224385256\n",
            "Epoch 1: | Loss: 1.76286 | Acc: 0.282\n",
            "Test acc:  28.673867659072343\n",
            "Test loss:  1.762636696672164\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.762636696672164\n",
            "Epoch 2: | Loss: 1.74453 | Acc: 0.298\n",
            "Test acc:  29.545248252700375\n",
            "Test loss:  1.7387694933510929\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7387694933510929\n",
            "Epoch 3: | Loss: 1.72454 | Acc: 0.310\n",
            "Test acc:  30.852319143142417\n",
            "Test loss:  1.7242843339897993\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7242843339897993\n",
            "Epoch 4: | Loss: 1.70188 | Acc: 0.321\n",
            "Test acc:  32.549695924480346\n",
            "Test loss:  1.693853590529778\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.693853590529778\n",
            "Epoch 5: | Loss: 1.67072 | Acc: 0.338\n",
            "Test acc:  33.23046201325225\n",
            "Test loss:  1.6826383261322286\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6826383261322286\n",
            "Epoch 6: | Loss: 1.63956 | Acc: 0.355\n",
            "Test acc:  34.30153399292003\n",
            "Test loss:  1.6590344389049994\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6590344389049994\n",
            "Epoch 7: | Loss: 1.61279 | Acc: 0.369\n",
            "Test acc:  36.07152582372697\n",
            "Test loss:  1.6375785101355844\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6375785101355844\n",
            "Epoch 8: | Loss: 1.59361 | Acc: 0.376\n",
            "Test acc:  35.78106562585096\n",
            "Test loss:  1.632232593663166\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.632232593663166\n",
            "Epoch 9: | Loss: 1.56973 | Acc: 0.388\n",
            "Test acc:  37.251520377598254\n",
            "Test loss:  1.607875636547287\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.607875636547287\n",
            "Epoch 10: | Loss: 1.54996 | Acc: 0.401\n",
            "Test acc:  37.15167468457838\n",
            "Test loss:  1.6100847934711875\n",
            "BEST TEST LOSS:  1.607875636547287\n",
            "Epoch 11: | Loss: 1.52765 | Acc: 0.405\n",
            "Test acc:  37.8415176545339\n",
            "Test loss:  1.5954920921711564\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5954920921711564\n",
            "Epoch 12: | Loss: 1.50517 | Acc: 0.418\n",
            "Test acc:  38.29536171371517\n",
            "Test loss:  1.5858284855164544\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5858284855164544\n",
            "Epoch 13: | Loss: 1.48689 | Acc: 0.422\n",
            "Test acc:  38.413361169102295\n",
            "Test loss:  1.5932161070707906\n",
            "BEST TEST LOSS:  1.5858284855164544\n",
            "Epoch 14: | Loss: 1.47529 | Acc: 0.426\n",
            "Test acc:  38.13197785240991\n",
            "Test loss:  1.5966443726093094\n",
            "BEST TEST LOSS:  1.5858284855164544\n",
            "Epoch 15: | Loss: 1.45714 | Acc: 0.435\n",
            "Test acc:  38.91258963420169\n",
            "Test loss:  1.5835441461188255\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5835441461188255\n",
            "Epoch 16: | Loss: 1.43936 | Acc: 0.444\n",
            "Test acc:  38.83997458473269\n",
            "Test loss:  1.5862832152085498\n",
            "BEST TEST LOSS:  1.5835441461188255\n",
            "Epoch 17: | Loss: 1.42631 | Acc: 0.449\n",
            "Test acc:  39.33920304983208\n",
            "Test loss:  1.5695328485069937\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5695328485069937\n",
            "Epoch 18: | Loss: 1.40737 | Acc: 0.456\n",
            "Test acc:  38.76735953526369\n",
            "Test loss:  1.619578826634181\n",
            "BEST TEST LOSS:  1.5695328485069937\n",
            "Epoch 19: | Loss: 1.38766 | Acc: 0.467\n",
            "Test acc:  39.41181809930108\n",
            "Test loss:  1.5922091021014086\n",
            "BEST TEST LOSS:  1.5695328485069937\n",
            "Epoch 20: | Loss: 1.37955 | Acc: 0.467\n",
            "Test acc:  40.0290460197876\n",
            "Test loss:  1.577017597380401\n",
            "Early stopping at epoch 21\n",
            "BEST TEST LOSS:  1.5695328485069937\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.79885 | Acc: 0.266\n",
            "Test acc:  27.62094944177181\n",
            "Test loss:  1.7646845131251163\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7646845131251163\n",
            "Epoch 1: | Loss: 1.75816 | Acc: 0.286\n",
            "Test acc:  29.436325678496868\n",
            "Test loss:  1.7511385506977235\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7511385506977235\n",
            "Epoch 2: | Loss: 1.74086 | Acc: 0.296\n",
            "Test acc:  29.72678587637288\n",
            "Test loss:  1.7378015084073724\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7378015084073724\n",
            "Epoch 3: | Loss: 1.71529 | Acc: 0.311\n",
            "Test acc:  32.12308250884996\n",
            "Test loss:  1.709692157761899\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.709692157761899\n",
            "Epoch 4: | Loss: 1.68282 | Acc: 0.335\n",
            "Test acc:  33.24861577561949\n",
            "Test loss:  1.6848143373610656\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6848143373610656\n",
            "Epoch 5: | Loss: 1.65903 | Acc: 0.350\n",
            "Test acc:  34.818916220386676\n",
            "Test loss:  1.6533267491125647\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6533267491125647\n",
            "Epoch 6: | Loss: 1.63614 | Acc: 0.359\n",
            "Test acc:  35.79014250703458\n",
            "Test loss:  1.6420343673298126\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6420343673298126\n",
            "Epoch 7: | Loss: 1.61367 | Acc: 0.369\n",
            "Test acc:  36.171371516746845\n",
            "Test loss:  1.6377505387874007\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6377505387874007\n",
            "Epoch 8: | Loss: 1.59763 | Acc: 0.380\n",
            "Test acc:  36.942906417355\n",
            "Test loss:  1.6250345445092702\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6250345445092702\n",
            "Epoch 9: | Loss: 1.57746 | Acc: 0.388\n",
            "Test acc:  37.868748298084775\n",
            "Test loss:  1.6082627056651033\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6082627056651033\n",
            "Epoch 10: | Loss: 1.55298 | Acc: 0.395\n",
            "Test acc:  38.08659344649178\n",
            "Test loss:  1.6017658868966076\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6017658868966076\n",
            "Epoch 11: | Loss: 1.54102 | Acc: 0.400\n",
            "Test acc:  37.950440228737406\n",
            "Test loss:  1.5993063925318636\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5993063925318636\n",
            "Epoch 12: | Loss: 1.52603 | Acc: 0.405\n",
            "Test acc:  37.22428973404738\n",
            "Test loss:  1.615370093742547\n",
            "BEST TEST LOSS:  1.5993063925318636\n",
            "Epoch 13: | Loss: 1.50746 | Acc: 0.415\n",
            "Test acc:  38.27720795134792\n",
            "Test loss:  1.594834913408136\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.594834913408136\n",
            "Epoch 14: | Loss: 1.49872 | Acc: 0.416\n",
            "Test acc:  38.89443587183444\n",
            "Test loss:  1.5815709160931537\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5815709160931537\n",
            "Epoch 15: | Loss: 1.47878 | Acc: 0.428\n",
            "Test acc:  39.28474176273033\n",
            "Test loss:  1.588257726906352\n",
            "BEST TEST LOSS:  1.5815709160931537\n",
            "Epoch 16: | Loss: 1.46305 | Acc: 0.435\n",
            "Test acc:  39.475356267586456\n",
            "Test loss:  1.5692209322328512\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5692209322328512\n",
            "Epoch 17: | Loss: 1.43947 | Acc: 0.441\n",
            "Test acc:  39.82935463374784\n",
            "Test loss:  1.5792937196059034\n",
            "BEST TEST LOSS:  1.5692209322328512\n",
            "Epoch 18: | Loss: 1.42958 | Acc: 0.448\n",
            "Test acc:  39.65689389125897\n",
            "Test loss:  1.5821995810966272\n",
            "BEST TEST LOSS:  1.5692209322328512\n",
            "Epoch 19: | Loss: 1.41767 | Acc: 0.451\n",
            "Test acc:  39.59335572297359\n",
            "Test loss:  1.5784003596774416\n",
            "Early stopping at epoch 20\n",
            "BEST TEST LOSS:  1.5692209322328512\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.87741 | Acc: 0.230\n",
            "Test acc:  24.816193156031588\n",
            "Test loss:  1.8282804151490935\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8282804151490935\n",
            "Epoch 1: | Loss: 1.82163 | Acc: 0.258\n",
            "Test acc:  25.306344739947356\n",
            "Test loss:  1.8100612735472663\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8100612735472663\n",
            "Epoch 2: | Loss: 1.80341 | Acc: 0.267\n",
            "Test acc:  26.63156939275665\n",
            "Test loss:  1.8027512710218485\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8027512710218485\n",
            "Epoch 3: | Loss: 1.79405 | Acc: 0.272\n",
            "Test acc:  27.09449033312154\n",
            "Test loss:  1.7860163787885897\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7860163787885897\n",
            "Epoch 4: | Loss: 1.78345 | Acc: 0.275\n",
            "Test acc:  27.675410728873562\n",
            "Test loss:  1.7844237854025957\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7844237854025957\n",
            "Epoch 5: | Loss: 1.77680 | Acc: 0.281\n",
            "Test acc:  27.784333303077062\n",
            "Test loss:  1.7771044804181666\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7771044804181666\n",
            "Epoch 6: | Loss: 1.77051 | Acc: 0.287\n",
            "Test acc:  27.484796224017426\n",
            "Test loss:  1.772250319491921\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.772250319491921\n",
            "Epoch 7: | Loss: 1.76605 | Acc: 0.290\n",
            "Test acc:  27.84787147136244\n",
            "Test loss:  1.7687856648009637\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7687856648009637\n",
            "Epoch 8: | Loss: 1.75911 | Acc: 0.292\n",
            "Test acc:  28.51956067895071\n",
            "Test loss:  1.7672192602488346\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7672192602488346\n",
            "Epoch 9: | Loss: 1.75676 | Acc: 0.290\n",
            "Test acc:  28.48325315421621\n",
            "Test loss:  1.766671494941491\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.766671494941491\n",
            "Epoch 10: | Loss: 1.75467 | Acc: 0.294\n",
            "Test acc:  28.637560134337843\n",
            "Test loss:  1.7622356435467053\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7622356435467053\n",
            "Epoch 11: | Loss: 1.74672 | Acc: 0.298\n",
            "Test acc:  29.118634837069983\n",
            "Test loss:  1.7550511876971735\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7550511876971735\n",
            "Epoch 12: | Loss: 1.74536 | Acc: 0.299\n",
            "Test acc:  29.20032676772261\n",
            "Test loss:  1.754234082436975\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.754234082436975\n",
            "Epoch 13: | Loss: 1.74316 | Acc: 0.300\n",
            "Test acc:  29.336479985476988\n",
            "Test loss:  1.7517256929695262\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7517256929695262\n",
            "Epoch 14: | Loss: 1.73956 | Acc: 0.302\n",
            "Test acc:  29.481710084414996\n",
            "Test loss:  1.7487030683914362\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7487030683914362\n",
            "Epoch 15: | Loss: 1.73362 | Acc: 0.305\n",
            "Test acc:  29.93555414359626\n",
            "Test loss:  1.7428826190143651\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7428826190143651\n",
            "Epoch 16: | Loss: 1.73183 | Acc: 0.306\n",
            "Test acc:  29.790324044658256\n",
            "Test loss:  1.7482510991179185\n",
            "BEST TEST LOSS:  1.7428826190143651\n",
            "Epoch 17: | Loss: 1.72998 | Acc: 0.308\n",
            "Test acc:  30.04447671779976\n",
            "Test loss:  1.7445869852352693\n",
            "BEST TEST LOSS:  1.7428826190143651\n",
            "Epoch 18: | Loss: 1.72531 | Acc: 0.311\n",
            "Test acc:  29.944631024779884\n",
            "Test loss:  1.7383482290830226\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7383482290830226\n",
            "Epoch 19: | Loss: 1.72325 | Acc: 0.311\n",
            "Test acc:  30.262321866206772\n",
            "Test loss:  1.737314714172672\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.737314714172672\n",
            "Epoch 20: | Loss: 1.72154 | Acc: 0.313\n",
            "Test acc:  30.90678043024417\n",
            "Test loss:  1.734957545478909\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.734957545478909\n",
            "Epoch 21: | Loss: 1.71699 | Acc: 0.313\n",
            "Test acc:  30.59816647000091\n",
            "Test loss:  1.7368850639100708\n",
            "BEST TEST LOSS:  1.734957545478909\n",
            "Epoch 22: | Loss: 1.71166 | Acc: 0.316\n",
            "Test acc:  30.779704093673416\n",
            "Test loss:  1.7328456984779048\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7328456984779048\n",
            "Epoch 23: | Loss: 1.70993 | Acc: 0.319\n",
            "Test acc:  30.72524280657166\n",
            "Test loss:  1.7321558115799303\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7321558115799303\n",
            "Epoch 24: | Loss: 1.70845 | Acc: 0.319\n",
            "Test acc:  30.979395479713173\n",
            "Test loss:  1.7271317911974957\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7271317911974957\n",
            "Epoch 25: | Loss: 1.70338 | Acc: 0.328\n",
            "Test acc:  31.00662612326405\n",
            "Test loss:  1.7253075562460574\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7253075562460574\n",
            "Epoch 26: | Loss: 1.69743 | Acc: 0.324\n",
            "Test acc:  31.58754651901607\n",
            "Test loss:  1.7174999534739235\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7174999534739235\n",
            "Epoch 27: | Loss: 1.69613 | Acc: 0.330\n",
            "Test acc:  31.48770082599619\n",
            "Test loss:  1.7217501415682666\n",
            "BEST TEST LOSS:  1.7174999534739235\n",
            "Epoch 28: | Loss: 1.69427 | Acc: 0.324\n",
            "Test acc:  31.89616047925933\n",
            "Test loss:  1.722849125806996\n",
            "BEST TEST LOSS:  1.7174999534739235\n",
            "Epoch 29: | Loss: 1.68895 | Acc: 0.334\n",
            "Test acc:  31.47862394481256\n",
            "Test loss:  1.7188430721360135\n",
            "Early stopping at epoch 30\n",
            "BEST TEST LOSS:  1.7174999534739235\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.89280 | Acc: 0.220\n",
            "Test acc:  24.543886720522828\n",
            "Test loss:  1.8295875257150287\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8295875257150287\n",
            "Epoch 1: | Loss: 1.81680 | Acc: 0.256\n",
            "Test acc:  26.22310973949351\n",
            "Test loss:  1.8062723613198781\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8062723613198781\n",
            "Epoch 2: | Loss: 1.79768 | Acc: 0.269\n",
            "Test acc:  26.949260234183537\n",
            "Test loss:  1.7913331627156692\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7913331627156692\n",
            "Epoch 3: | Loss: 1.78677 | Acc: 0.275\n",
            "Test acc:  27.339566125079422\n",
            "Test loss:  1.781577978520035\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.781577978520035\n",
            "Epoch 4: | Loss: 1.77620 | Acc: 0.281\n",
            "Test acc:  27.23064355087592\n",
            "Test loss:  1.7774430285988516\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7774430285988516\n",
            "Epoch 5: | Loss: 1.76664 | Acc: 0.287\n",
            "Test acc:  28.791867114459475\n",
            "Test loss:  1.7676049629387829\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7676049629387829\n",
            "Epoch 6: | Loss: 1.76007 | Acc: 0.289\n",
            "Test acc:  28.338023055278207\n",
            "Test loss:  1.7690587236702098\n",
            "BEST TEST LOSS:  1.7676049629387829\n",
            "Epoch 7: | Loss: 1.75660 | Acc: 0.294\n",
            "Test acc:  29.06417354996823\n",
            "Test loss:  1.7609425197446966\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7609425197446966\n",
            "Epoch 8: | Loss: 1.74989 | Acc: 0.296\n",
            "Test acc:  28.96432785694835\n",
            "Test loss:  1.7599836622359435\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7599836622359435\n",
            "Epoch 9: | Loss: 1.74309 | Acc: 0.302\n",
            "Test acc:  29.953707905963512\n",
            "Test loss:  1.7505834702122418\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7505834702122418\n",
            "Epoch 10: | Loss: 1.73616 | Acc: 0.304\n",
            "Test acc:  29.581555777434875\n",
            "Test loss:  1.7485278555423538\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7485278555423538\n",
            "Epoch 11: | Loss: 1.73388 | Acc: 0.307\n",
            "Test acc:  30.026322955432512\n",
            "Test loss:  1.7452829442272297\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7452829442272297\n",
            "Epoch 12: | Loss: 1.73057 | Acc: 0.310\n",
            "Test acc:  30.425705727512025\n",
            "Test loss:  1.7419620586957545\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7419620586957545\n",
            "Epoch 13: | Loss: 1.72402 | Acc: 0.314\n",
            "Test acc:  30.207860579105017\n",
            "Test loss:  1.7422749706775467\n",
            "BEST TEST LOSS:  1.7419620586957545\n",
            "Epoch 14: | Loss: 1.72057 | Acc: 0.316\n",
            "Test acc:  30.797857856040668\n",
            "Test loss:  1.7352777064880194\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7352777064880194\n",
            "Epoch 15: | Loss: 1.71237 | Acc: 0.319\n",
            "Test acc:  30.979395479713173\n",
            "Test loss:  1.7357255275538892\n",
            "BEST TEST LOSS:  1.7352777064880194\n",
            "Epoch 16: | Loss: 1.71072 | Acc: 0.323\n",
            "Test acc:  31.188163746936553\n",
            "Test loss:  1.7278785119856024\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7278785119856024\n",
            "Epoch 17: | Loss: 1.70818 | Acc: 0.323\n",
            "Test acc:  31.26985567758918\n",
            "Test loss:  1.7251284770193818\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7251284770193818\n",
            "Epoch 18: | Loss: 1.70067 | Acc: 0.331\n",
            "Test acc:  31.1337024598348\n",
            "Test loss:  1.7251697468619815\n",
            "BEST TEST LOSS:  1.7251284770193818\n",
            "Epoch 19: | Loss: 1.69581 | Acc: 0.330\n",
            "Test acc:  31.551238994281565\n",
            "Test loss:  1.7181808059615207\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7181808059615207\n",
            "Epoch 20: | Loss: 1.69226 | Acc: 0.331\n",
            "Test acc:  31.986929291095578\n",
            "Test loss:  1.7123815544767875\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7123815544767875\n",
            "Epoch 21: | Loss: 1.68422 | Acc: 0.339\n",
            "Test acc:  31.977852409911954\n",
            "Test loss:  1.7137527665650913\n",
            "BEST TEST LOSS:  1.7123815544767875\n",
            "Epoch 22: | Loss: 1.68202 | Acc: 0.340\n",
            "Test acc:  32.31369701370609\n",
            "Test loss:  1.7119825334218197\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7119825334218197\n",
            "Epoch 23: | Loss: 1.67622 | Acc: 0.338\n",
            "Test acc:  32.07769810293183\n",
            "Test loss:  1.7103898986915633\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7103898986915633\n",
            "Epoch 24: | Loss: 1.66983 | Acc: 0.342\n",
            "Test acc:  32.4589271126441\n",
            "Test loss:  1.7085223776756684\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7085223776756684\n",
            "Epoch 25: | Loss: 1.66567 | Acc: 0.350\n",
            "Test acc:  33.24861577561949\n",
            "Test loss:  1.7036921123548738\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7036921123548738\n",
            "Epoch 26: | Loss: 1.65968 | Acc: 0.350\n",
            "Test acc:  33.11246255786512\n",
            "Test loss:  1.694441776055132\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.694441776055132\n",
            "Epoch 27: | Loss: 1.65178 | Acc: 0.354\n",
            "Test acc:  33.45738404284288\n",
            "Test loss:  1.6892161941252692\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6892161941252692\n",
            "Epoch 28: | Loss: 1.65043 | Acc: 0.352\n",
            "Test acc:  33.384768993373875\n",
            "Test loss:  1.6947995920401777\n",
            "BEST TEST LOSS:  1.6892161941252692\n",
            "Epoch 29: | Loss: 1.63879 | Acc: 0.364\n",
            "Test acc:  33.26676953798675\n",
            "Test loss:  1.6897569956807044\n",
            "BEST TEST LOSS:  1.6892161941252692\n",
            "Epoch 30: | Loss: 1.63298 | Acc: 0.361\n",
            "Test acc:  33.77507488426976\n",
            "Test loss:  1.687100799097491\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.687100799097491\n",
            "Epoch 31: | Loss: 1.63281 | Acc: 0.363\n",
            "Test acc:  34.19261141871653\n",
            "Test loss:  1.6812435071592386\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6812435071592386\n",
            "Epoch 32: | Loss: 1.62347 | Acc: 0.367\n",
            "Test acc:  34.18353453753291\n",
            "Test loss:  1.6763048433844066\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6763048433844066\n",
            "Epoch 33: | Loss: 1.61771 | Acc: 0.371\n",
            "Test acc:  34.35599528002179\n",
            "Test loss:  1.6702295548654016\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6702295548654016\n",
            "Epoch 34: | Loss: 1.61205 | Acc: 0.371\n",
            "Test acc:  33.929381864391395\n",
            "Test loss:  1.678439115513267\n",
            "BEST TEST LOSS:  1.6702295548654016\n",
            "Epoch 35: | Loss: 1.60729 | Acc: 0.375\n",
            "Test acc:  34.89153126985568\n",
            "Test loss:  1.6673111343659417\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6673111343659417\n",
            "Epoch 36: | Loss: 1.59985 | Acc: 0.379\n",
            "Test acc:  35.39075973495507\n",
            "Test loss:  1.6642055614835265\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6642055614835265\n",
            "Epoch 37: | Loss: 1.59655 | Acc: 0.381\n",
            "Test acc:  35.41799037850595\n",
            "Test loss:  1.657459691769815\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.657459691769815\n",
            "Epoch 38: | Loss: 1.59096 | Acc: 0.385\n",
            "Test acc:  35.653989289280204\n",
            "Test loss:  1.6524386130316409\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6524386130316409\n",
            "Epoch 39: | Loss: 1.58171 | Acc: 0.390\n",
            "Test acc:  35.3998366161387\n",
            "Test loss:  1.6529109050772783\n",
            "BEST TEST LOSS:  1.6524386130316409\n",
            "Epoch 40: | Loss: 1.57893 | Acc: 0.390\n",
            "Test acc:  35.5087591903422\n",
            "Test loss:  1.6519153324854856\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6519153324854856\n",
            "Epoch 41: | Loss: 1.57178 | Acc: 0.394\n",
            "Test acc:  35.66306617046383\n",
            "Test loss:  1.6507452554096376\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6507452554096376\n",
            "Epoch 42: | Loss: 1.56546 | Acc: 0.395\n",
            "Test acc:  35.71752745756558\n",
            "Test loss:  1.6498398319145158\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6498398319145158\n",
            "Epoch 43: | Loss: 1.55469 | Acc: 0.400\n",
            "Test acc:  35.83552691295271\n",
            "Test loss:  1.651006378879437\n",
            "BEST TEST LOSS:  1.6498398319145158\n",
            "Epoch 44: | Loss: 1.55037 | Acc: 0.402\n",
            "Test acc:  35.753834982300084\n",
            "Test loss:  1.6465041988846885\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6465041988846885\n",
            "Epoch 45: | Loss: 1.54775 | Acc: 0.405\n",
            "Test acc:  36.371062902786605\n",
            "Test loss:  1.6383470145264112\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6383470145264112\n",
            "Epoch 46: | Loss: 1.53862 | Acc: 0.409\n",
            "Test acc:  36.3347553780521\n",
            "Test loss:  1.6388303647840643\n",
            "BEST TEST LOSS:  1.6383470145264112\n",
            "Epoch 47: | Loss: 1.53492 | Acc: 0.411\n",
            "Test acc:  37.015521466824\n",
            "Test loss:  1.63304192137856\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.63304192137856\n",
            "Epoch 48: | Loss: 1.53327 | Acc: 0.415\n",
            "Test acc:  36.271217209766725\n",
            "Test loss:  1.6400995378549388\n",
            "BEST TEST LOSS:  1.63304192137856\n",
            "Epoch 49: | Loss: 1.52505 | Acc: 0.417\n",
            "Test acc:  36.70690750658074\n",
            "Test loss:  1.6310935344310165\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6310935344310165\n",
            "Epoch 50: | Loss: 1.51822 | Acc: 0.416\n",
            "Test acc:  37.14259780339476\n",
            "Test loss:  1.6316982459470717\n",
            "BEST TEST LOSS:  1.6310935344310165\n",
            "Epoch 51: | Loss: 1.51337 | Acc: 0.421\n",
            "Test acc:  36.47998547699011\n",
            "Test loss:  1.6346152131957126\n",
            "BEST TEST LOSS:  1.6310935344310165\n",
            "Epoch 52: | Loss: 1.50734 | Acc: 0.426\n",
            "Test acc:  36.1532177543796\n",
            "Test loss:  1.6365875536306744\n",
            "Early stopping at epoch 53\n",
            "BEST TEST LOSS:  1.6310935344310165\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.86329 | Acc: 0.234\n",
            "Test acc:  26.32295543251339\n",
            "Test loss:  1.8075987011021961\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8075987011021961\n",
            "Epoch 1: | Loss: 1.79798 | Acc: 0.268\n",
            "Test acc:  27.257874194426794\n",
            "Test loss:  1.78467108266202\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.78467108266202\n",
            "Epoch 2: | Loss: 1.77732 | Acc: 0.277\n",
            "Test acc:  28.1564854316057\n",
            "Test loss:  1.7738018807648235\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7738018807648235\n",
            "Epoch 3: | Loss: 1.76238 | Acc: 0.285\n",
            "Test acc:  29.027866025233727\n",
            "Test loss:  1.760767753413647\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.760767753413647\n",
            "Epoch 4: | Loss: 1.75405 | Acc: 0.292\n",
            "Test acc:  29.617863302169372\n",
            "Test loss:  1.7528468060355655\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7528468060355655\n",
            "Epoch 5: | Loss: 1.74461 | Acc: 0.298\n",
            "Test acc:  29.39094127257874\n",
            "Test loss:  1.7469521313044376\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7469521313044376\n",
            "Epoch 6: | Loss: 1.73417 | Acc: 0.305\n",
            "Test acc:  29.971861668330764\n",
            "Test loss:  1.7402246501404426\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7402246501404426\n",
            "Epoch 7: | Loss: 1.72908 | Acc: 0.306\n",
            "Test acc:  30.661704638286285\n",
            "Test loss:  1.7351690268929982\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7351690268929982\n",
            "Epoch 8: | Loss: 1.71957 | Acc: 0.316\n",
            "Test acc:  31.360624489425433\n",
            "Test loss:  1.725268278507828\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.725268278507828\n",
            "Epoch 9: | Loss: 1.70697 | Acc: 0.324\n",
            "Test acc:  32.150313152400834\n",
            "Test loss:  1.7182982133303075\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7182982133303075\n",
            "Epoch 10: | Loss: 1.69850 | Acc: 0.327\n",
            "Test acc:  32.14123627121721\n",
            "Test loss:  1.7141936865845167\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7141936865845167\n",
            "Epoch 11: | Loss: 1.68468 | Acc: 0.337\n",
            "Test acc:  32.77661795407098\n",
            "Test loss:  1.7031439956213008\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7031439956213008\n",
            "Epoch 12: | Loss: 1.67772 | Acc: 0.340\n",
            "Test acc:  33.33030770627213\n",
            "Test loss:  1.6968412530215489\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6968412530215489\n",
            "Epoch 13: | Loss: 1.66524 | Acc: 0.347\n",
            "Test acc:  33.60261414178088\n",
            "Test loss:  1.69075822692386\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.69075822692386\n",
            "Epoch 14: | Loss: 1.65324 | Acc: 0.357\n",
            "Test acc:  34.13815013161477\n",
            "Test loss:  1.6884043120235377\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6884043120235377\n",
            "Epoch 15: | Loss: 1.64618 | Acc: 0.359\n",
            "Test acc:  34.24707270581828\n",
            "Test loss:  1.6771612794413042\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6771612794413042\n",
            "Epoch 16: | Loss: 1.63552 | Acc: 0.363\n",
            "Test acc:  34.7553780521013\n",
            "Test loss:  1.6693894360106805\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6693894360106805\n",
            "Epoch 17: | Loss: 1.62949 | Acc: 0.367\n",
            "Test acc:  34.80076245801943\n",
            "Test loss:  1.669238038834809\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.669238038834809\n",
            "Epoch 18: | Loss: 1.62038 | Acc: 0.369\n",
            "Test acc:  35.05491513116093\n",
            "Test loss:  1.6631380278251076\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6631380278251076\n",
            "Epoch 19: | Loss: 1.61372 | Acc: 0.373\n",
            "Test acc:  34.97322320050831\n",
            "Test loss:  1.6607167293570635\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6607167293570635\n",
            "Epoch 20: | Loss: 1.60281 | Acc: 0.380\n",
            "Test acc:  35.02768448761005\n",
            "Test loss:  1.659882463471738\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.659882463471738\n",
            "Epoch 21: | Loss: 1.58848 | Acc: 0.384\n",
            "Test acc:  35.209222111282564\n",
            "Test loss:  1.6583403865726007\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6583403865726007\n",
            "Epoch 22: | Loss: 1.58210 | Acc: 0.388\n",
            "Test acc:  35.69029681401471\n",
            "Test loss:  1.6517071434528152\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6517071434528152\n",
            "Epoch 23: | Loss: 1.57221 | Acc: 0.394\n",
            "Test acc:  35.84460379413634\n",
            "Test loss:  1.648812938287768\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.648812938287768\n",
            "Epoch 24: | Loss: 1.56448 | Acc: 0.398\n",
            "Test acc:  35.899065081238085\n",
            "Test loss:  1.648355574966166\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.648355574966166\n",
            "Epoch 25: | Loss: 1.55684 | Acc: 0.401\n",
            "Test acc:  36.72506126894799\n",
            "Test loss:  1.6413211753602661\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6413211753602661\n",
            "Epoch 26: | Loss: 1.54700 | Acc: 0.401\n",
            "Test acc:  36.50721612054098\n",
            "Test loss:  1.6393921492416734\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6393921492416734\n",
            "Epoch 27: | Loss: 1.54082 | Acc: 0.409\n",
            "Test acc:  36.12598711082872\n",
            "Test loss:  1.6413705514345556\n",
            "BEST TEST LOSS:  1.6393921492416734\n",
            "Epoch 28: | Loss: 1.53234 | Acc: 0.412\n",
            "Test acc:  35.57229735862757\n",
            "Test loss:  1.6396028265098617\n",
            "BEST TEST LOSS:  1.6393921492416734\n",
            "Epoch 29: | Loss: 1.51970 | Acc: 0.419\n",
            "Test acc:  36.87029136788599\n",
            "Test loss:  1.639203522935768\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.639203522935768\n",
            "Epoch 30: | Loss: 1.51679 | Acc: 0.418\n",
            "Test acc:  36.73413815013161\n",
            "Test loss:  1.6379967707430008\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6379967707430008\n",
            "Epoch 31: | Loss: 1.50179 | Acc: 0.423\n",
            "Test acc:  37.26059725878188\n",
            "Test loss:  1.636611347253612\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.636611347253612\n",
            "Epoch 32: | Loss: 1.49688 | Acc: 0.426\n",
            "Test acc:  36.77044567486612\n",
            "Test loss:  1.629077635748538\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.629077635748538\n",
            "Epoch 33: | Loss: 1.48315 | Acc: 0.430\n",
            "Test acc:  37.178905328129254\n",
            "Test loss:  1.6254822973571073\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6254822973571073\n",
            "Epoch 34: | Loss: 1.48077 | Acc: 0.435\n",
            "Test acc:  37.20613597168013\n",
            "Test loss:  1.638298601773433\n",
            "BEST TEST LOSS:  1.6254822973571073\n",
            "Epoch 35: | Loss: 1.47490 | Acc: 0.440\n",
            "Test acc:  37.060905872742126\n",
            "Test loss:  1.6294192702784014\n",
            "BEST TEST LOSS:  1.6254822973571073\n",
            "Epoch 36: | Loss: 1.46225 | Acc: 0.441\n",
            "Test acc:  36.66152310066261\n",
            "Test loss:  1.6404948475732968\n",
            "Early stopping at epoch 37\n",
            "BEST TEST LOSS:  1.6254822973571073\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.80543 | Acc: 0.264\n",
            "Test acc:  28.18371607515658\n",
            "Test loss:  1.7731080000111132\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7731080000111132\n",
            "Epoch 1: | Loss: 1.77135 | Acc: 0.277\n",
            "Test acc:  29.60878642098575\n",
            "Test loss:  1.7653860129372922\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7653860129372922\n",
            "Epoch 2: | Loss: 1.74926 | Acc: 0.292\n",
            "Test acc:  29.263864936007987\n",
            "Test loss:  1.745890843385906\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.745890843385906\n",
            "Epoch 3: | Loss: 1.70908 | Acc: 0.317\n",
            "Test acc:  32.77661795407098\n",
            "Test loss:  1.684969679468629\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.684969679468629\n",
            "Epoch 4: | Loss: 1.67849 | Acc: 0.334\n",
            "Test acc:  33.71153671598439\n",
            "Test loss:  1.6688603197219054\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6688603197219054\n",
            "Epoch 5: | Loss: 1.65773 | Acc: 0.352\n",
            "Test acc:  34.69183988381592\n",
            "Test loss:  1.6636468895597953\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6636468895597953\n",
            "Epoch 6: | Loss: 1.63782 | Acc: 0.360\n",
            "Test acc:  36.62521557592811\n",
            "Test loss:  1.6350318462173374\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6350318462173374\n",
            "Epoch 7: | Loss: 1.61402 | Acc: 0.365\n",
            "Test acc:  36.77044567486612\n",
            "Test loss:  1.6208867454804436\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6208867454804436\n",
            "Epoch 8: | Loss: 1.60643 | Acc: 0.377\n",
            "Test acc:  36.73413815013161\n",
            "Test loss:  1.6323615643330391\n",
            "BEST TEST LOSS:  1.6208867454804436\n",
            "Epoch 9: | Loss: 1.58437 | Acc: 0.384\n",
            "Test acc:  37.433058001270766\n",
            "Test loss:  1.6093541363071155\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6093541363071155\n",
            "Epoch 10: | Loss: 1.57589 | Acc: 0.387\n",
            "Test acc:  37.678133793228646\n",
            "Test loss:  1.6249395229912906\n",
            "BEST TEST LOSS:  1.6093541363071155\n",
            "Epoch 11: | Loss: 1.55379 | Acc: 0.397\n",
            "Test acc:  38.80366705999819\n",
            "Test loss:  1.5867768663891477\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5867768663891477\n",
            "Epoch 12: | Loss: 1.53856 | Acc: 0.402\n",
            "Test acc:  35.94444948715621\n",
            "Test loss:  1.6574950817692486\n",
            "BEST TEST LOSS:  1.5867768663891477\n",
            "Epoch 13: | Loss: 1.53416 | Acc: 0.407\n",
            "Test acc:  38.613052555142055\n",
            "Test loss:  1.5915725775536773\n",
            "BEST TEST LOSS:  1.5867768663891477\n",
            "Epoch 14: | Loss: 1.51362 | Acc: 0.414\n",
            "Test acc:  39.36643369338295\n",
            "Test loss:  1.5778874413815538\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5778874413815538\n",
            "Epoch 15: | Loss: 1.49743 | Acc: 0.417\n",
            "Test acc:  39.85658527729872\n",
            "Test loss:  1.5902420902527825\n",
            "BEST TEST LOSS:  1.5778874413815538\n",
            "Epoch 16: | Loss: 1.48446 | Acc: 0.422\n",
            "Test acc:  39.18489606971045\n",
            "Test loss:  1.5911477576790518\n",
            "BEST TEST LOSS:  1.5778874413815538\n",
            "Epoch 17: | Loss: 1.47191 | Acc: 0.432\n",
            "Test acc:  39.3482799310157\n",
            "Test loss:  1.5810821214852306\n",
            "Early stopping at epoch 18\n",
            "BEST TEST LOSS:  1.5778874413815538\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.81193 | Acc: 0.261\n",
            "Test acc:  26.912952709449034\n",
            "Test loss:  1.7947102502591348\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7947102502591348\n",
            "Epoch 1: | Loss: 1.78686 | Acc: 0.272\n",
            "Test acc:  27.775256421893435\n",
            "Test loss:  1.7875035794484133\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7875035794484133\n",
            "Epoch 2: | Loss: 1.77203 | Acc: 0.279\n",
            "Test acc:  28.664790777888715\n",
            "Test loss:  1.7612302827008197\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7612302827008197\n",
            "Epoch 3: | Loss: 1.75920 | Acc: 0.285\n",
            "Test acc:  28.96432785694835\n",
            "Test loss:  1.7673257644465894\n",
            "BEST TEST LOSS:  1.7612302827008197\n",
            "Epoch 4: | Loss: 1.74766 | Acc: 0.290\n",
            "Test acc:  29.817554688209132\n",
            "Test loss:  1.75293540403333\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.75293540403333\n",
            "Epoch 5: | Loss: 1.72454 | Acc: 0.305\n",
            "Test acc:  32.740310429336475\n",
            "Test loss:  1.7007961231849098\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7007961231849098\n",
            "Epoch 6: | Loss: 1.70097 | Acc: 0.320\n",
            "Test acc:  32.16846691476808\n",
            "Test loss:  1.6870285982341435\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6870285982341435\n",
            "Epoch 7: | Loss: 1.67009 | Acc: 0.336\n",
            "Test acc:  32.350004538440594\n",
            "Test loss:  1.7144794257390017\n",
            "BEST TEST LOSS:  1.6870285982341435\n",
            "Epoch 8: | Loss: 1.65290 | Acc: 0.350\n",
            "Test acc:  33.69338295361713\n",
            "Test loss:  1.6761988408303674\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6761988408303674\n",
            "Epoch 9: | Loss: 1.63547 | Acc: 0.360\n",
            "Test acc:  36.03521829899247\n",
            "Test loss:  1.6264062196533116\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6264062196533116\n",
            "Epoch 10: | Loss: 1.61766 | Acc: 0.368\n",
            "Test acc:  37.233366615231006\n",
            "Test loss:  1.6312465033779255\n",
            "BEST TEST LOSS:  1.6264062196533116\n",
            "Epoch 11: | Loss: 1.59949 | Acc: 0.378\n",
            "Test acc:  35.726604338749205\n",
            "Test loss:  1.6364010875624728\n",
            "BEST TEST LOSS:  1.6264062196533116\n",
            "Epoch 12: | Loss: 1.58952 | Acc: 0.384\n",
            "Test acc:  36.84306072433512\n",
            "Test loss:  1.6323251448614748\n",
            "Early stopping at epoch 13\n",
            "BEST TEST LOSS:  1.6264062196533116\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.82472 | Acc: 0.258\n",
            "Test acc:  27.339566125079422\n",
            "Test loss:  1.7965434755204042\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7965434755204042\n",
            "Epoch 1: | Loss: 1.79050 | Acc: 0.270\n",
            "Test acc:  26.18680221475901\n",
            "Test loss:  1.7898630847820658\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7898630847820658\n",
            "Epoch 2: | Loss: 1.78305 | Acc: 0.272\n",
            "Test acc:  27.602795679404558\n",
            "Test loss:  1.7840361402213918\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7840361402213918\n",
            "Epoch 3: | Loss: 1.77926 | Acc: 0.273\n",
            "Test acc:  27.049105927203414\n",
            "Test loss:  1.775725568650086\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.775725568650086\n",
            "Epoch 4: | Loss: 1.77584 | Acc: 0.273\n",
            "Test acc:  27.003721521285286\n",
            "Test loss:  1.7756083376834848\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7756083376834848\n",
            "Epoch 5: | Loss: 1.77445 | Acc: 0.272\n",
            "Test acc:  27.475719342833806\n",
            "Test loss:  1.7755953176862243\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7755953176862243\n",
            "Epoch 6: | Loss: 1.76666 | Acc: 0.277\n",
            "Test acc:  28.51956067895071\n",
            "Test loss:  1.7714167612825515\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7714167612825515\n",
            "Epoch 7: | Loss: 1.76221 | Acc: 0.280\n",
            "Test acc:  27.802487065444314\n",
            "Test loss:  1.7614974548361895\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7614974548361895\n",
            "Epoch 8: | Loss: 1.75165 | Acc: 0.279\n",
            "Test acc:  27.38495053099755\n",
            "Test loss:  1.7549156460458832\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7549156460458832\n",
            "Epoch 9: | Loss: 1.74448 | Acc: 0.281\n",
            "Test acc:  27.049105927203414\n",
            "Test loss:  1.7707674448200732\n",
            "BEST TEST LOSS:  1.7549156460458832\n",
            "Epoch 10: | Loss: 1.73985 | Acc: 0.285\n",
            "Test acc:  30.17155305437052\n",
            "Test loss:  1.722512778519206\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.722512778519206\n",
            "Epoch 11: | Loss: 1.71686 | Acc: 0.310\n",
            "Test acc:  31.11554869746755\n",
            "Test loss:  1.7097041207241874\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7097041207241874\n",
            "Epoch 12: | Loss: 1.69877 | Acc: 0.319\n",
            "Test acc:  33.239538894435874\n",
            "Test loss:  1.687515176100538\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.687515176100538\n",
            "Epoch 13: | Loss: 1.67313 | Acc: 0.335\n",
            "Test acc:  32.73123354815286\n",
            "Test loss:  1.68264339287157\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.68264339287157\n",
            "Epoch 14: | Loss: 1.65131 | Acc: 0.344\n",
            "Test acc:  33.411999636924754\n",
            "Test loss:  1.6750954231085804\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6750954231085804\n",
            "Epoch 15: | Loss: 1.63831 | Acc: 0.350\n",
            "Test acc:  34.38322592357266\n",
            "Test loss:  1.659789602191462\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.659789602191462\n",
            "Epoch 16: | Loss: 1.61378 | Acc: 0.363\n",
            "Test acc:  35.71752745756558\n",
            "Test loss:  1.6420514149472893\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6420514149472893\n",
            "Epoch 17: | Loss: 1.59628 | Acc: 0.372\n",
            "Test acc:  35.554143596260325\n",
            "Test loss:  1.641365866440569\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.641365866440569\n",
            "Epoch 18: | Loss: 1.57614 | Acc: 0.386\n",
            "Test acc:  37.088136516293005\n",
            "Test loss:  1.6145327449533982\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6145327449533982\n",
            "Epoch 19: | Loss: 1.55436 | Acc: 0.395\n",
            "Test acc:  37.505673050739766\n",
            "Test loss:  1.622174327773166\n",
            "BEST TEST LOSS:  1.6145327449533982\n",
            "Epoch 20: | Loss: 1.53730 | Acc: 0.400\n",
            "Test acc:  37.31505854588363\n",
            "Test loss:  1.615028119500662\n",
            "BEST TEST LOSS:  1.6145327449533982\n",
            "Epoch 21: | Loss: 1.51903 | Acc: 0.409\n",
            "Test acc:  39.02151220840519\n",
            "Test loss:  1.6022265646499017\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6022265646499017\n",
            "Epoch 22: | Loss: 1.49804 | Acc: 0.418\n",
            "Test acc:  37.0518289915585\n",
            "Test loss:  1.614826163115529\n",
            "BEST TEST LOSS:  1.6022265646499017\n",
            "Epoch 23: | Loss: 1.48248 | Acc: 0.426\n",
            "Test acc:  39.87473903966597\n",
            "Test loss:  1.5855291013772776\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5855291013772776\n",
            "Epoch 24: | Loss: 1.47176 | Acc: 0.427\n",
            "Test acc:  39.22120359444495\n",
            "Test loss:  1.6036800731813288\n",
            "BEST TEST LOSS:  1.5855291013772776\n",
            "Epoch 25: | Loss: 1.45558 | Acc: 0.437\n",
            "Test acc:  38.93074339656894\n",
            "Test loss:  1.6091931396826153\n",
            "BEST TEST LOSS:  1.5855291013772776\n",
            "Epoch 26: | Loss: 1.43802 | Acc: 0.441\n",
            "Test acc:  39.402741218117455\n",
            "Test loss:  1.5946437430519589\n",
            "Early stopping at epoch 27\n",
            "BEST TEST LOSS:  1.5855291013772776\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.81704 | Acc: 0.259\n",
            "Test acc:  28.247254243441954\n",
            "Test loss:  1.767979931280103\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.767979931280103\n",
            "Epoch 1: | Loss: 1.76210 | Acc: 0.285\n",
            "Test acc:  29.036942906417355\n",
            "Test loss:  1.7523639277915735\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7523639277915735\n",
            "Epoch 2: | Loss: 1.73808 | Acc: 0.303\n",
            "Test acc:  30.17155305437052\n",
            "Test loss:  1.7373517503628153\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7373517503628153\n",
            "Epoch 3: | Loss: 1.71238 | Acc: 0.317\n",
            "Test acc:  32.24108196423709\n",
            "Test loss:  1.7063414885129542\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7063414885129542\n",
            "Epoch 4: | Loss: 1.68247 | Acc: 0.333\n",
            "Test acc:  33.52999909231188\n",
            "Test loss:  1.6730711115578007\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6730711115578007\n",
            "Epoch 5: | Loss: 1.65848 | Acc: 0.347\n",
            "Test acc:  34.42861032949079\n",
            "Test loss:  1.6612207510567814\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6612207510567814\n",
            "Epoch 6: | Loss: 1.63735 | Acc: 0.355\n",
            "Test acc:  34.991376962875556\n",
            "Test loss:  1.6525842178763681\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6525842178763681\n",
            "Epoch 7: | Loss: 1.61655 | Acc: 0.367\n",
            "Test acc:  36.00798765544159\n",
            "Test loss:  1.6328446417185611\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6328446417185611\n",
            "Epoch 8: | Loss: 1.59808 | Acc: 0.372\n",
            "Test acc:  35.27276027956794\n",
            "Test loss:  1.6376294814093264\n",
            "BEST TEST LOSS:  1.6328446417185611\n",
            "Epoch 9: | Loss: 1.57758 | Acc: 0.386\n",
            "Test acc:  36.67059998184624\n",
            "Test loss:  1.6195798271653281\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6195798271653281\n",
            "Epoch 10: | Loss: 1.56567 | Acc: 0.391\n",
            "Test acc:  37.46028864482164\n",
            "Test loss:  1.609654281869789\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.609654281869789\n",
            "Epoch 11: | Loss: 1.54861 | Acc: 0.397\n",
            "Test acc:  37.09721339747662\n",
            "Test loss:  1.6067249664681496\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6067249664681496\n",
            "Epoch 12: | Loss: 1.53756 | Acc: 0.404\n",
            "Test acc:  38.12290097122629\n",
            "Test loss:  1.5961631336653164\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5961631336653164\n",
            "Epoch 13: | Loss: 1.52128 | Acc: 0.407\n",
            "Test acc:  37.59644186257602\n",
            "Test loss:  1.5958321604425507\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5958321604425507\n",
            "Epoch 14: | Loss: 1.51239 | Acc: 0.414\n",
            "Test acc:  38.53136062448942\n",
            "Test loss:  1.5966337354196978\n",
            "BEST TEST LOSS:  1.5958321604425507\n",
            "Epoch 15: | Loss: 1.49201 | Acc: 0.425\n",
            "Test acc:  38.92166651538531\n",
            "Test loss:  1.5885950299356715\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5885950299356715\n",
            "Epoch 16: | Loss: 1.47616 | Acc: 0.427\n",
            "Test acc:  38.15013161477716\n",
            "Test loss:  1.587766918143785\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.587766918143785\n",
            "Epoch 17: | Loss: 1.46585 | Acc: 0.434\n",
            "Test acc:  38.86720522828357\n",
            "Test loss:  1.5790110020279196\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5790110020279196\n",
            "Epoch 18: | Loss: 1.44872 | Acc: 0.441\n",
            "Test acc:  38.89443587183444\n",
            "Test loss:  1.602945965149499\n",
            "BEST TEST LOSS:  1.5790110020279196\n",
            "Epoch 19: | Loss: 1.44059 | Acc: 0.445\n",
            "Test acc:  38.5948987927748\n",
            "Test loss:  1.6026205651332877\n",
            "BEST TEST LOSS:  1.5790110020279196\n",
            "Epoch 20: | Loss: 1.42860 | Acc: 0.449\n",
            "Test acc:  39.302895525097576\n",
            "Test loss:  1.5758875649788475\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5758875649788475\n",
            "Epoch 21: | Loss: 1.41201 | Acc: 0.457\n",
            "Test acc:  39.647817010075336\n",
            "Test loss:  1.5902918094844487\n",
            "BEST TEST LOSS:  1.5758875649788475\n",
            "Epoch 22: | Loss: 1.39288 | Acc: 0.466\n",
            "Test acc:  38.758282654080055\n",
            "Test loss:  1.5900949039900234\n",
            "BEST TEST LOSS:  1.5758875649788475\n",
            "Epoch 23: | Loss: 1.37985 | Acc: 0.469\n",
            "Test acc:  38.540437505673054\n",
            "Test loss:  1.6012034498887255\n",
            "Early stopping at epoch 24\n",
            "BEST TEST LOSS:  1.5758875649788475\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.80418 | Acc: 0.260\n",
            "Test acc:  28.682944540255967\n",
            "Test loss:  1.7600724876271507\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7600724876271507\n",
            "Epoch 1: | Loss: 1.75773 | Acc: 0.288\n",
            "Test acc:  28.89171280747935\n",
            "Test loss:  1.7479931054087732\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7479931054087732\n",
            "Epoch 2: | Loss: 1.73601 | Acc: 0.300\n",
            "Test acc:  30.51647453934828\n",
            "Test loss:  1.729094678266889\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.729094678266889\n",
            "Epoch 3: | Loss: 1.71883 | Acc: 0.310\n",
            "Test acc:  31.442316420078058\n",
            "Test loss:  1.7124055568882495\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7124055568882495\n",
            "Epoch 4: | Loss: 1.69508 | Acc: 0.324\n",
            "Test acc:  32.604157211582105\n",
            "Test loss:  1.695893716260877\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.695893716260877\n",
            "Epoch 5: | Loss: 1.66760 | Acc: 0.339\n",
            "Test acc:  34.19261141871653\n",
            "Test loss:  1.6738119876453643\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6738119876453643\n",
            "Epoch 6: | Loss: 1.64891 | Acc: 0.351\n",
            "Test acc:  34.23799582463465\n",
            "Test loss:  1.6591680270398972\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6591680270398972\n",
            "Epoch 7: | Loss: 1.62304 | Acc: 0.363\n",
            "Test acc:  35.29999092311882\n",
            "Test loss:  1.6352958927264791\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6352958927264791\n",
            "Epoch 8: | Loss: 1.59911 | Acc: 0.377\n",
            "Test acc:  36.489062358173726\n",
            "Test loss:  1.6346294245967976\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6346294245967976\n",
            "Epoch 9: | Loss: 1.57991 | Acc: 0.384\n",
            "Test acc:  36.38921666515385\n",
            "Test loss:  1.6236389778942042\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6236389778942042\n",
            "Epoch 10: | Loss: 1.56575 | Acc: 0.389\n",
            "Test acc:  36.73413815013161\n",
            "Test loss:  1.6218253560148912\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6218253560148912\n",
            "Epoch 11: | Loss: 1.54140 | Acc: 0.398\n",
            "Test acc:  37.54198057547426\n",
            "Test loss:  1.6210330676481215\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6210330676481215\n",
            "Epoch 12: | Loss: 1.53117 | Acc: 0.407\n",
            "Test acc:  38.540437505673054\n",
            "Test loss:  1.5941272622588052\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5941272622588052\n",
            "Epoch 13: | Loss: 1.51225 | Acc: 0.413\n",
            "Test acc:  38.83997458473269\n",
            "Test loss:  1.5952733300324808\n",
            "BEST TEST LOSS:  1.5941272622588052\n",
            "Epoch 14: | Loss: 1.49406 | Acc: 0.422\n",
            "Test acc:  38.785513297630935\n",
            "Test loss:  1.5868914726841656\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5868914726841656\n",
            "Epoch 15: | Loss: 1.47857 | Acc: 0.426\n",
            "Test acc:  38.13197785240991\n",
            "Test loss:  1.598043554780111\n",
            "BEST TEST LOSS:  1.5868914726841656\n",
            "Epoch 16: | Loss: 1.46315 | Acc: 0.436\n",
            "Test acc:  38.45874557502042\n",
            "Test loss:  1.6013097804405785\n",
            "BEST TEST LOSS:  1.5868914726841656\n",
            "Epoch 17: | Loss: 1.44510 | Acc: 0.443\n",
            "Test acc:  38.095670327675414\n",
            "Test loss:  1.6102571639022387\n",
            "Early stopping at epoch 18\n",
            "BEST TEST LOSS:  1.5868914726841656\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.80183 | Acc: 0.264\n",
            "Test acc:  28.39248434237996\n",
            "Test loss:  1.7664219478651277\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7664219478651277\n",
            "Epoch 1: | Loss: 1.76030 | Acc: 0.283\n",
            "Test acc:  29.091404193519104\n",
            "Test loss:  1.7496319823182387\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7496319823182387\n",
            "Epoch 2: | Loss: 1.73770 | Acc: 0.293\n",
            "Test acc:  30.943087954978672\n",
            "Test loss:  1.7259131924954454\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7259131924954454\n",
            "Epoch 3: | Loss: 1.71239 | Acc: 0.314\n",
            "Test acc:  32.66769537986748\n",
            "Test loss:  1.689052503922082\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.689052503922082\n",
            "Epoch 4: | Loss: 1.66980 | Acc: 0.336\n",
            "Test acc:  33.64799854769901\n",
            "Test loss:  1.668064417177542\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.668064417177542\n",
            "Epoch 5: | Loss: 1.64507 | Acc: 0.351\n",
            "Test acc:  35.76291186348371\n",
            "Test loss:  1.6355895120973531\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6355895120973531\n",
            "Epoch 6: | Loss: 1.61060 | Acc: 0.371\n",
            "Test acc:  36.69783062539712\n",
            "Test loss:  1.621001757638303\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.621001757638303\n",
            "Epoch 7: | Loss: 1.58949 | Acc: 0.383\n",
            "Test acc:  37.278751021149134\n",
            "Test loss:  1.6057578277036635\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6057578277036635\n",
            "Epoch 8: | Loss: 1.56531 | Acc: 0.390\n",
            "Test acc:  38.62212943632568\n",
            "Test loss:  1.5922871276822392\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5922871276822392\n",
            "Epoch 9: | Loss: 1.54236 | Acc: 0.401\n",
            "Test acc:  38.985204683670695\n",
            "Test loss:  1.5797686735329601\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5797686735329601\n",
            "Epoch 10: | Loss: 1.52632 | Acc: 0.406\n",
            "Test acc:  38.96705092130344\n",
            "Test loss:  1.5819464467164408\n",
            "BEST TEST LOSS:  1.5797686735329601\n",
            "Epoch 11: | Loss: 1.50530 | Acc: 0.413\n",
            "Test acc:  38.74012889171281\n",
            "Test loss:  1.5778712571700872\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5778712571700872\n",
            "Epoch 12: | Loss: 1.49224 | Acc: 0.422\n",
            "Test acc:  39.51166379232096\n",
            "Test loss:  1.5646603217703758\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5646603217703758\n",
            "Epoch 13: | Loss: 1.47629 | Acc: 0.425\n",
            "Test acc:  39.747662703095216\n",
            "Test loss:  1.566963554117721\n",
            "BEST TEST LOSS:  1.5646603217703758\n",
            "Epoch 14: | Loss: 1.46366 | Acc: 0.434\n",
            "Test acc:  40.52827448488699\n",
            "Test loss:  1.5468555943814317\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5468555943814317\n",
            "Epoch 15: | Loss: 1.44040 | Acc: 0.443\n",
            "Test acc:  40.41935191068349\n",
            "Test loss:  1.5566339892459053\n",
            "BEST TEST LOSS:  1.5468555943814317\n",
            "Epoch 16: | Loss: 1.43011 | Acc: 0.444\n",
            "Test acc:  40.410275029499864\n",
            "Test loss:  1.5686553172293427\n",
            "BEST TEST LOSS:  1.5468555943814317\n",
            "Epoch 17: | Loss: 1.40909 | Acc: 0.456\n",
            "Test acc:  40.14704547517473\n",
            "Test loss:  1.5781672214497031\n",
            "Early stopping at epoch 18\n",
            "BEST TEST LOSS:  1.5468555943814317\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.89977 | Acc: 0.208\n",
            "Test acc:  23.037124444041027\n",
            "Test loss:  1.8509807579779212\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8509807579779212\n",
            "Epoch 1: | Loss: 1.83494 | Acc: 0.240\n",
            "Test acc:  24.825270037215212\n",
            "Test loss:  1.8212183527863783\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8212183527863783\n",
            "Epoch 2: | Loss: 1.81254 | Acc: 0.258\n",
            "Test acc:  25.50603612598711\n",
            "Test loss:  1.8085199084585113\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8085199084585113\n",
            "Epoch 3: | Loss: 1.80449 | Acc: 0.266\n",
            "Test acc:  26.513569937369518\n",
            "Test loss:  1.7927564499695177\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7927564499695177\n",
            "Epoch 4: | Loss: 1.79363 | Acc: 0.274\n",
            "Test acc:  27.348643006263046\n",
            "Test loss:  1.7863730874364776\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7863730874364776\n",
            "Epoch 5: | Loss: 1.78387 | Acc: 0.278\n",
            "Test acc:  27.375873649813926\n",
            "Test loss:  1.7861349541327858\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7861349541327858\n",
            "Epoch 6: | Loss: 1.77926 | Acc: 0.278\n",
            "Test acc:  27.82971770899519\n",
            "Test loss:  1.7808115751068028\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7808115751068028\n",
            "Epoch 7: | Loss: 1.77034 | Acc: 0.283\n",
            "Test acc:  27.775256421893435\n",
            "Test loss:  1.7723041807295958\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7723041807295958\n",
            "Epoch 8: | Loss: 1.76735 | Acc: 0.289\n",
            "Test acc:  28.29263864936008\n",
            "Test loss:  1.7721822103323963\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7721822103323963\n",
            "Epoch 9: | Loss: 1.76253 | Acc: 0.290\n",
            "Test acc:  28.301715530543703\n",
            "Test loss:  1.7666640488398557\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7666640488398557\n",
            "Epoch 10: | Loss: 1.75849 | Acc: 0.291\n",
            "Test acc:  28.347099936461834\n",
            "Test loss:  1.765426044519237\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.765426044519237\n",
            "Epoch 11: | Loss: 1.75453 | Acc: 0.294\n",
            "Test acc:  28.283561768176458\n",
            "Test loss:  1.7608057391436802\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7608057391436802\n",
            "Epoch 12: | Loss: 1.75254 | Acc: 0.295\n",
            "Test acc:  28.564945084868835\n",
            "Test loss:  1.7590737942326276\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7590737942326276\n",
            "Epoch 13: | Loss: 1.74831 | Acc: 0.299\n",
            "Test acc:  29.06417354996823\n",
            "Test loss:  1.7540748829097417\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7540748829097417\n",
            "Epoch 14: | Loss: 1.74627 | Acc: 0.300\n",
            "Test acc:  28.982481619315603\n",
            "Test loss:  1.7565570484007025\n",
            "BEST TEST LOSS:  1.7540748829097417\n",
            "Epoch 15: | Loss: 1.73937 | Acc: 0.300\n",
            "Test acc:  29.191249886538984\n",
            "Test loss:  1.7511555149376048\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7511555149376048\n",
            "Epoch 16: | Loss: 1.73765 | Acc: 0.306\n",
            "Test acc:  29.082327312335483\n",
            "Test loss:  1.7517919774689426\n",
            "BEST TEST LOSS:  1.7511555149376048\n",
            "Epoch 17: | Loss: 1.73275 | Acc: 0.304\n",
            "Test acc:  29.082327312335483\n",
            "Test loss:  1.7503333229550047\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7503333229550047\n",
            "Epoch 18: | Loss: 1.73072 | Acc: 0.305\n",
            "Test acc:  29.50894072796587\n",
            "Test loss:  1.7481409070119693\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7481409070119693\n",
            "Epoch 19: | Loss: 1.73098 | Acc: 0.308\n",
            "Test acc:  29.84478533176001\n",
            "Test loss:  1.7435214044041716\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7435214044041716\n",
            "Epoch 20: | Loss: 1.72600 | Acc: 0.313\n",
            "Test acc:  29.64509394572025\n",
            "Test loss:  1.7425270301069138\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7425270301069138\n",
            "Epoch 21: | Loss: 1.72478 | Acc: 0.307\n",
            "Test acc:  30.425705727512025\n",
            "Test loss:  1.74047438602227\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.74047438602227\n",
            "Epoch 22: | Loss: 1.72019 | Acc: 0.314\n",
            "Test acc:  29.40909503494599\n",
            "Test loss:  1.7424580534069525\n",
            "BEST TEST LOSS:  1.74047438602227\n",
            "Epoch 23: | Loss: 1.71854 | Acc: 0.317\n",
            "Test acc:  30.2713987473904\n",
            "Test loss:  1.739261051822949\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.739261051822949\n",
            "Epoch 24: | Loss: 1.71481 | Acc: 0.316\n",
            "Test acc:  30.507397658164653\n",
            "Test loss:  1.7366116405222458\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7366116405222458\n",
            "Epoch 25: | Loss: 1.71158 | Acc: 0.317\n",
            "Test acc:  30.48016701461378\n",
            "Test loss:  1.7300441271996911\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7300441271996911\n",
            "Epoch 26: | Loss: 1.71200 | Acc: 0.319\n",
            "Test acc:  30.861396024326044\n",
            "Test loss:  1.7336964228249698\n",
            "BEST TEST LOSS:  1.7300441271996911\n",
            "Epoch 27: | Loss: 1.70861 | Acc: 0.319\n",
            "Test acc:  30.761550331306164\n",
            "Test loss:  1.729980451523224\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.729980451523224\n",
            "Epoch 28: | Loss: 1.70226 | Acc: 0.326\n",
            "Test acc:  31.088318053916673\n",
            "Test loss:  1.725693192785186\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.725693192785186\n",
            "Epoch 29: | Loss: 1.69918 | Acc: 0.328\n",
            "Test acc:  30.56185894526641\n",
            "Test loss:  1.7281104753472212\n",
            "BEST TEST LOSS:  1.725693192785186\n",
            "Epoch 30: | Loss: 1.69617 | Acc: 0.326\n",
            "Test acc:  31.333393845874557\n",
            "Test loss:  1.725657239125643\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.725657239125643\n",
            "Epoch 31: | Loss: 1.69589 | Acc: 0.329\n",
            "Test acc:  30.334936915675776\n",
            "Test loss:  1.7246274713835965\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7246274713835965\n",
            "Epoch 32: | Loss: 1.69059 | Acc: 0.332\n",
            "Test acc:  31.206317509303805\n",
            "Test loss:  1.7228536805665562\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7228536805665562\n",
            "Epoch 33: | Loss: 1.68861 | Acc: 0.335\n",
            "Test acc:  31.415085776527185\n",
            "Test loss:  1.7193506060308115\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7193506060308115\n",
            "Epoch 34: | Loss: 1.68430 | Acc: 0.336\n",
            "Test acc:  31.288009439956433\n",
            "Test loss:  1.7173919119586833\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7173919119586833\n",
            "Epoch 35: | Loss: 1.67893 | Acc: 0.340\n",
            "Test acc:  32.28646637015522\n",
            "Test loss:  1.7164020607237183\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7164020607237183\n",
            "Epoch 36: | Loss: 1.67761 | Acc: 0.341\n",
            "Test acc:  31.805391667423073\n",
            "Test loss:  1.715945001282444\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.715945001282444\n",
            "Epoch 37: | Loss: 1.67439 | Acc: 0.342\n",
            "Test acc:  31.569392756648817\n",
            "Test loss:  1.7118210137924017\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7118210137924017\n",
            "Epoch 38: | Loss: 1.67261 | Acc: 0.344\n",
            "Test acc:  31.56031587546519\n",
            "Test loss:  1.7104922264297573\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7104922264297573\n",
            "Epoch 39: | Loss: 1.66797 | Acc: 0.345\n",
            "Test acc:  32.159390033584465\n",
            "Test loss:  1.7075308561325073\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7075308561325073\n",
            "Epoch 40: | Loss: 1.66443 | Acc: 0.343\n",
            "Test acc:  32.4589271126441\n",
            "Test loss:  1.698925914102896\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.698925914102896\n",
            "Epoch 41: | Loss: 1.66216 | Acc: 0.348\n",
            "Test acc:  32.694926023418354\n",
            "Test loss:  1.701529750245155\n",
            "BEST TEST LOSS:  1.698925914102896\n",
            "Epoch 42: | Loss: 1.65887 | Acc: 0.351\n",
            "Test acc:  32.6767722610511\n",
            "Test loss:  1.6964804278632808\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6964804278632808\n",
            "Epoch 43: | Loss: 1.65571 | Acc: 0.354\n",
            "Test acc:  32.694926023418354\n",
            "Test loss:  1.7009650530842688\n",
            "BEST TEST LOSS:  1.6964804278632808\n",
            "Epoch 44: | Loss: 1.64874 | Acc: 0.357\n",
            "Test acc:  32.940001815376235\n",
            "Test loss:  1.69565139685063\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.69565139685063\n",
            "Epoch 45: | Loss: 1.64793 | Acc: 0.357\n",
            "Test acc:  33.384768993373875\n",
            "Test loss:  1.6946379973020167\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6946379973020167\n",
            "Epoch 46: | Loss: 1.64244 | Acc: 0.355\n",
            "Test acc:  33.59353726059726\n",
            "Test loss:  1.6918230773396574\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6918230773396574\n",
            "Epoch 47: | Loss: 1.63921 | Acc: 0.361\n",
            "Test acc:  33.55722973586276\n",
            "Test loss:  1.6817387494048632\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6817387494048632\n",
            "Epoch 48: | Loss: 1.63332 | Acc: 0.365\n",
            "Test acc:  33.51184532994463\n",
            "Test loss:  1.687836529891615\n",
            "BEST TEST LOSS:  1.6817387494048632\n",
            "Epoch 49: | Loss: 1.63097 | Acc: 0.367\n",
            "Test acc:  33.77507488426976\n",
            "Test loss:  1.6823199325903302\n",
            "BEST TEST LOSS:  1.6817387494048632\n",
            "Epoch 50: | Loss: 1.62722 | Acc: 0.367\n",
            "Test acc:  33.938458745575026\n",
            "Test loss:  1.6788801533638398\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6788801533638398\n",
            "Epoch 51: | Loss: 1.62363 | Acc: 0.370\n",
            "Test acc:  33.70245983480076\n",
            "Test loss:  1.677143710886123\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.677143710886123\n",
            "Epoch 52: | Loss: 1.61956 | Acc: 0.370\n",
            "Test acc:  33.78415176545339\n",
            "Test loss:  1.68218623006964\n",
            "BEST TEST LOSS:  1.677143710886123\n",
            "Epoch 53: | Loss: 1.61761 | Acc: 0.372\n",
            "Test acc:  33.92030498320777\n",
            "Test loss:  1.6748776690808336\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6748776690808336\n",
            "Epoch 54: | Loss: 1.61246 | Acc: 0.377\n",
            "Test acc:  34.70999364618317\n",
            "Test loss:  1.6742149701697289\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6742149701697289\n",
            "Epoch 55: | Loss: 1.60916 | Acc: 0.374\n",
            "Test acc:  34.1109194880639\n",
            "Test loss:  1.6712299220134756\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6712299220134756\n",
            "Epoch 56: | Loss: 1.60490 | Acc: 0.377\n",
            "Test acc:  34.519379141327036\n",
            "Test loss:  1.6718114056339153\n",
            "BEST TEST LOSS:  1.6712299220134756\n",
            "Epoch 57: | Loss: 1.59990 | Acc: 0.381\n",
            "Test acc:  34.59199419079604\n",
            "Test loss:  1.6649345504066158\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6649345504066158\n",
            "Epoch 58: | Loss: 1.60109 | Acc: 0.380\n",
            "Test acc:  34.573840428428795\n",
            "Test loss:  1.666155254220687\n",
            "BEST TEST LOSS:  1.6649345504066158\n",
            "Epoch 59: | Loss: 1.59456 | Acc: 0.380\n",
            "Test acc:  34.22891894345103\n",
            "Test loss:  1.669343227595952\n",
            "BEST TEST LOSS:  1.6649345504066158\n",
            "Epoch 60: | Loss: 1.59270 | Acc: 0.387\n",
            "Test acc:  35.31814468548607\n",
            "Test loss:  1.6601577507967205\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6601577507967205\n",
            "Epoch 61: | Loss: 1.58676 | Acc: 0.387\n",
            "Test acc:  35.009530725242804\n",
            "Test loss:  1.6618140653378701\n",
            "BEST TEST LOSS:  1.6601577507967205\n",
            "Epoch 62: | Loss: 1.58486 | Acc: 0.390\n",
            "Test acc:  35.29999092311882\n",
            "Test loss:  1.6598948350531517\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6598948350531517\n",
            "Epoch 63: | Loss: 1.58278 | Acc: 0.391\n",
            "Test acc:  35.653989289280204\n",
            "Test loss:  1.6556316855325863\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6556316855325863\n",
            "Epoch 64: | Loss: 1.57446 | Acc: 0.391\n",
            "Test acc:  34.77353181446855\n",
            "Test loss:  1.6562431899109327\n",
            "BEST TEST LOSS:  1.6556316855325863\n",
            "Epoch 65: | Loss: 1.57271 | Acc: 0.393\n",
            "Test acc:  35.236452754833444\n",
            "Test loss:  1.6620411238918416\n",
            "BEST TEST LOSS:  1.6556316855325863\n",
            "Epoch 66: | Loss: 1.57010 | Acc: 0.398\n",
            "Test acc:  35.309067804302444\n",
            "Test loss:  1.656316460212531\n",
            "Early stopping at epoch 67\n",
            "BEST TEST LOSS:  1.6556316855325863\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.86541 | Acc: 0.232\n",
            "Test acc:  24.988653898520468\n",
            "Test loss:  1.8218129907729308\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8218129907729308\n",
            "Epoch 1: | Loss: 1.80815 | Acc: 0.265\n",
            "Test acc:  26.359262957247893\n",
            "Test loss:  1.800382738168529\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.800382738168529\n",
            "Epoch 2: | Loss: 1.78957 | Acc: 0.270\n",
            "Test acc:  26.876645184714533\n",
            "Test loss:  1.7891097137693726\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7891097137693726\n",
            "Epoch 3: | Loss: 1.78114 | Acc: 0.274\n",
            "Test acc:  27.62094944177181\n",
            "Test loss:  1.7775907316648891\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7775907316648891\n",
            "Epoch 4: | Loss: 1.77116 | Acc: 0.277\n",
            "Test acc:  27.775256421893435\n",
            "Test loss:  1.7753295967344604\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7753295967344604\n",
            "Epoch 5: | Loss: 1.76157 | Acc: 0.290\n",
            "Test acc:  28.092947263320323\n",
            "Test loss:  1.7706453090458247\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7706453090458247\n",
            "Epoch 6: | Loss: 1.75994 | Acc: 0.287\n",
            "Test acc:  28.338023055278207\n",
            "Test loss:  1.7615372307727792\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7615372307727792\n",
            "Epoch 7: | Loss: 1.75063 | Acc: 0.293\n",
            "Test acc:  28.673867659072343\n",
            "Test loss:  1.7577778025169593\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7577778025169593\n",
            "Epoch 8: | Loss: 1.74644 | Acc: 0.296\n",
            "Test acc:  28.846328401561223\n",
            "Test loss:  1.7569626404370875\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7569626404370875\n",
            "Epoch 9: | Loss: 1.74073 | Acc: 0.298\n",
            "Test acc:  29.27294181719161\n",
            "Test loss:  1.753473290129204\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.753473290129204\n",
            "Epoch 10: | Loss: 1.73862 | Acc: 0.299\n",
            "Test acc:  29.263864936007987\n",
            "Test loss:  1.7481688047420083\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7481688047420083\n",
            "Epoch 11: | Loss: 1.73292 | Acc: 0.306\n",
            "Test acc:  29.472633203231368\n",
            "Test loss:  1.7468911629880783\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7468911629880783\n",
            "Epoch 12: | Loss: 1.72466 | Acc: 0.309\n",
            "Test acc:  29.245711173640736\n",
            "Test loss:  1.7417279096008036\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7417279096008036\n",
            "Epoch 13: | Loss: 1.72030 | Acc: 0.309\n",
            "Test acc:  29.772170282291004\n",
            "Test loss:  1.7384269926589349\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7384269926589349\n",
            "Epoch 14: | Loss: 1.71750 | Acc: 0.314\n",
            "Test acc:  29.690478351638376\n",
            "Test loss:  1.738301905593431\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.738301905593431\n",
            "Epoch 15: | Loss: 1.71095 | Acc: 0.316\n",
            "Test acc:  30.108014886085144\n",
            "Test loss:  1.7324743305327575\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7324743305327575\n",
            "Epoch 16: | Loss: 1.70795 | Acc: 0.318\n",
            "Test acc:  30.4892438957974\n",
            "Test loss:  1.7303235592869666\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7303235592869666\n",
            "Epoch 17: | Loss: 1.70523 | Acc: 0.322\n",
            "Test acc:  30.69801216302079\n",
            "Test loss:  1.729661572875315\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.729661572875315\n",
            "Epoch 18: | Loss: 1.69725 | Acc: 0.323\n",
            "Test acc:  31.433239538894437\n",
            "Test loss:  1.7210240508779624\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7210240508779624\n",
            "Epoch 19: | Loss: 1.69304 | Acc: 0.324\n",
            "Test acc:  31.14277934101843\n",
            "Test loss:  1.717430264274509\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.717430264274509\n",
            "Epoch 20: | Loss: 1.68652 | Acc: 0.332\n",
            "Test acc:  31.71462285558682\n",
            "Test loss:  1.713249574506903\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.713249574506903\n",
            "Epoch 21: | Loss: 1.68322 | Acc: 0.333\n",
            "Test acc:  32.01415993464646\n",
            "Test loss:  1.7115263842433863\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7115263842433863\n",
            "Epoch 22: | Loss: 1.67834 | Acc: 0.336\n",
            "Test acc:  32.17754379595171\n",
            "Test loss:  1.7087192569853942\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7087192569853942\n",
            "Epoch 23: | Loss: 1.67067 | Acc: 0.341\n",
            "Test acc:  31.996006172279206\n",
            "Test loss:  1.7098522110481482\n",
            "BEST TEST LOSS:  1.7087192569853942\n",
            "Epoch 24: | Loss: 1.66748 | Acc: 0.343\n",
            "Test acc:  32.5315421621131\n",
            "Test loss:  1.7008148790094895\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7008148790094895\n",
            "Epoch 25: | Loss: 1.65648 | Acc: 0.349\n",
            "Test acc:  32.46800399382772\n",
            "Test loss:  1.697051020715967\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.697051020715967\n",
            "Epoch 26: | Loss: 1.65407 | Acc: 0.350\n",
            "Test acc:  33.139693201415994\n",
            "Test loss:  1.6909922719690842\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6909922719690842\n",
            "Epoch 27: | Loss: 1.64995 | Acc: 0.354\n",
            "Test acc:  33.52999909231188\n",
            "Test loss:  1.6939553987084097\n",
            "BEST TEST LOSS:  1.6909922719690842\n",
            "Epoch 28: | Loss: 1.64170 | Acc: 0.356\n",
            "Test acc:  32.949078696559866\n",
            "Test loss:  1.692326092306589\n",
            "BEST TEST LOSS:  1.6909922719690842\n",
            "Epoch 29: | Loss: 1.63675 | Acc: 0.358\n",
            "Test acc:  33.43923028047563\n",
            "Test loss:  1.6851125335417731\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6851125335417731\n",
            "Epoch 30: | Loss: 1.63673 | Acc: 0.357\n",
            "Test acc:  33.85676681492239\n",
            "Test loss:  1.6888944703030448\n",
            "BEST TEST LOSS:  1.6851125335417731\n",
            "Epoch 31: | Loss: 1.62775 | Acc: 0.364\n",
            "Test acc:  33.61169102296451\n",
            "Test loss:  1.6775773715421645\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6775773715421645\n",
            "Epoch 32: | Loss: 1.62302 | Acc: 0.368\n",
            "Test acc:  33.756921121902515\n",
            "Test loss:  1.678258869000253\n",
            "BEST TEST LOSS:  1.6775773715421645\n",
            "Epoch 33: | Loss: 1.61657 | Acc: 0.371\n",
            "Test acc:  34.43768721067441\n",
            "Test loss:  1.6740101320895155\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6740101320895155\n",
            "Epoch 34: | Loss: 1.61370 | Acc: 0.369\n",
            "Test acc:  34.392302804756284\n",
            "Test loss:  1.6691585572468752\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6691585572468752\n",
            "Epoch 35: | Loss: 1.60989 | Acc: 0.374\n",
            "Test acc:  34.19261141871653\n",
            "Test loss:  1.6727210241935158\n",
            "BEST TEST LOSS:  1.6691585572468752\n",
            "Epoch 36: | Loss: 1.60610 | Acc: 0.377\n",
            "Test acc:  34.546609784877916\n",
            "Test loss:  1.677309619898052\n",
            "BEST TEST LOSS:  1.6691585572468752\n",
            "Epoch 37: | Loss: 1.59828 | Acc: 0.378\n",
            "Test acc:  34.31061087410366\n",
            "Test loss:  1.6711709265074979\n",
            "Early stopping at epoch 38\n",
            "BEST TEST LOSS:  1.6691585572468752\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.84827 | Acc: 0.238\n",
            "Test acc:  26.459108650267765\n",
            "Test loss:  1.8001809044380408\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8001809044380408\n",
            "Epoch 1: | Loss: 1.79005 | Acc: 0.269\n",
            "Test acc:  27.59371879822093\n",
            "Test loss:  1.7759542017313785\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7759542017313785\n",
            "Epoch 2: | Loss: 1.77336 | Acc: 0.278\n",
            "Test acc:  28.583098847236087\n",
            "Test loss:  1.765235695535737\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.765235695535737\n",
            "Epoch 3: | Loss: 1.76165 | Acc: 0.286\n",
            "Test acc:  29.055096668784607\n",
            "Test loss:  1.759737091257393\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.759737091257393\n",
            "Epoch 4: | Loss: 1.75164 | Acc: 0.294\n",
            "Test acc:  29.154942361804487\n",
            "Test loss:  1.7535506617816197\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7535506617816197\n",
            "Epoch 5: | Loss: 1.74439 | Acc: 0.299\n",
            "Test acc:  29.790324044658256\n",
            "Test loss:  1.7448665020782823\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7448665020782823\n",
            "Epoch 6: | Loss: 1.73217 | Acc: 0.304\n",
            "Test acc:  30.316783153308524\n",
            "Test loss:  1.7420810171634475\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7420810171634475\n",
            "Epoch 7: | Loss: 1.72538 | Acc: 0.310\n",
            "Test acc:  30.888626667876917\n",
            "Test loss:  1.733869159841813\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.733869159841813\n",
            "Epoch 8: | Loss: 1.71905 | Acc: 0.313\n",
            "Test acc:  30.816011618407913\n",
            "Test loss:  1.7278897555577273\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7278897555577273\n",
            "Epoch 9: | Loss: 1.70844 | Acc: 0.320\n",
            "Test acc:  31.78723790505582\n",
            "Test loss:  1.7155788447815559\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7155788447815559\n",
            "Epoch 10: | Loss: 1.70092 | Acc: 0.327\n",
            "Test acc:  31.723699736770445\n",
            "Test loss:  1.7089409056426472\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7089409056426472\n",
            "Epoch 11: | Loss: 1.69147 | Acc: 0.330\n",
            "Test acc:  32.07769810293183\n",
            "Test loss:  1.704747729907835\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.704747729907835\n",
            "Epoch 12: | Loss: 1.67956 | Acc: 0.334\n",
            "Test acc:  32.31369701370609\n",
            "Test loss:  1.6967558468008317\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6967558468008317\n",
            "Epoch 13: | Loss: 1.66686 | Acc: 0.342\n",
            "Test acc:  32.967232458927114\n",
            "Test loss:  1.6919068380587363\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6919068380587363\n",
            "Epoch 14: | Loss: 1.65777 | Acc: 0.349\n",
            "Test acc:  33.47553780521013\n",
            "Test loss:  1.6859315365036098\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6859315365036098\n",
            "Epoch 15: | Loss: 1.64687 | Acc: 0.352\n",
            "Test acc:  34.546609784877916\n",
            "Test loss:  1.667176369297711\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.667176369297711\n",
            "Epoch 16: | Loss: 1.63609 | Acc: 0.357\n",
            "Test acc:  34.50122537895979\n",
            "Test loss:  1.6636096562953353\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6636096562953353\n",
            "Epoch 17: | Loss: 1.62727 | Acc: 0.364\n",
            "Test acc:  35.136607061813564\n",
            "Test loss:  1.6638174622045088\n",
            "BEST TEST LOSS:  1.6636096562953353\n",
            "Epoch 18: | Loss: 1.61864 | Acc: 0.367\n",
            "Test acc:  34.7916855768358\n",
            "Test loss:  1.6562427647541025\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6562427647541025\n",
            "Epoch 19: | Loss: 1.60464 | Acc: 0.374\n",
            "Test acc:  35.381682853771444\n",
            "Test loss:  1.6528950564434073\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6528950564434073\n",
            "Epoch 20: | Loss: 1.59507 | Acc: 0.378\n",
            "Test acc:  35.19106834891531\n",
            "Test loss:  1.6448677488834182\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6448677488834182\n",
            "Epoch 21: | Loss: 1.59001 | Acc: 0.383\n",
            "Test acc:  35.49060542797495\n",
            "Test loss:  1.6450007568205023\n",
            "BEST TEST LOSS:  1.6448677488834182\n",
            "Epoch 22: | Loss: 1.57843 | Acc: 0.386\n",
            "Test acc:  35.826450031769085\n",
            "Test loss:  1.6467639717752534\n",
            "BEST TEST LOSS:  1.6448677488834182\n",
            "Epoch 23: | Loss: 1.56820 | Acc: 0.395\n",
            "Test acc:  36.00798765544159\n",
            "Test loss:  1.6339597247239481\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6339597247239481\n",
            "Epoch 24: | Loss: 1.56350 | Acc: 0.393\n",
            "Test acc:  36.443677952255605\n",
            "Test loss:  1.6320295581927877\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6320295581927877\n",
            "Epoch 25: | Loss: 1.55262 | Acc: 0.396\n",
            "Test acc:  37.178905328129254\n",
            "Test loss:  1.621425532881235\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.621425532881235\n",
            "Epoch 26: | Loss: 1.54050 | Acc: 0.407\n",
            "Test acc:  36.38013978397023\n",
            "Test loss:  1.6267251389564117\n",
            "BEST TEST LOSS:  1.621425532881235\n",
            "Epoch 27: | Loss: 1.52980 | Acc: 0.411\n",
            "Test acc:  37.14259780339476\n",
            "Test loss:  1.6168379280608514\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6168379280608514\n",
            "Epoch 28: | Loss: 1.52299 | Acc: 0.413\n",
            "Test acc:  37.015521466824\n",
            "Test loss:  1.6171917260726751\n",
            "BEST TEST LOSS:  1.6168379280608514\n",
            "Epoch 29: | Loss: 1.51692 | Acc: 0.414\n",
            "Test acc:  37.10629027866025\n",
            "Test loss:  1.6201298967262223\n",
            "BEST TEST LOSS:  1.6168379280608514\n",
            "Epoch 30: | Loss: 1.50456 | Acc: 0.418\n",
            "Test acc:  37.31505854588363\n",
            "Test loss:  1.6164751411173386\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6164751411173386\n",
            "Epoch 31: | Loss: 1.50018 | Acc: 0.423\n",
            "Test acc:  37.14259780339476\n",
            "Test loss:  1.6109715279816204\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6109715279816204\n",
            "Epoch 32: | Loss: 1.49379 | Acc: 0.426\n",
            "Test acc:  36.87029136788599\n",
            "Test loss:  1.6227663610711953\n",
            "BEST TEST LOSS:  1.6109715279816204\n",
            "Epoch 33: | Loss: 1.48045 | Acc: 0.431\n",
            "Test acc:  37.88690206045203\n",
            "Test loss:  1.6111086041941118\n",
            "BEST TEST LOSS:  1.6109715279816204\n",
            "Epoch 34: | Loss: 1.47513 | Acc: 0.432\n",
            "Test acc:  37.78705636743215\n",
            "Test loss:  1.612672519821652\n",
            "Early stopping at epoch 35\n",
            "BEST TEST LOSS:  1.6109715279816204\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.80288 | Acc: 0.264\n",
            "Test acc:  28.319869292910955\n",
            "Test loss:  1.7679576859997876\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7679576859997876\n",
            "Epoch 1: | Loss: 1.76711 | Acc: 0.279\n",
            "Test acc:  29.481710084414996\n",
            "Test loss:  1.7511448667228566\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7511448667228566\n",
            "Epoch 2: | Loss: 1.73800 | Acc: 0.300\n",
            "Test acc:  31.197240628120177\n",
            "Test loss:  1.7088894237672663\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7088894237672663\n",
            "Epoch 3: | Loss: 1.69997 | Acc: 0.321\n",
            "Test acc:  34.21076518108378\n",
            "Test loss:  1.6809463418288038\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6809463418288038\n",
            "Epoch 4: | Loss: 1.67633 | Acc: 0.333\n",
            "Test acc:  33.829536171371515\n",
            "Test loss:  1.6634572165549835\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6634572165549835\n",
            "Epoch 5: | Loss: 1.64604 | Acc: 0.351\n",
            "Test acc:  35.18199146773169\n",
            "Test loss:  1.6391565655008218\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6391565655008218\n",
            "Epoch 6: | Loss: 1.62130 | Acc: 0.364\n",
            "Test acc:  35.136607061813564\n",
            "Test loss:  1.6379929574238772\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6379929574238772\n",
            "Epoch 7: | Loss: 1.61548 | Acc: 0.366\n",
            "Test acc:  35.354452210220565\n",
            "Test loss:  1.6455366459885084\n",
            "BEST TEST LOSS:  1.6379929574238772\n",
            "Epoch 8: | Loss: 1.59594 | Acc: 0.378\n",
            "Test acc:  37.405827357719886\n",
            "Test loss:  1.6131484384481618\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6131484384481618\n",
            "Epoch 9: | Loss: 1.57305 | Acc: 0.387\n",
            "Test acc:  37.650903149677774\n",
            "Test loss:  1.6124227198562182\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6124227198562182\n",
            "Epoch 10: | Loss: 1.55782 | Acc: 0.390\n",
            "Test acc:  38.10474720885904\n",
            "Test loss:  1.5917176745530497\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5917176745530497\n",
            "Epoch 11: | Loss: 1.54299 | Acc: 0.401\n",
            "Test acc:  37.9867477534719\n",
            "Test loss:  1.5875285023209678\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5875285023209678\n",
            "Epoch 12: | Loss: 1.52860 | Acc: 0.400\n",
            "Test acc:  38.585821911591175\n",
            "Test loss:  1.591066363229917\n",
            "BEST TEST LOSS:  1.5875285023209678\n",
            "Epoch 13: | Loss: 1.51317 | Acc: 0.410\n",
            "Test acc:  38.4859762185713\n",
            "Test loss:  1.6009527251899587\n",
            "BEST TEST LOSS:  1.5875285023209678\n",
            "Epoch 14: | Loss: 1.49554 | Acc: 0.421\n",
            "Test acc:  38.72197512934556\n",
            "Test loss:  1.5810575933125668\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5810575933125668\n",
            "Epoch 15: | Loss: 1.48106 | Acc: 0.423\n",
            "Test acc:  37.532903694290646\n",
            "Test loss:  1.6123459704349496\n",
            "BEST TEST LOSS:  1.5810575933125668\n",
            "Epoch 16: | Loss: 1.46253 | Acc: 0.431\n",
            "Test acc:  39.402741218117455\n",
            "Test loss:  1.5889983445922764\n",
            "BEST TEST LOSS:  1.5810575933125668\n",
            "Epoch 17: | Loss: 1.45220 | Acc: 0.437\n",
            "Test acc:  39.030589089588815\n",
            "Test loss:  1.5854586576450767\n",
            "Early stopping at epoch 18\n",
            "BEST TEST LOSS:  1.5810575933125668\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.81026 | Acc: 0.262\n",
            "Test acc:  26.804030135245533\n",
            "Test loss:  1.7850770592000442\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7850770592000442\n",
            "Epoch 1: | Loss: 1.78307 | Acc: 0.275\n",
            "Test acc:  28.229100481074703\n",
            "Test loss:  1.7829821399181565\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7829821399181565\n",
            "Epoch 2: | Loss: 1.76694 | Acc: 0.281\n",
            "Test acc:  28.147408550422075\n",
            "Test loss:  1.7672218766515655\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7672218766515655\n",
            "Epoch 3: | Loss: 1.74773 | Acc: 0.288\n",
            "Test acc:  29.463556322047747\n",
            "Test loss:  1.7390526905225192\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7390526905225192\n",
            "Epoch 4: | Loss: 1.72406 | Acc: 0.306\n",
            "Test acc:  31.278932558772805\n",
            "Test loss:  1.71135317383474\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.71135317383474\n",
            "Epoch 5: | Loss: 1.70024 | Acc: 0.325\n",
            "Test acc:  32.150313152400834\n",
            "Test loss:  1.709700798712714\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.709700798712714\n",
            "Epoch 6: | Loss: 1.68509 | Acc: 0.333\n",
            "Test acc:  33.73876735953527\n",
            "Test loss:  1.6804416648225289\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6804416648225289\n",
            "Epoch 7: | Loss: 1.65961 | Acc: 0.347\n",
            "Test acc:  35.236452754833444\n",
            "Test loss:  1.6531322512323456\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6531322512323456\n",
            "Epoch 8: | Loss: 1.64236 | Acc: 0.356\n",
            "Test acc:  33.33030770627213\n",
            "Test loss:  1.722493944140528\n",
            "BEST TEST LOSS:  1.6531322512323456\n",
            "Epoch 9: | Loss: 1.62592 | Acc: 0.362\n",
            "Test acc:  36.2621403285831\n",
            "Test loss:  1.6302948962746329\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6302948962746329\n",
            "Epoch 10: | Loss: 1.61324 | Acc: 0.370\n",
            "Test acc:  35.52691295270945\n",
            "Test loss:  1.64438885002467\n",
            "BEST TEST LOSS:  1.6302948962746329\n",
            "Epoch 11: | Loss: 1.60030 | Acc: 0.377\n",
            "Test acc:  35.29091404193519\n",
            "Test loss:  1.6499677496838432\n",
            "BEST TEST LOSS:  1.6302948962746329\n",
            "Epoch 12: | Loss: 1.58682 | Acc: 0.383\n",
            "Test acc:  37.30598166470001\n",
            "Test loss:  1.626524169321005\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.626524169321005\n",
            "Epoch 13: | Loss: 1.56863 | Acc: 0.390\n",
            "Test acc:  38.322592357266046\n",
            "Test loss:  1.6024140188459717\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6024140188459717\n",
            "Epoch 14: | Loss: 1.55023 | Acc: 0.401\n",
            "Test acc:  37.94136334755378\n",
            "Test loss:  1.6180230075913358\n",
            "BEST TEST LOSS:  1.6024140188459717\n",
            "Epoch 15: | Loss: 1.54294 | Acc: 0.403\n",
            "Test acc:  37.950440228737406\n",
            "Test loss:  1.6118019288674945\n",
            "BEST TEST LOSS:  1.6024140188459717\n",
            "Epoch 16: | Loss: 1.53204 | Acc: 0.407\n",
            "Test acc:  38.80366705999819\n",
            "Test loss:  1.6158222973002174\n",
            "Early stopping at epoch 17\n",
            "BEST TEST LOSS:  1.6024140188459717\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.82804 | Acc: 0.259\n",
            "Test acc:  26.84033765998003\n",
            "Test loss:  1.7984398644783592\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7984398644783592\n",
            "Epoch 1: | Loss: 1.79262 | Acc: 0.270\n",
            "Test acc:  27.403104293364798\n",
            "Test loss:  1.7885494804106696\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7885494804106696\n",
            "Epoch 2: | Loss: 1.78553 | Acc: 0.271\n",
            "Test acc:  27.23064355087592\n",
            "Test loss:  1.7848397307313246\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7848397307313246\n",
            "Epoch 3: | Loss: 1.78089 | Acc: 0.271\n",
            "Test acc:  26.74049196696015\n",
            "Test loss:  1.7807684750915262\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7807684750915262\n",
            "Epoch 4: | Loss: 1.77661 | Acc: 0.275\n",
            "Test acc:  27.103567214305162\n",
            "Test loss:  1.772589957093917\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.772589957093917\n",
            "Epoch 5: | Loss: 1.77096 | Acc: 0.275\n",
            "Test acc:  27.72987201597531\n",
            "Test loss:  1.769743487325018\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.769743487325018\n",
            "Epoch 6: | Loss: 1.76774 | Acc: 0.274\n",
            "Test acc:  27.375873649813926\n",
            "Test loss:  1.773042498985467\n",
            "BEST TEST LOSS:  1.769743487325018\n",
            "Epoch 7: | Loss: 1.76193 | Acc: 0.276\n",
            "Test acc:  27.793410184260686\n",
            "Test loss:  1.768633175447497\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.768633175447497\n",
            "Epoch 8: | Loss: 1.75075 | Acc: 0.276\n",
            "Test acc:  27.31233548152855\n",
            "Test loss:  1.7475570309368862\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7475570309368862\n",
            "Epoch 9: | Loss: 1.73269 | Acc: 0.290\n",
            "Test acc:  30.82508849959154\n",
            "Test loss:  1.727669593226703\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.727669593226703\n",
            "Epoch 10: | Loss: 1.72574 | Acc: 0.302\n",
            "Test acc:  29.481710084414996\n",
            "Test loss:  1.7422618438742754\n",
            "BEST TEST LOSS:  1.727669593226703\n",
            "Epoch 11: | Loss: 1.70809 | Acc: 0.311\n",
            "Test acc:  31.56031587546519\n",
            "Test loss:  1.7176940627180772\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7176940627180772\n",
            "Epoch 12: | Loss: 1.70256 | Acc: 0.315\n",
            "Test acc:  30.743396568938913\n",
            "Test loss:  1.7463354678512308\n",
            "BEST TEST LOSS:  1.7176940627180772\n",
            "Epoch 13: | Loss: 1.68943 | Acc: 0.326\n",
            "Test acc:  31.89616047925933\n",
            "Test loss:  1.6948176960035555\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6948176960035555\n",
            "Epoch 14: | Loss: 1.66612 | Acc: 0.338\n",
            "Test acc:  34.101842606880275\n",
            "Test loss:  1.6704625228925936\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6704625228925936\n",
            "Epoch 15: | Loss: 1.65484 | Acc: 0.343\n",
            "Test acc:  34.274303349369156\n",
            "Test loss:  1.6655206404669436\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6655206404669436\n",
            "Epoch 16: | Loss: 1.63935 | Acc: 0.355\n",
            "Test acc:  35.52691295270945\n",
            "Test loss:  1.6478629870221795\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6478629870221795\n",
            "Epoch 17: | Loss: 1.62384 | Acc: 0.361\n",
            "Test acc:  35.42706725968957\n",
            "Test loss:  1.658189859004379\n",
            "BEST TEST LOSS:  1.6478629870221795\n",
            "Epoch 18: | Loss: 1.60570 | Acc: 0.368\n",
            "Test acc:  35.42706725968957\n",
            "Test loss:  1.645831276915666\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.645831276915666\n",
            "Epoch 19: | Loss: 1.59534 | Acc: 0.375\n",
            "Test acc:  36.198602160297725\n",
            "Test loss:  1.6326376640727753\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6326376640727753\n",
            "Epoch 20: | Loss: 1.57868 | Acc: 0.386\n",
            "Test acc:  36.85213760551874\n",
            "Test loss:  1.6331740149183769\n",
            "BEST TEST LOSS:  1.6326376640727753\n",
            "Epoch 21: | Loss: 1.55858 | Acc: 0.393\n",
            "Test acc:  36.89752201143687\n",
            "Test loss:  1.6187286425188097\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6187286425188097\n",
            "Epoch 22: | Loss: 1.54549 | Acc: 0.399\n",
            "Test acc:  35.309067804302444\n",
            "Test loss:  1.6467744759741547\n",
            "BEST TEST LOSS:  1.6187286425188097\n",
            "Epoch 23: | Loss: 1.53471 | Acc: 0.404\n",
            "Test acc:  38.69474448579468\n",
            "Test loss:  1.6193848345321038\n",
            "BEST TEST LOSS:  1.6187286425188097\n",
            "Epoch 24: | Loss: 1.51013 | Acc: 0.415\n",
            "Test acc:  39.01243532722157\n",
            "Test loss:  1.599452127611017\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.599452127611017\n",
            "Epoch 25: | Loss: 1.49601 | Acc: 0.422\n",
            "Test acc:  38.49505309975492\n",
            "Test loss:  1.6199359156492819\n",
            "BEST TEST LOSS:  1.599452127611017\n",
            "Epoch 26: | Loss: 1.48528 | Acc: 0.422\n",
            "Test acc:  38.49505309975492\n",
            "Test loss:  1.592269505379517\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.592269505379517\n",
            "Epoch 27: | Loss: 1.46842 | Acc: 0.431\n",
            "Test acc:  39.52981755468821\n",
            "Test loss:  1.5785268097254581\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5785268097254581\n",
            "Epoch 28: | Loss: 1.45075 | Acc: 0.439\n",
            "Test acc:  39.77489334664609\n",
            "Test loss:  1.589866332925124\n",
            "BEST TEST LOSS:  1.5785268097254581\n",
            "Epoch 29: | Loss: 1.44206 | Acc: 0.442\n",
            "Test acc:  39.19397295089407\n",
            "Test loss:  1.5884727997586907\n",
            "BEST TEST LOSS:  1.5785268097254581\n",
            "Epoch 30: | Loss: 1.42482 | Acc: 0.452\n",
            "Test acc:  38.84905146591631\n",
            "Test loss:  1.613336224087401\n",
            "Early stopping at epoch 31\n",
            "BEST TEST LOSS:  1.5785268097254581\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.81927 | Acc: 0.258\n",
            "Test acc:  27.675410728873562\n",
            "Test loss:  1.776051089253729\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.776051089253729\n",
            "Epoch 1: | Loss: 1.76712 | Acc: 0.282\n",
            "Test acc:  27.984024689116822\n",
            "Test loss:  1.7677564924162936\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7677564924162936\n",
            "Epoch 2: | Loss: 1.74778 | Acc: 0.291\n",
            "Test acc:  29.263864936007987\n",
            "Test loss:  1.7499976640491817\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7499976640491817\n",
            "Epoch 3: | Loss: 1.73523 | Acc: 0.303\n",
            "Test acc:  30.22601434147227\n",
            "Test loss:  1.7361168068957467\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7361168068957467\n",
            "Epoch 4: | Loss: 1.71749 | Acc: 0.313\n",
            "Test acc:  30.46201325224653\n",
            "Test loss:  1.7240312740292851\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7240312740292851\n",
            "Epoch 5: | Loss: 1.70084 | Acc: 0.325\n",
            "Test acc:  32.27738948897159\n",
            "Test loss:  1.701611674589918\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.701611674589918\n",
            "Epoch 6: | Loss: 1.68008 | Acc: 0.336\n",
            "Test acc:  32.87646364709086\n",
            "Test loss:  1.6922033942503736\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6922033942503736\n",
            "Epoch 7: | Loss: 1.65603 | Acc: 0.351\n",
            "Test acc:  34.59199419079604\n",
            "Test loss:  1.6711918301665025\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6711918301665025\n",
            "Epoch 8: | Loss: 1.62979 | Acc: 0.363\n",
            "Test acc:  35.381682853771444\n",
            "Test loss:  1.6464313151519423\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6464313151519423\n",
            "Epoch 9: | Loss: 1.60851 | Acc: 0.373\n",
            "Test acc:  35.88998820005446\n",
            "Test loss:  1.635374103667419\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.635374103667419\n",
            "Epoch 10: | Loss: 1.58240 | Acc: 0.386\n",
            "Test acc:  36.371062902786605\n",
            "Test loss:  1.6277289156279813\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6277289156279813\n",
            "Epoch 11: | Loss: 1.56482 | Acc: 0.394\n",
            "Test acc:  36.83398384315149\n",
            "Test loss:  1.626560036157597\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.626560036157597\n",
            "Epoch 12: | Loss: 1.54419 | Acc: 0.405\n",
            "Test acc:  36.715984387764365\n",
            "Test loss:  1.6140954942372494\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6140954942372494\n",
            "Epoch 13: | Loss: 1.52825 | Acc: 0.412\n",
            "Test acc:  38.440591812653174\n",
            "Test loss:  1.5908681140469678\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5908681140469678\n",
            "Epoch 14: | Loss: 1.51229 | Acc: 0.419\n",
            "Test acc:  39.02151220840519\n",
            "Test loss:  1.5918261598300383\n",
            "BEST TEST LOSS:  1.5908681140469678\n",
            "Epoch 15: | Loss: 1.49075 | Acc: 0.426\n",
            "Test acc:  38.785513297630935\n",
            "Test loss:  1.5818139631624166\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5818139631624166\n",
            "Epoch 16: | Loss: 1.47847 | Acc: 0.433\n",
            "Test acc:  38.66751384224381\n",
            "Test loss:  1.589105358702599\n",
            "BEST TEST LOSS:  1.5818139631624166\n",
            "Epoch 17: | Loss: 1.46570 | Acc: 0.439\n",
            "Test acc:  39.01243532722157\n",
            "Test loss:  1.5813457641987443\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5813457641987443\n",
            "Epoch 18: | Loss: 1.44760 | Acc: 0.445\n",
            "Test acc:  38.82182082236543\n",
            "Test loss:  1.5848785039317401\n",
            "BEST TEST LOSS:  1.5813457641987443\n",
            "Epoch 19: | Loss: 1.43823 | Acc: 0.452\n",
            "Test acc:  39.302895525097576\n",
            "Test loss:  1.577766396406758\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.577766396406758\n",
            "Epoch 20: | Loss: 1.43749 | Acc: 0.448\n",
            "Test acc:  38.81274394118181\n",
            "Test loss:  1.5963096239663273\n",
            "BEST TEST LOSS:  1.577766396406758\n",
            "Epoch 21: | Loss: 1.41808 | Acc: 0.454\n",
            "Test acc:  39.31197240628121\n",
            "Test loss:  1.5870720623545564\n",
            "BEST TEST LOSS:  1.577766396406758\n",
            "Epoch 22: | Loss: 1.40592 | Acc: 0.460\n",
            "Test acc:  38.82182082236543\n",
            "Test loss:  1.5806605202614228\n",
            "Early stopping at epoch 23\n",
            "BEST TEST LOSS:  1.577766396406758\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.80388 | Acc: 0.268\n",
            "Test acc:  28.165562312789326\n",
            "Test loss:  1.7646821289393253\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7646821289393253\n",
            "Epoch 1: | Loss: 1.75775 | Acc: 0.290\n",
            "Test acc:  30.389398202777524\n",
            "Test loss:  1.7466033972756712\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7466033972756712\n",
            "Epoch 2: | Loss: 1.73468 | Acc: 0.306\n",
            "Test acc:  30.997549242080417\n",
            "Test loss:  1.7271445824231715\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7271445824231715\n",
            "Epoch 3: | Loss: 1.71021 | Acc: 0.319\n",
            "Test acc:  32.78569483525461\n",
            "Test loss:  1.7039661090498026\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7039661090498026\n",
            "Epoch 4: | Loss: 1.68365 | Acc: 0.334\n",
            "Test acc:  33.78415176545339\n",
            "Test loss:  1.6806924081262136\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6806924081262136\n",
            "Epoch 5: | Loss: 1.65166 | Acc: 0.352\n",
            "Test acc:  35.109376418262684\n",
            "Test loss:  1.6607889515816132\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6607889515816132\n",
            "Epoch 6: | Loss: 1.63279 | Acc: 0.357\n",
            "Test acc:  35.74475810111646\n",
            "Test loss:  1.6440736461926058\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6440736461926058\n",
            "Epoch 7: | Loss: 1.61015 | Acc: 0.372\n",
            "Test acc:  36.31660161568485\n",
            "Test loss:  1.642013997700862\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.642013997700862\n",
            "Epoch 8: | Loss: 1.59541 | Acc: 0.381\n",
            "Test acc:  36.38013978397023\n",
            "Test loss:  1.622552006230878\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.622552006230878\n",
            "Epoch 9: | Loss: 1.57597 | Acc: 0.384\n",
            "Test acc:  37.505673050739766\n",
            "Test loss:  1.612305850651912\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.612305850651912\n",
            "Epoch 10: | Loss: 1.55881 | Acc: 0.396\n",
            "Test acc:  37.650903149677774\n",
            "Test loss:  1.617645916222148\n",
            "BEST TEST LOSS:  1.612305850651912\n",
            "Epoch 11: | Loss: 1.53842 | Acc: 0.407\n",
            "Test acc:  38.213669783062535\n",
            "Test loss:  1.6042643234219853\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6042643234219853\n",
            "Epoch 12: | Loss: 1.52958 | Acc: 0.409\n",
            "Test acc:  37.723518199146774\n",
            "Test loss:  1.602956936538564\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.602956936538564\n",
            "Epoch 13: | Loss: 1.51013 | Acc: 0.414\n",
            "Test acc:  37.995824634655534\n",
            "Test loss:  1.5947238448038266\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5947238448038266\n",
            "Epoch 14: | Loss: 1.49461 | Acc: 0.421\n",
            "Test acc:  38.57674503040755\n",
            "Test loss:  1.5933156144412266\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5933156144412266\n",
            "Epoch 15: | Loss: 1.47699 | Acc: 0.433\n",
            "Test acc:  38.62212943632568\n",
            "Test loss:  1.584354386164274\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.584354386164274\n",
            "Epoch 16: | Loss: 1.45987 | Acc: 0.439\n",
            "Test acc:  38.758282654080055\n",
            "Test loss:  1.5805288801303488\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5805288801303488\n",
            "Epoch 17: | Loss: 1.44575 | Acc: 0.439\n",
            "Test acc:  39.07597349550694\n",
            "Test loss:  1.5830654753425908\n",
            "BEST TEST LOSS:  1.5805288801303488\n",
            "Epoch 18: | Loss: 1.43253 | Acc: 0.448\n",
            "Test acc:  39.45720250521921\n",
            "Test loss:  1.5844353899101302\n",
            "BEST TEST LOSS:  1.5805288801303488\n",
            "Epoch 19: | Loss: 1.42004 | Acc: 0.452\n",
            "Test acc:  39.321049287464824\n",
            "Test loss:  1.5883311322658737\n",
            "Early stopping at epoch 20\n",
            "BEST TEST LOSS:  1.5805288801303488\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.80378 | Acc: 0.264\n",
            "Test acc:  28.583098847236087\n",
            "Test loss:  1.7620518841495403\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7620518841495403\n",
            "Epoch 1: | Loss: 1.75352 | Acc: 0.290\n",
            "Test acc:  29.72678587637288\n",
            "Test loss:  1.7493826481648262\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7493826481648262\n",
            "Epoch 2: | Loss: 1.71569 | Acc: 0.316\n",
            "Test acc:  32.27738948897159\n",
            "Test loss:  1.6975048553047842\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6975048553047842\n",
            "Epoch 3: | Loss: 1.67858 | Acc: 0.334\n",
            "Test acc:  33.86584369610602\n",
            "Test loss:  1.6803159906685008\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6803159906685008\n",
            "Epoch 4: | Loss: 1.64428 | Acc: 0.354\n",
            "Test acc:  36.03521829899247\n",
            "Test loss:  1.6440993699035205\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6440993699035205\n",
            "Epoch 5: | Loss: 1.61686 | Acc: 0.367\n",
            "Test acc:  36.95198329853862\n",
            "Test loss:  1.6222782734501568\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6222782734501568\n",
            "Epoch 6: | Loss: 1.58931 | Acc: 0.379\n",
            "Test acc:  37.30598166470001\n",
            "Test loss:  1.6134894149151842\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6134894149151842\n",
            "Epoch 7: | Loss: 1.56552 | Acc: 0.395\n",
            "Test acc:  37.623672506126894\n",
            "Test loss:  1.611983206230781\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.611983206230781\n",
            "Epoch 8: | Loss: 1.55412 | Acc: 0.396\n",
            "Test acc:  37.995824634655534\n",
            "Test loss:  1.5988633763583409\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5988633763583409\n",
            "Epoch 9: | Loss: 1.53245 | Acc: 0.404\n",
            "Test acc:  39.28474176273033\n",
            "Test loss:  1.5892211736282171\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5892211736282171\n",
            "Epoch 10: | Loss: 1.51387 | Acc: 0.415\n",
            "Test acc:  39.321049287464824\n",
            "Test loss:  1.5721723220251889\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5721723220251889\n",
            "Epoch 11: | Loss: 1.50046 | Acc: 0.414\n",
            "Test acc:  39.230280475628575\n",
            "Test loss:  1.5817886618520483\n",
            "BEST TEST LOSS:  1.5721723220251889\n",
            "Epoch 12: | Loss: 1.48052 | Acc: 0.425\n",
            "Test acc:  39.11228102024145\n",
            "Test loss:  1.5757807093548637\n",
            "BEST TEST LOSS:  1.5721723220251889\n",
            "Epoch 13: | Loss: 1.47602 | Acc: 0.427\n",
            "Test acc:  39.2393573568122\n",
            "Test loss:  1.5782192931698926\n",
            "Early stopping at epoch 14\n",
            "BEST TEST LOSS:  1.5721723220251889\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.86964 | Acc: 0.221\n",
            "Test acc:  25.170191522192976\n",
            "Test loss:  1.8277655681433704\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8277655681433704\n",
            "Epoch 1: | Loss: 1.81592 | Acc: 0.253\n",
            "Test acc:  26.259417264228013\n",
            "Test loss:  1.8008669146223564\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8008669146223564\n",
            "Epoch 2: | Loss: 1.79827 | Acc: 0.268\n",
            "Test acc:  26.32295543251339\n",
            "Test loss:  1.7965061561220643\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7965061561220643\n",
            "Epoch 3: | Loss: 1.78823 | Acc: 0.274\n",
            "Test acc:  27.484796224017426\n",
            "Test loss:  1.7838887472373213\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7838887472373213\n",
            "Epoch 4: | Loss: 1.78075 | Acc: 0.278\n",
            "Test acc:  27.720795134791686\n",
            "Test loss:  1.783038542449819\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.783038542449819\n",
            "Epoch 5: | Loss: 1.77406 | Acc: 0.282\n",
            "Test acc:  27.993101570300443\n",
            "Test loss:  1.7720520592838354\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7720520592838354\n",
            "Epoch 6: | Loss: 1.77016 | Acc: 0.283\n",
            "Test acc:  27.875102114913314\n",
            "Test loss:  1.7718966145046873\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7718966145046873\n",
            "Epoch 7: | Loss: 1.76772 | Acc: 0.284\n",
            "Test acc:  27.720795134791686\n",
            "Test loss:  1.766263393308386\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.766263393308386\n",
            "Epoch 8: | Loss: 1.75801 | Acc: 0.287\n",
            "Test acc:  28.61940637197059\n",
            "Test loss:  1.760707979257396\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.760707979257396\n",
            "Epoch 9: | Loss: 1.75644 | Acc: 0.288\n",
            "Test acc:  28.991558500499227\n",
            "Test loss:  1.7603142233942286\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7603142233942286\n",
            "Epoch 10: | Loss: 1.75208 | Acc: 0.295\n",
            "Test acc:  29.009712262866476\n",
            "Test loss:  1.757740218515341\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.757740218515341\n",
            "Epoch 11: | Loss: 1.74588 | Acc: 0.297\n",
            "Test acc:  29.236634292457115\n",
            "Test loss:  1.7572123432435052\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7572123432435052\n",
            "Epoch 12: | Loss: 1.74787 | Acc: 0.297\n",
            "Test acc:  29.626940183353\n",
            "Test loss:  1.7520545493660635\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7520545493660635\n",
            "Epoch 13: | Loss: 1.74354 | Acc: 0.301\n",
            "Test acc:  29.345556866660615\n",
            "Test loss:  1.7550671831031754\n",
            "BEST TEST LOSS:  1.7520545493660635\n",
            "Epoch 14: | Loss: 1.73942 | Acc: 0.304\n",
            "Test acc:  29.862939094127256\n",
            "Test loss:  1.7476622700002151\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7476622700002151\n",
            "Epoch 15: | Loss: 1.73440 | Acc: 0.300\n",
            "Test acc:  29.754016519923752\n",
            "Test loss:  1.7416832453942712\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7416832453942712\n",
            "Epoch 16: | Loss: 1.73172 | Acc: 0.304\n",
            "Test acc:  29.817554688209132\n",
            "Test loss:  1.7419904973465583\n",
            "BEST TEST LOSS:  1.7416832453942712\n",
            "Epoch 17: | Loss: 1.72783 | Acc: 0.306\n",
            "Test acc:  29.980938549514384\n",
            "Test loss:  1.737377296982473\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.737377296982473\n",
            "Epoch 18: | Loss: 1.72279 | Acc: 0.312\n",
            "Test acc:  29.654170826903876\n",
            "Test loss:  1.7395146092927525\n",
            "BEST TEST LOSS:  1.737377296982473\n",
            "Epoch 19: | Loss: 1.72104 | Acc: 0.313\n",
            "Test acc:  29.953707905963512\n",
            "Test loss:  1.7388786931947477\n",
            "BEST TEST LOSS:  1.737377296982473\n",
            "Epoch 20: | Loss: 1.71983 | Acc: 0.313\n",
            "Test acc:  30.017246074248888\n",
            "Test loss:  1.7354059977338494\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7354059977338494\n",
            "Epoch 21: | Loss: 1.71337 | Acc: 0.319\n",
            "Test acc:  30.407551965144776\n",
            "Test loss:  1.7349129363980595\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7349129363980595\n",
            "Epoch 22: | Loss: 1.71057 | Acc: 0.318\n",
            "Test acc:  30.198783697921392\n",
            "Test loss:  1.7290267710051785\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7290267710051785\n",
            "Epoch 23: | Loss: 1.70617 | Acc: 0.322\n",
            "Test acc:  30.779704093673416\n",
            "Test loss:  1.7309988833576269\n",
            "BEST TEST LOSS:  1.7290267710051785\n",
            "Epoch 24: | Loss: 1.70553 | Acc: 0.320\n",
            "Test acc:  30.834165380775165\n",
            "Test loss:  1.7289156328046942\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7289156328046942\n",
            "Epoch 25: | Loss: 1.70180 | Acc: 0.325\n",
            "Test acc:  31.160933103385673\n",
            "Test loss:  1.723635925722949\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.723635925722949\n",
            "Epoch 26: | Loss: 1.69639 | Acc: 0.326\n",
            "Test acc:  31.288009439956433\n",
            "Test loss:  1.7227144551414975\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7227144551414975\n",
            "Epoch 27: | Loss: 1.69414 | Acc: 0.331\n",
            "Test acc:  31.03385676681492\n",
            "Test loss:  1.719262665406817\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.719262665406817\n",
            "Epoch 28: | Loss: 1.68942 | Acc: 0.328\n",
            "Test acc:  31.34247072705818\n",
            "Test loss:  1.7170582823670668\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7170582823670668\n",
            "Epoch 29: | Loss: 1.68801 | Acc: 0.331\n",
            "Test acc:  31.42416265771081\n",
            "Test loss:  1.7146333194192434\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7146333194192434\n",
            "Epoch 30: | Loss: 1.68224 | Acc: 0.337\n",
            "Test acc:  31.66016156848507\n",
            "Test loss:  1.7142191897926993\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7142191897926993\n",
            "Epoch 31: | Loss: 1.68098 | Acc: 0.332\n",
            "Test acc:  31.605700281383314\n",
            "Test loss:  1.7176061413880717\n",
            "BEST TEST LOSS:  1.7142191897926993\n",
            "Epoch 32: | Loss: 1.67781 | Acc: 0.339\n",
            "Test acc:  32.304620132522466\n",
            "Test loss:  1.707196738678596\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.707196738678596\n",
            "Epoch 33: | Loss: 1.67478 | Acc: 0.340\n",
            "Test acc:  32.66769537986748\n",
            "Test loss:  1.7066003594095307\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7066003594095307\n",
            "Epoch 34: | Loss: 1.66903 | Acc: 0.341\n",
            "Test acc:  32.98538622129436\n",
            "Test loss:  1.7021851746333128\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7021851746333128\n",
            "Epoch 35: | Loss: 1.66498 | Acc: 0.342\n",
            "Test acc:  32.6404647363166\n",
            "Test loss:  1.701172510323497\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.701172510323497\n",
            "Epoch 36: | Loss: 1.66475 | Acc: 0.342\n",
            "Test acc:  32.38631206317509\n",
            "Test loss:  1.701075755791857\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.701075755791857\n",
            "Epoch 37: | Loss: 1.66146 | Acc: 0.348\n",
            "Test acc:  33.23046201325225\n",
            "Test loss:  1.6961010239716898\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6961010239716898\n",
            "Epoch 38: | Loss: 1.65597 | Acc: 0.354\n",
            "Test acc:  33.021693746028866\n",
            "Test loss:  1.6996864783281536\n",
            "BEST TEST LOSS:  1.6961010239716898\n",
            "Epoch 39: | Loss: 1.65274 | Acc: 0.352\n",
            "Test acc:  33.64799854769901\n",
            "Test loss:  1.690534327071526\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.690534327071526\n",
            "Epoch 40: | Loss: 1.64660 | Acc: 0.359\n",
            "Test acc:  32.91277117182536\n",
            "Test loss:  1.6953661924152705\n",
            "BEST TEST LOSS:  1.690534327071526\n",
            "Epoch 41: | Loss: 1.64482 | Acc: 0.356\n",
            "Test acc:  33.384768993373875\n",
            "Test loss:  1.686900001729844\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.686900001729844\n",
            "Epoch 42: | Loss: 1.63912 | Acc: 0.356\n",
            "Test acc:  33.00353998366161\n",
            "Test loss:  1.6913429684721666\n",
            "BEST TEST LOSS:  1.686900001729844\n",
            "Epoch 43: | Loss: 1.63528 | Acc: 0.360\n",
            "Test acc:  33.55722973586276\n",
            "Test loss:  1.6876895916944294\n",
            "BEST TEST LOSS:  1.686900001729844\n",
            "Epoch 44: | Loss: 1.63199 | Acc: 0.362\n",
            "Test acc:  33.71153671598439\n",
            "Test loss:  1.6814162427979398\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6814162427979398\n",
            "Epoch 45: | Loss: 1.63189 | Acc: 0.361\n",
            "Test acc:  33.77507488426976\n",
            "Test loss:  1.6816390105065582\n",
            "BEST TEST LOSS:  1.6814162427979398\n",
            "Epoch 46: | Loss: 1.62545 | Acc: 0.364\n",
            "Test acc:  34.26522646818553\n",
            "Test loss:  1.6766383220694658\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6766383220694658\n",
            "Epoch 47: | Loss: 1.61937 | Acc: 0.371\n",
            "Test acc:  33.938458745575026\n",
            "Test loss:  1.6811632710385185\n",
            "BEST TEST LOSS:  1.6766383220694658\n",
            "Epoch 48: | Loss: 1.61501 | Acc: 0.374\n",
            "Test acc:  33.51184532994463\n",
            "Test loss:  1.6799671767074937\n",
            "BEST TEST LOSS:  1.6766383220694658\n",
            "Epoch 49: | Loss: 1.61473 | Acc: 0.372\n",
            "Test acc:  33.89307433965689\n",
            "Test loss:  1.681788132369863\n",
            "Early stopping at epoch 50\n",
            "BEST TEST LOSS:  1.6766383220694658\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.87195 | Acc: 0.236\n",
            "Test acc:  25.52418988835436\n",
            "Test loss:  1.8189538662144213\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8189538662144213\n",
            "Epoch 1: | Loss: 1.81512 | Acc: 0.259\n",
            "Test acc:  26.831260778796405\n",
            "Test loss:  1.799635193940532\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.799635193940532\n",
            "Epoch 2: | Loss: 1.79851 | Acc: 0.267\n",
            "Test acc:  27.139874739039666\n",
            "Test loss:  1.7894834569423874\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7894834569423874\n",
            "Epoch 3: | Loss: 1.78544 | Acc: 0.274\n",
            "Test acc:  27.575565035853682\n",
            "Test loss:  1.7808063174947837\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7808063174947837\n",
            "Epoch 4: | Loss: 1.77777 | Acc: 0.277\n",
            "Test acc:  27.984024689116822\n",
            "Test loss:  1.7745239789775342\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7745239789775342\n",
            "Epoch 5: | Loss: 1.76971 | Acc: 0.283\n",
            "Test acc:  27.121720976672414\n",
            "Test loss:  1.7732949125973476\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7732949125973476\n",
            "Epoch 6: | Loss: 1.76487 | Acc: 0.285\n",
            "Test acc:  28.51048379776709\n",
            "Test loss:  1.7658635281413966\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7658635281413966\n",
            "Epoch 7: | Loss: 1.75674 | Acc: 0.291\n",
            "Test acc:  28.664790777888715\n",
            "Test loss:  1.7600767295484598\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7600767295484598\n",
            "Epoch 8: | Loss: 1.75456 | Acc: 0.292\n",
            "Test acc:  28.44694562948171\n",
            "Test loss:  1.7582584640194225\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7582584640194225\n",
            "Epoch 9: | Loss: 1.74871 | Acc: 0.296\n",
            "Test acc:  28.900789688662975\n",
            "Test loss:  1.7585583580711674\n",
            "BEST TEST LOSS:  1.7582584640194225\n",
            "Epoch 10: | Loss: 1.74556 | Acc: 0.296\n",
            "Test acc:  29.14586548062086\n",
            "Test loss:  1.7526045024739525\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7526045024739525\n",
            "Epoch 11: | Loss: 1.73919 | Acc: 0.301\n",
            "Test acc:  29.40001815376237\n",
            "Test loss:  1.748851253118129\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.748851253118129\n",
            "Epoch 12: | Loss: 1.73759 | Acc: 0.302\n",
            "Test acc:  29.327403104293364\n",
            "Test loss:  1.7468638454558532\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7468638454558532\n",
            "Epoch 13: | Loss: 1.73194 | Acc: 0.305\n",
            "Test acc:  29.5906326586185\n",
            "Test loss:  1.7448467794870366\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7448467794870366\n",
            "Epoch 14: | Loss: 1.72744 | Acc: 0.307\n",
            "Test acc:  30.017246074248888\n",
            "Test loss:  1.7382147098552285\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7382147098552285\n",
            "Epoch 15: | Loss: 1.72438 | Acc: 0.311\n",
            "Test acc:  30.416628846328404\n",
            "Test loss:  1.7351728843126684\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7351728843126684\n",
            "Epoch 16: | Loss: 1.71901 | Acc: 0.311\n",
            "Test acc:  30.543705182899156\n",
            "Test loss:  1.7331255129996064\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7331255129996064\n",
            "Epoch 17: | Loss: 1.71564 | Acc: 0.316\n",
            "Test acc:  30.216937460288644\n",
            "Test loss:  1.7355331251386963\n",
            "BEST TEST LOSS:  1.7331255129996064\n",
            "Epoch 18: | Loss: 1.71190 | Acc: 0.318\n",
            "Test acc:  30.743396568938913\n",
            "Test loss:  1.73155213229229\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.73155213229229\n",
            "Epoch 19: | Loss: 1.70734 | Acc: 0.317\n",
            "Test acc:  31.01570300444767\n",
            "Test loss:  1.7279657290850072\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7279657290850072\n",
            "Epoch 20: | Loss: 1.70445 | Acc: 0.322\n",
            "Test acc:  30.797857856040668\n",
            "Test loss:  1.7309646082751324\n",
            "BEST TEST LOSS:  1.7279657290850072\n",
            "Epoch 21: | Loss: 1.69886 | Acc: 0.325\n",
            "Test acc:  31.14277934101843\n",
            "Test loss:  1.718435053191433\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.718435053191433\n",
            "Epoch 22: | Loss: 1.69518 | Acc: 0.328\n",
            "Test acc:  31.01570300444767\n",
            "Test loss:  1.7177063860645183\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7177063860645183\n",
            "Epoch 23: | Loss: 1.69006 | Acc: 0.329\n",
            "Test acc:  31.58754651901607\n",
            "Test loss:  1.7162433821341896\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7162433821341896\n",
            "Epoch 24: | Loss: 1.68447 | Acc: 0.334\n",
            "Test acc:  31.642007806117817\n",
            "Test loss:  1.714788157126807\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.714788157126807\n",
            "Epoch 25: | Loss: 1.68201 | Acc: 0.338\n",
            "Test acc:  32.449850231460466\n",
            "Test loss:  1.7111846373949438\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7111846373949438\n",
            "Epoch 26: | Loss: 1.67295 | Acc: 0.338\n",
            "Test acc:  31.959698647544705\n",
            "Test loss:  1.7074919387784306\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7074919387784306\n",
            "Epoch 27: | Loss: 1.66951 | Acc: 0.337\n",
            "Test acc:  32.404465825542346\n",
            "Test loss:  1.70598846708419\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.70598846708419\n",
            "Epoch 28: | Loss: 1.66464 | Acc: 0.345\n",
            "Test acc:  33.05800127076336\n",
            "Test loss:  1.7000681713137324\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7000681713137324\n",
            "Epoch 29: | Loss: 1.66082 | Acc: 0.343\n",
            "Test acc:  32.495234637378594\n",
            "Test loss:  1.6976795837369267\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6976795837369267\n",
            "Epoch 30: | Loss: 1.65559 | Acc: 0.351\n",
            "Test acc:  32.840156122356355\n",
            "Test loss:  1.6921191181061586\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6921191181061586\n",
            "Epoch 31: | Loss: 1.64864 | Acc: 0.354\n",
            "Test acc:  33.67522919124989\n",
            "Test loss:  1.6888916003221721\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6888916003221721\n",
            "Epoch 32: | Loss: 1.64264 | Acc: 0.357\n",
            "Test acc:  32.767541072887354\n",
            "Test loss:  1.6896370215223016\n",
            "BEST TEST LOSS:  1.6888916003221721\n",
            "Epoch 33: | Loss: 1.63849 | Acc: 0.359\n",
            "Test acc:  33.411999636924754\n",
            "Test loss:  1.6864315526333848\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6864315526333848\n",
            "Epoch 34: | Loss: 1.63451 | Acc: 0.357\n",
            "Test acc:  34.0019969138604\n",
            "Test loss:  1.6805831965683513\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6805831965683513\n",
            "Epoch 35: | Loss: 1.62778 | Acc: 0.365\n",
            "Test acc:  33.657075428882635\n",
            "Test loss:  1.6782423188920654\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6782423188920654\n",
            "Epoch 36: | Loss: 1.62341 | Acc: 0.364\n",
            "Test acc:  33.80230552782064\n",
            "Test loss:  1.6782373072784071\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6782373072784071\n",
            "Epoch 37: | Loss: 1.61678 | Acc: 0.367\n",
            "Test acc:  34.13815013161477\n",
            "Test loss:  1.6803028087395464\n",
            "BEST TEST LOSS:  1.6782373072784071\n",
            "Epoch 38: | Loss: 1.61083 | Acc: 0.371\n",
            "Test acc:  34.392302804756284\n",
            "Test loss:  1.6691711162556113\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6691711162556113\n",
            "Epoch 39: | Loss: 1.60836 | Acc: 0.375\n",
            "Test acc:  33.90215122084052\n",
            "Test loss:  1.6686000417422697\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6686000417422697\n",
            "Epoch 40: | Loss: 1.59815 | Acc: 0.378\n",
            "Test acc:  34.29245711173641\n",
            "Test loss:  1.6702064110364527\n",
            "BEST TEST LOSS:  1.6686000417422697\n",
            "Epoch 41: | Loss: 1.59304 | Acc: 0.382\n",
            "Test acc:  34.77353181446855\n",
            "Test loss:  1.6610335938503287\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6610335938503287\n",
            "Epoch 42: | Loss: 1.58593 | Acc: 0.381\n",
            "Test acc:  34.43768721067441\n",
            "Test loss:  1.6634127590697625\n",
            "BEST TEST LOSS:  1.6610335938503287\n",
            "Epoch 43: | Loss: 1.58232 | Acc: 0.387\n",
            "Test acc:  34.274303349369156\n",
            "Test loss:  1.6642815494812981\n",
            "BEST TEST LOSS:  1.6610335938503287\n",
            "Epoch 44: | Loss: 1.57996 | Acc: 0.387\n",
            "Test acc:  35.17291458654806\n",
            "Test loss:  1.659221454851889\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.659221454851889\n",
            "Epoch 45: | Loss: 1.57165 | Acc: 0.390\n",
            "Test acc:  35.27276027956794\n",
            "Test loss:  1.6554583724523555\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6554583724523555\n",
            "Epoch 46: | Loss: 1.56753 | Acc: 0.396\n",
            "Test acc:  35.20014523009894\n",
            "Test loss:  1.648075384900749\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.648075384900749\n",
            "Epoch 47: | Loss: 1.56458 | Acc: 0.391\n",
            "Test acc:  35.21829899246619\n",
            "Test loss:  1.650516919317962\n",
            "BEST TEST LOSS:  1.648075384900749\n",
            "Epoch 48: | Loss: 1.55400 | Acc: 0.402\n",
            "Test acc:  35.454297903240445\n",
            "Test loss:  1.6541608744273986\n",
            "BEST TEST LOSS:  1.648075384900749\n",
            "Epoch 49: | Loss: 1.54968 | Acc: 0.400\n",
            "Test acc:  35.436144140873196\n",
            "Test loss:  1.6496397759873054\n",
            "Early stopping at epoch 50\n",
            "BEST TEST LOSS:  1.648075384900749\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.85294 | Acc: 0.235\n",
            "Test acc:  25.678496868475992\n",
            "Test loss:  1.8056167625967479\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8056167625967479\n",
            "Epoch 1: | Loss: 1.80075 | Acc: 0.266\n",
            "Test acc:  27.71171825360806\n",
            "Test loss:  1.7863160034135588\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7863160034135588\n",
            "Epoch 2: | Loss: 1.78067 | Acc: 0.278\n",
            "Test acc:  28.06571661976945\n",
            "Test loss:  1.774079041673958\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.774079041673958\n",
            "Epoch 3: | Loss: 1.76853 | Acc: 0.288\n",
            "Test acc:  28.428791867114462\n",
            "Test loss:  1.7641319022702344\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7641319022702344\n",
            "Epoch 4: | Loss: 1.75643 | Acc: 0.290\n",
            "Test acc:  28.991558500499227\n",
            "Test loss:  1.7589333078075695\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7589333078075695\n",
            "Epoch 5: | Loss: 1.74985 | Acc: 0.294\n",
            "Test acc:  28.982481619315603\n",
            "Test loss:  1.7525906114909\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7525906114909\n",
            "Epoch 6: | Loss: 1.74310 | Acc: 0.297\n",
            "Test acc:  29.127711718253607\n",
            "Test loss:  1.748558885789331\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.748558885789331\n",
            "Epoch 7: | Loss: 1.73335 | Acc: 0.303\n",
            "Test acc:  29.899246618861756\n",
            "Test loss:  1.7461744684704466\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7461744684704466\n",
            "Epoch 8: | Loss: 1.72589 | Acc: 0.304\n",
            "Test acc:  30.353090678043028\n",
            "Test loss:  1.740276610231124\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.740276610231124\n",
            "Epoch 9: | Loss: 1.72463 | Acc: 0.311\n",
            "Test acc:  30.625397113551784\n",
            "Test loss:  1.7300548291619802\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7300548291619802\n",
            "Epoch 10: | Loss: 1.71427 | Acc: 0.317\n",
            "Test acc:  30.970318598529545\n",
            "Test loss:  1.7274269788940517\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7274269788940517\n",
            "Epoch 11: | Loss: 1.71052 | Acc: 0.319\n",
            "Test acc:  31.288009439956433\n",
            "Test loss:  1.7226669381808684\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7226669381808684\n",
            "Epoch 12: | Loss: 1.70091 | Acc: 0.323\n",
            "Test acc:  31.651084687301445\n",
            "Test loss:  1.7211018318385747\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7211018318385747\n",
            "Epoch 13: | Loss: 1.69071 | Acc: 0.330\n",
            "Test acc:  31.524008350730686\n",
            "Test loss:  1.7191958344740674\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7191958344740674\n",
            "Epoch 14: | Loss: 1.68547 | Acc: 0.333\n",
            "Test acc:  32.33185077607334\n",
            "Test loss:  1.7097859141454532\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7097859141454532\n",
            "Epoch 15: | Loss: 1.67938 | Acc: 0.336\n",
            "Test acc:  32.78569483525461\n",
            "Test loss:  1.7066460999450244\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7066460999450244\n",
            "Epoch 16: | Loss: 1.66982 | Acc: 0.341\n",
            "Test acc:  33.294000181537626\n",
            "Test loss:  1.694906236119353\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.694906236119353\n",
            "Epoch 17: | Loss: 1.65822 | Acc: 0.347\n",
            "Test acc:  33.43923028047563\n",
            "Test loss:  1.6886704574430609\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6886704574430609\n",
            "Epoch 18: | Loss: 1.64395 | Acc: 0.352\n",
            "Test acc:  34.129073250431155\n",
            "Test loss:  1.6800647167801168\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6800647167801168\n",
            "Epoch 19: | Loss: 1.63994 | Acc: 0.359\n",
            "Test acc:  34.23799582463465\n",
            "Test loss:  1.6759604670408834\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6759604670408834\n",
            "Epoch 20: | Loss: 1.62726 | Acc: 0.366\n",
            "Test acc:  35.02768448761005\n",
            "Test loss:  1.6653419595233279\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6653419595233279\n",
            "Epoch 21: | Loss: 1.61699 | Acc: 0.374\n",
            "Test acc:  34.837069982753924\n",
            "Test loss:  1.6679456054819801\n",
            "BEST TEST LOSS:  1.6653419595233279\n",
            "Epoch 22: | Loss: 1.60365 | Acc: 0.376\n",
            "Test acc:  34.95506943814106\n",
            "Test loss:  1.6602276846163535\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6602276846163535\n",
            "Epoch 23: | Loss: 1.59145 | Acc: 0.382\n",
            "Test acc:  35.599528002178445\n",
            "Test loss:  1.6439072810156496\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6439072810156496\n",
            "Epoch 24: | Loss: 1.58378 | Acc: 0.388\n",
            "Test acc:  36.20767904148134\n",
            "Test loss:  1.6412721810313318\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6412721810313318\n",
            "Epoch 25: | Loss: 1.57431 | Acc: 0.392\n",
            "Test acc:  36.30752473450122\n",
            "Test loss:  1.6357312298923559\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6357312298923559\n",
            "Epoch 26: | Loss: 1.56155 | Acc: 0.397\n",
            "Test acc:  36.516293001724605\n",
            "Test loss:  1.632807185884156\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.632807185884156\n",
            "Epoch 27: | Loss: 1.55307 | Acc: 0.402\n",
            "Test acc:  36.81583008078424\n",
            "Test loss:  1.6318454198065522\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6318454198065522\n",
            "Epoch 28: | Loss: 1.53893 | Acc: 0.405\n",
            "Test acc:  36.47090859580648\n",
            "Test loss:  1.6355896299285007\n",
            "BEST TEST LOSS:  1.6318454198065522\n",
            "Epoch 29: | Loss: 1.53512 | Acc: 0.407\n",
            "Test acc:  36.87029136788599\n",
            "Test loss:  1.6210934488759565\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6210934488759565\n",
            "Epoch 30: | Loss: 1.52276 | Acc: 0.413\n",
            "Test acc:  37.178905328129254\n",
            "Test loss:  1.6250738229365707\n",
            "BEST TEST LOSS:  1.6210934488759565\n",
            "Epoch 31: | Loss: 1.51119 | Acc: 0.420\n",
            "Test acc:  37.478442407188886\n",
            "Test loss:  1.6209604843503478\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6209604843503478\n",
            "Epoch 32: | Loss: 1.50255 | Acc: 0.421\n",
            "Test acc:  37.44213488245439\n",
            "Test loss:  1.619913445042737\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.619913445042737\n",
            "Epoch 33: | Loss: 1.49836 | Acc: 0.423\n",
            "Test acc:  37.44213488245439\n",
            "Test loss:  1.609667001432077\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.609667001432077\n",
            "Epoch 34: | Loss: 1.48852 | Acc: 0.428\n",
            "Test acc:  37.41490423890351\n",
            "Test loss:  1.619312044513019\n",
            "BEST TEST LOSS:  1.609667001432077\n",
            "Epoch 35: | Loss: 1.47717 | Acc: 0.430\n",
            "Test acc:  36.86121448670237\n",
            "Test loss:  1.6252564639714413\n",
            "BEST TEST LOSS:  1.609667001432077\n",
            "Epoch 36: | Loss: 1.46662 | Acc: 0.441\n",
            "Test acc:  37.63274938731052\n",
            "Test loss:  1.6079912785160748\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6079912785160748\n",
            "Epoch 37: | Loss: 1.46609 | Acc: 0.441\n",
            "Test acc:  38.01397839702278\n",
            "Test loss:  1.6116607168506336\n",
            "BEST TEST LOSS:  1.6079912785160748\n",
            "Epoch 38: | Loss: 1.45328 | Acc: 0.447\n",
            "Test acc:  37.895978941635654\n",
            "Test loss:  1.6088114453188946\n",
            "BEST TEST LOSS:  1.6079912785160748\n",
            "Epoch 39: | Loss: 1.44651 | Acc: 0.443\n",
            "Test acc:  37.968593991104655\n",
            "Test loss:  1.61165624615774\n",
            "Early stopping at epoch 40\n",
            "BEST TEST LOSS:  1.6079912785160748\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.80509 | Acc: 0.263\n",
            "Test acc:  27.194336026141418\n",
            "Test loss:  1.7745438307181172\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7745438307181172\n",
            "Epoch 1: | Loss: 1.76524 | Acc: 0.282\n",
            "Test acc:  28.38340746119633\n",
            "Test loss:  1.7552023057279915\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7552023057279915\n",
            "Epoch 2: | Loss: 1.74917 | Acc: 0.290\n",
            "Test acc:  29.708632114005628\n",
            "Test loss:  1.7456211879335601\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7456211879335601\n",
            "Epoch 3: | Loss: 1.72433 | Acc: 0.304\n",
            "Test acc:  32.35908141962422\n",
            "Test loss:  1.6989798723966225\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6989798723966225\n",
            "Epoch 4: | Loss: 1.68484 | Acc: 0.329\n",
            "Test acc:  32.867386765907234\n",
            "Test loss:  1.6751611657526302\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6751611657526302\n",
            "Epoch 5: | Loss: 1.64582 | Acc: 0.347\n",
            "Test acc:  33.629844785331755\n",
            "Test loss:  1.6749998701029811\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6749998701029811\n",
            "Epoch 6: | Loss: 1.63656 | Acc: 0.357\n",
            "Test acc:  36.1532177543796\n",
            "Test loss:  1.6355663483170257\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6355663483170257\n",
            "Epoch 7: | Loss: 1.61314 | Acc: 0.365\n",
            "Test acc:  35.18199146773169\n",
            "Test loss:  1.6410464075790054\n",
            "BEST TEST LOSS:  1.6355663483170257\n",
            "Epoch 8: | Loss: 1.58895 | Acc: 0.376\n",
            "Test acc:  37.505673050739766\n",
            "Test loss:  1.608280897140503\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.608280897140503\n",
            "Epoch 9: | Loss: 1.57280 | Acc: 0.388\n",
            "Test acc:  36.95198329853862\n",
            "Test loss:  1.6130181235828618\n",
            "BEST TEST LOSS:  1.608280897140503\n",
            "Epoch 10: | Loss: 1.55327 | Acc: 0.399\n",
            "Test acc:  37.75982572388127\n",
            "Test loss:  1.6001295810458305\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6001295810458305\n",
            "Epoch 11: | Loss: 1.54095 | Acc: 0.400\n",
            "Test acc:  38.82182082236543\n",
            "Test loss:  1.5920725005796585\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5920725005796585\n",
            "Epoch 12: | Loss: 1.51954 | Acc: 0.412\n",
            "Test acc:  38.77643641644731\n",
            "Test loss:  1.5775095703958095\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5775095703958095\n",
            "Epoch 13: | Loss: 1.49673 | Acc: 0.420\n",
            "Test acc:  38.712898248161935\n",
            "Test loss:  1.5804389523363662\n",
            "BEST TEST LOSS:  1.5775095703958095\n",
            "Epoch 14: | Loss: 1.48964 | Acc: 0.421\n",
            "Test acc:  38.758282654080055\n",
            "Test loss:  1.5965440547329255\n",
            "BEST TEST LOSS:  1.5775095703958095\n",
            "Epoch 15: | Loss: 1.46959 | Acc: 0.431\n",
            "Test acc:  39.13951166379232\n",
            "Test loss:  1.576460098398143\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.576460098398143\n",
            "Epoch 16: | Loss: 1.46029 | Acc: 0.436\n",
            "Test acc:  38.96705092130344\n",
            "Test loss:  1.5802706836283893\n",
            "BEST TEST LOSS:  1.576460098398143\n",
            "Epoch 17: | Loss: 1.44433 | Acc: 0.437\n",
            "Test acc:  39.520740673504584\n",
            "Test loss:  1.5837569497097497\n",
            "BEST TEST LOSS:  1.576460098398143\n",
            "Epoch 18: | Loss: 1.42285 | Acc: 0.448\n",
            "Test acc:  38.92166651538531\n",
            "Test loss:  1.6064004144449344\n",
            "Early stopping at epoch 19\n",
            "BEST TEST LOSS:  1.576460098398143\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.79978 | Acc: 0.268\n",
            "Test acc:  28.401561223563583\n",
            "Test loss:  1.7730801228819222\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7730801228819222\n",
            "Epoch 1: | Loss: 1.76645 | Acc: 0.283\n",
            "Test acc:  28.41971498593083\n",
            "Test loss:  1.7577917603240616\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7577917603240616\n",
            "Epoch 2: | Loss: 1.75325 | Acc: 0.289\n",
            "Test acc:  29.626940183353\n",
            "Test loss:  1.7388208529044842\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7388208529044842\n",
            "Epoch 3: | Loss: 1.72951 | Acc: 0.300\n",
            "Test acc:  31.750930380321325\n",
            "Test loss:  1.7096966970926044\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7096966970926044\n",
            "Epoch 4: | Loss: 1.70014 | Acc: 0.323\n",
            "Test acc:  33.13061632023237\n",
            "Test loss:  1.6842550272229073\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6842550272229073\n",
            "Epoch 5: | Loss: 1.66658 | Acc: 0.345\n",
            "Test acc:  34.70091676499955\n",
            "Test loss:  1.6596392694560962\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6596392694560962\n",
            "Epoch 6: | Loss: 1.63900 | Acc: 0.356\n",
            "Test acc:  34.7916855768358\n",
            "Test loss:  1.6479283543838852\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6479283543838852\n",
            "Epoch 7: | Loss: 1.62697 | Acc: 0.364\n",
            "Test acc:  35.52691295270945\n",
            "Test loss:  1.6554045074287502\n",
            "BEST TEST LOSS:  1.6479283543838852\n",
            "Epoch 8: | Loss: 1.60506 | Acc: 0.373\n",
            "Test acc:  37.796133248615774\n",
            "Test loss:  1.6123668434976162\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6123668434976162\n",
            "Epoch 9: | Loss: 1.57897 | Acc: 0.386\n",
            "Test acc:  36.57983117000999\n",
            "Test loss:  1.6259464463968387\n",
            "BEST TEST LOSS:  1.6123668434976162\n",
            "Epoch 10: | Loss: 1.56828 | Acc: 0.393\n",
            "Test acc:  38.11382409004266\n",
            "Test loss:  1.621955560541701\n",
            "BEST TEST LOSS:  1.6123668434976162\n",
            "Epoch 11: | Loss: 1.55957 | Acc: 0.396\n",
            "Test acc:  38.957974040119815\n",
            "Test loss:  1.590536214839453\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.590536214839453\n",
            "Epoch 12: | Loss: 1.55681 | Acc: 0.396\n",
            "Test acc:  38.712898248161935\n",
            "Test loss:  1.584782074237692\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.584782074237692\n",
            "Epoch 13: | Loss: 1.53157 | Acc: 0.404\n",
            "Test acc:  38.885358990650815\n",
            "Test loss:  1.5988801046349537\n",
            "BEST TEST LOSS:  1.584782074237692\n",
            "Epoch 14: | Loss: 1.51520 | Acc: 0.415\n",
            "Test acc:  39.09412725787419\n",
            "Test loss:  1.6154342944594635\n",
            "BEST TEST LOSS:  1.584782074237692\n",
            "Epoch 15: | Loss: 1.50144 | Acc: 0.419\n",
            "Test acc:  38.712898248161935\n",
            "Test loss:  1.6054166390978057\n",
            "Early stopping at epoch 16\n",
            "BEST TEST LOSS:  1.584782074237692\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.81641 | Acc: 0.258\n",
            "Test acc:  27.18525914495779\n",
            "Test loss:  1.7980829121052533\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7980829121052533\n",
            "Epoch 1: | Loss: 1.78386 | Acc: 0.276\n",
            "Test acc:  27.394027412181178\n",
            "Test loss:  1.7809297380776241\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7809297380776241\n",
            "Epoch 2: | Loss: 1.78077 | Acc: 0.276\n",
            "Test acc:  27.856948352546063\n",
            "Test loss:  1.7729812874191109\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7729812874191109\n",
            "Epoch 3: | Loss: 1.76770 | Acc: 0.280\n",
            "Test acc:  28.18371607515658\n",
            "Test loss:  1.765578269958496\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.765578269958496\n",
            "Epoch 4: | Loss: 1.75424 | Acc: 0.287\n",
            "Test acc:  29.109557955886356\n",
            "Test loss:  1.7586664564308079\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7586664564308079\n",
            "Epoch 5: | Loss: 1.74044 | Acc: 0.290\n",
            "Test acc:  28.692021421439595\n",
            "Test loss:  1.7539346697686733\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7539346697686733\n",
            "Epoch 6: | Loss: 1.72554 | Acc: 0.307\n",
            "Test acc:  30.90678043024417\n",
            "Test loss:  1.7105629978508785\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7105629978508785\n",
            "Epoch 7: | Loss: 1.71255 | Acc: 0.311\n",
            "Test acc:  30.14432241081964\n",
            "Test loss:  1.7283014429026637\n",
            "BEST TEST LOSS:  1.7105629978508785\n",
            "Epoch 8: | Loss: 1.70698 | Acc: 0.316\n",
            "Test acc:  32.38631206317509\n",
            "Test loss:  1.6901134458081475\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6901134458081475\n",
            "Epoch 9: | Loss: 1.67972 | Acc: 0.335\n",
            "Test acc:  33.88399745847327\n",
            "Test loss:  1.6815874083288784\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6815874083288784\n",
            "Epoch 10: | Loss: 1.66233 | Acc: 0.341\n",
            "Test acc:  34.72814740855042\n",
            "Test loss:  1.6622685194015503\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6622685194015503\n",
            "Epoch 11: | Loss: 1.64977 | Acc: 0.349\n",
            "Test acc:  34.9006081510393\n",
            "Test loss:  1.657774108579789\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.657774108579789\n",
            "Epoch 12: | Loss: 1.64364 | Acc: 0.356\n",
            "Test acc:  34.67368612144867\n",
            "Test loss:  1.6591630132719017\n",
            "BEST TEST LOSS:  1.657774108579789\n",
            "Epoch 13: | Loss: 1.63017 | Acc: 0.359\n",
            "Test acc:  34.44676409185804\n",
            "Test loss:  1.6531102122931645\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6531102122931645\n",
            "Epoch 14: | Loss: 1.60300 | Acc: 0.369\n",
            "Test acc:  35.91721884360533\n",
            "Test loss:  1.637889340006072\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.637889340006072\n",
            "Epoch 15: | Loss: 1.59853 | Acc: 0.374\n",
            "Test acc:  36.18044839793047\n",
            "Test loss:  1.641044605737445\n",
            "BEST TEST LOSS:  1.637889340006072\n",
            "Epoch 16: | Loss: 1.59052 | Acc: 0.381\n",
            "Test acc:  36.42552418988835\n",
            "Test loss:  1.6283229945719928\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6283229945719928\n",
            "Epoch 17: | Loss: 1.57581 | Acc: 0.385\n",
            "Test acc:  35.42706725968957\n",
            "Test loss:  1.6200381298174804\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6200381298174804\n",
            "Epoch 18: | Loss: 1.56782 | Acc: 0.388\n",
            "Test acc:  37.20613597168013\n",
            "Test loss:  1.6078848194801945\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6078848194801945\n",
            "Epoch 19: | Loss: 1.56097 | Acc: 0.392\n",
            "Test acc:  37.81428701098303\n",
            "Test loss:  1.5976291579761723\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5976291579761723\n",
            "Epoch 20: | Loss: 1.54129 | Acc: 0.396\n",
            "Test acc:  37.433058001270766\n",
            "Test loss:  1.6147240235887725\n",
            "BEST TEST LOSS:  1.5976291579761723\n",
            "Epoch 21: | Loss: 1.53236 | Acc: 0.404\n",
            "Test acc:  38.27720795134792\n",
            "Test loss:  1.6272328160274987\n",
            "BEST TEST LOSS:  1.5976291579761723\n",
            "Epoch 22: | Loss: 1.51976 | Acc: 0.410\n",
            "Test acc:  38.57674503040755\n",
            "Test loss:  1.5812925251050927\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5812925251050927\n",
            "Epoch 23: | Loss: 1.50625 | Acc: 0.414\n",
            "Test acc:  38.27720795134792\n",
            "Test loss:  1.5970936575155148\n",
            "BEST TEST LOSS:  1.5812925251050927\n",
            "Epoch 24: | Loss: 1.48621 | Acc: 0.421\n",
            "Test acc:  38.57674503040755\n",
            "Test loss:  1.5890523578928806\n",
            "BEST TEST LOSS:  1.5812925251050927\n",
            "Epoch 25: | Loss: 1.47871 | Acc: 0.426\n",
            "Test acc:  37.66905691204502\n",
            "Test loss:  1.599524648710229\n",
            "Early stopping at epoch 26\n",
            "BEST TEST LOSS:  1.5812925251050927\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.82962 | Acc: 0.243\n",
            "Test acc:  26.86756830353091\n",
            "Test loss:  1.7877237029459285\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7877237029459285\n",
            "Epoch 1: | Loss: 1.77616 | Acc: 0.280\n",
            "Test acc:  27.920486520831446\n",
            "Test loss:  1.7707319794030025\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7707319794030025\n",
            "Epoch 2: | Loss: 1.75768 | Acc: 0.293\n",
            "Test acc:  29.027866025233727\n",
            "Test loss:  1.757401203287059\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.757401203287059\n",
            "Epoch 3: | Loss: 1.74829 | Acc: 0.297\n",
            "Test acc:  29.055096668784607\n",
            "Test loss:  1.7545912334288674\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7545912334288674\n",
            "Epoch 4: | Loss: 1.73903 | Acc: 0.302\n",
            "Test acc:  29.681401470454748\n",
            "Test loss:  1.7416030785133099\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7416030785133099\n",
            "Epoch 5: | Loss: 1.72621 | Acc: 0.307\n",
            "Test acc:  31.1700099845693\n",
            "Test loss:  1.7320817489733642\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7320817489733642\n",
            "Epoch 6: | Loss: 1.71669 | Acc: 0.315\n",
            "Test acc:  31.57846963783244\n",
            "Test loss:  1.7212595638187451\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7212595638187451\n",
            "Epoch 7: | Loss: 1.70008 | Acc: 0.325\n",
            "Test acc:  31.78723790505582\n",
            "Test loss:  1.7086122652579998\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7086122652579998\n",
            "Epoch 8: | Loss: 1.68637 | Acc: 0.334\n",
            "Test acc:  32.81292547880548\n",
            "Test loss:  1.6965948151445938\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6965948151445938\n",
            "Epoch 9: | Loss: 1.66976 | Acc: 0.342\n",
            "Test acc:  33.47553780521013\n",
            "Test loss:  1.6896387544171563\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6896387544171563\n",
            "Epoch 10: | Loss: 1.65589 | Acc: 0.349\n",
            "Test acc:  33.59353726059726\n",
            "Test loss:  1.6767659625787845\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6767659625787845\n",
            "Epoch 11: | Loss: 1.63705 | Acc: 0.361\n",
            "Test acc:  33.847689933738764\n",
            "Test loss:  1.6585072251572006\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6585072251572006\n",
            "Epoch 12: | Loss: 1.62414 | Acc: 0.365\n",
            "Test acc:  35.60860488336208\n",
            "Test loss:  1.6494728244584183\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6494728244584183\n",
            "Epoch 13: | Loss: 1.60478 | Acc: 0.375\n",
            "Test acc:  35.27276027956794\n",
            "Test loss:  1.6401940940440387\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6401940940440387\n",
            "Epoch 14: | Loss: 1.59099 | Acc: 0.382\n",
            "Test acc:  36.57983117000999\n",
            "Test loss:  1.6281975384416252\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6281975384416252\n",
            "Epoch 15: | Loss: 1.57845 | Acc: 0.387\n",
            "Test acc:  36.52536988290823\n",
            "Test loss:  1.622611700803384\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.622611700803384\n",
            "Epoch 16: | Loss: 1.56674 | Acc: 0.392\n",
            "Test acc:  37.1244440410275\n",
            "Test loss:  1.6213632479481312\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6213632479481312\n",
            "Epoch 17: | Loss: 1.55110 | Acc: 0.402\n",
            "Test acc:  37.66905691204502\n",
            "Test loss:  1.6165726541102619\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6165726541102619\n",
            "Epoch 18: | Loss: 1.53815 | Acc: 0.407\n",
            "Test acc:  37.92320958518653\n",
            "Test loss:  1.605526265056654\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.605526265056654\n",
            "Epoch 19: | Loss: 1.52287 | Acc: 0.412\n",
            "Test acc:  37.7689026050649\n",
            "Test loss:  1.6078828682844666\n",
            "BEST TEST LOSS:  1.605526265056654\n",
            "Epoch 20: | Loss: 1.51107 | Acc: 0.420\n",
            "Test acc:  38.08659344649178\n",
            "Test loss:  1.5988518492928867\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5988518492928867\n",
            "Epoch 21: | Loss: 1.50141 | Acc: 0.424\n",
            "Test acc:  38.068439684124534\n",
            "Test loss:  1.5952904731377788\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5952904731377788\n",
            "Epoch 22: | Loss: 1.49309 | Acc: 0.425\n",
            "Test acc:  38.6312063175093\n",
            "Test loss:  1.5908693308117745\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5908693308117745\n",
            "Epoch 23: | Loss: 1.47712 | Acc: 0.432\n",
            "Test acc:  38.095670327675414\n",
            "Test loss:  1.590744444693642\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.590744444693642\n",
            "Epoch 24: | Loss: 1.46808 | Acc: 0.437\n",
            "Test acc:  38.27720795134792\n",
            "Test loss:  1.600689328950027\n",
            "BEST TEST LOSS:  1.590744444693642\n",
            "Epoch 25: | Loss: 1.45783 | Acc: 0.440\n",
            "Test acc:  38.82182082236543\n",
            "Test loss:  1.5895656128039306\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5895656128039306\n",
            "Epoch 26: | Loss: 1.44692 | Acc: 0.449\n",
            "Test acc:  38.240900426613415\n",
            "Test loss:  1.5920901517758423\n",
            "BEST TEST LOSS:  1.5895656128039306\n",
            "Epoch 27: | Loss: 1.43484 | Acc: 0.453\n",
            "Test acc:  38.785513297630935\n",
            "Test loss:  1.5906319864865006\n",
            "BEST TEST LOSS:  1.5895656128039306\n",
            "Epoch 28: | Loss: 1.42490 | Acc: 0.454\n",
            "Test acc:  38.72197512934556\n",
            "Test loss:  1.5863488391898144\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5863488391898144\n",
            "Epoch 29: | Loss: 1.41112 | Acc: 0.460\n",
            "Test acc:  39.95643097031859\n",
            "Test loss:  1.5881203221178604\n",
            "BEST TEST LOSS:  1.5863488391898144\n",
            "Epoch 30: | Loss: 1.40389 | Acc: 0.464\n",
            "Test acc:  38.92166651538531\n",
            "Test loss:  1.5823296705881755\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5823296705881755\n",
            "Epoch 31: | Loss: 1.39528 | Acc: 0.470\n",
            "Test acc:  39.58427884178996\n",
            "Test loss:  1.578543113565993\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.578543113565993\n",
            "Epoch 32: | Loss: 1.38386 | Acc: 0.472\n",
            "Test acc:  38.758282654080055\n",
            "Test loss:  1.5910510235819324\n",
            "BEST TEST LOSS:  1.578543113565993\n",
            "Epoch 33: | Loss: 1.36830 | Acc: 0.476\n",
            "Test acc:  39.37551057456658\n",
            "Test loss:  1.591756504157494\n",
            "BEST TEST LOSS:  1.578543113565993\n",
            "Epoch 34: | Loss: 1.36265 | Acc: 0.482\n",
            "Test acc:  39.58427884178996\n",
            "Test loss:  1.5931628298485416\n",
            "Early stopping at epoch 35\n",
            "BEST TEST LOSS:  1.578543113565993\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.81749 | Acc: 0.260\n",
            "Test acc:  27.158028501406918\n",
            "Test loss:  1.7774030381235584\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7774030381235584\n",
            "Epoch 1: | Loss: 1.76928 | Acc: 0.282\n",
            "Test acc:  29.545248252700375\n",
            "Test loss:  1.7568228148865974\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7568228148865974\n",
            "Epoch 2: | Loss: 1.74961 | Acc: 0.296\n",
            "Test acc:  29.862939094127256\n",
            "Test loss:  1.7458307386814862\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7458307386814862\n",
            "Epoch 3: | Loss: 1.73590 | Acc: 0.301\n",
            "Test acc:  30.434782608695656\n",
            "Test loss:  1.7370833336621865\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7370833336621865\n",
            "Epoch 4: | Loss: 1.72328 | Acc: 0.308\n",
            "Test acc:  30.353090678043028\n",
            "Test loss:  1.735774469101566\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.735774469101566\n",
            "Epoch 5: | Loss: 1.71215 | Acc: 0.315\n",
            "Test acc:  31.469547063628937\n",
            "Test loss:  1.7180515007040966\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7180515007040966\n",
            "Epoch 6: | Loss: 1.69644 | Acc: 0.325\n",
            "Test acc:  32.304620132522466\n",
            "Test loss:  1.704986665440702\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.704986665440702\n",
            "Epoch 7: | Loss: 1.68085 | Acc: 0.336\n",
            "Test acc:  32.6767722610511\n",
            "Test loss:  1.692852721817192\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.692852721817192\n",
            "Epoch 8: | Loss: 1.66475 | Acc: 0.344\n",
            "Test acc:  33.64799854769901\n",
            "Test loss:  1.681432930902503\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.681432930902503\n",
            "Epoch 9: | Loss: 1.64654 | Acc: 0.355\n",
            "Test acc:  34.19261141871653\n",
            "Test loss:  1.6728774733927059\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6728774733927059\n",
            "Epoch 10: | Loss: 1.62742 | Acc: 0.363\n",
            "Test acc:  34.837069982753924\n",
            "Test loss:  1.6628915715491634\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6628915715491634\n",
            "Epoch 11: | Loss: 1.60772 | Acc: 0.375\n",
            "Test acc:  35.88998820005446\n",
            "Test loss:  1.6545004159554668\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6545004159554668\n",
            "Epoch 12: | Loss: 1.58979 | Acc: 0.381\n",
            "Test acc:  36.50721612054098\n",
            "Test loss:  1.6371411318066476\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6371411318066476\n",
            "Epoch 13: | Loss: 1.56966 | Acc: 0.393\n",
            "Test acc:  36.56167740764273\n",
            "Test loss:  1.6308872494204292\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6308872494204292\n",
            "Epoch 14: | Loss: 1.55441 | Acc: 0.402\n",
            "Test acc:  36.57983117000999\n",
            "Test loss:  1.619243909572733\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.619243909572733\n",
            "Epoch 15: | Loss: 1.53438 | Acc: 0.409\n",
            "Test acc:  37.56013433784152\n",
            "Test loss:  1.6090337805364323\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6090337805364323\n",
            "Epoch 16: | Loss: 1.51901 | Acc: 0.413\n",
            "Test acc:  37.28782790233276\n",
            "Test loss:  1.615409470152581\n",
            "BEST TEST LOSS:  1.6090337805364323\n",
            "Epoch 17: | Loss: 1.50414 | Acc: 0.419\n",
            "Test acc:  38.02305527820641\n",
            "Test loss:  1.6089353465485847\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6089353465485847\n",
            "Epoch 18: | Loss: 1.48948 | Acc: 0.426\n",
            "Test acc:  38.3770536443678\n",
            "Test loss:  1.6029709043173954\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6029709043173954\n",
            "Epoch 19: | Loss: 1.47199 | Acc: 0.436\n",
            "Test acc:  38.82182082236543\n",
            "Test loss:  1.5963927411484993\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5963927411484993\n",
            "Epoch 20: | Loss: 1.45989 | Acc: 0.442\n",
            "Test acc:  37.68721067441227\n",
            "Test loss:  1.607429179651984\n",
            "BEST TEST LOSS:  1.5963927411484993\n",
            "Epoch 21: | Loss: 1.44129 | Acc: 0.445\n",
            "Test acc:  38.53136062448942\n",
            "Test loss:  1.5974531118897186\n",
            "BEST TEST LOSS:  1.5963927411484993\n",
            "Epoch 22: | Loss: 1.42138 | Acc: 0.456\n",
            "Test acc:  38.23182354542979\n",
            "Test loss:  1.600403066339164\n",
            "Early stopping at epoch 23\n",
            "BEST TEST LOSS:  1.5963927411484993\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.81875 | Acc: 0.256\n",
            "Test acc:  27.049105927203414\n",
            "Test loss:  1.7750414815442315\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7750414815442315\n",
            "Epoch 1: | Loss: 1.76407 | Acc: 0.283\n",
            "Test acc:  28.746482708541343\n",
            "Test loss:  1.7580848603413022\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7580848603413022\n",
            "Epoch 2: | Loss: 1.74516 | Acc: 0.297\n",
            "Test acc:  29.654170826903876\n",
            "Test loss:  1.7402745553816872\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7402745553816872\n",
            "Epoch 3: | Loss: 1.72547 | Acc: 0.306\n",
            "Test acc:  30.634473994735412\n",
            "Test loss:  1.7271661566591812\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7271661566591812\n",
            "Epoch 4: | Loss: 1.70124 | Acc: 0.323\n",
            "Test acc:  32.93092493419261\n",
            "Test loss:  1.694916131852687\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.694916131852687\n",
            "Epoch 5: | Loss: 1.67247 | Acc: 0.336\n",
            "Test acc:  34.24707270581828\n",
            "Test loss:  1.6762987156023925\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6762987156023925\n",
            "Epoch 6: | Loss: 1.64738 | Acc: 0.348\n",
            "Test acc:  34.74630117091767\n",
            "Test loss:  1.6605379060767163\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6605379060767163\n",
            "Epoch 7: | Loss: 1.62132 | Acc: 0.367\n",
            "Test acc:  35.481528546791324\n",
            "Test loss:  1.6406530909154606\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6406530909154606\n",
            "Epoch 8: | Loss: 1.60133 | Acc: 0.375\n",
            "Test acc:  35.998910774257965\n",
            "Test loss:  1.636319768839869\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.636319768839869\n",
            "Epoch 9: | Loss: 1.57911 | Acc: 0.385\n",
            "Test acc:  37.26967413996551\n",
            "Test loss:  1.613670397078854\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.613670397078854\n",
            "Epoch 10: | Loss: 1.54782 | Acc: 0.398\n",
            "Test acc:  36.942906417355\n",
            "Test loss:  1.6123802237127018\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6123802237127018\n",
            "Epoch 11: | Loss: 1.53347 | Acc: 0.405\n",
            "Test acc:  37.74167196151402\n",
            "Test loss:  1.612532011393843\n",
            "BEST TEST LOSS:  1.6123802237127018\n",
            "Epoch 12: | Loss: 1.50816 | Acc: 0.418\n",
            "Test acc:  39.03966597077244\n",
            "Test loss:  1.6038375531119862\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6038375531119862\n",
            "Epoch 13: | Loss: 1.48817 | Acc: 0.423\n",
            "Test acc:  37.777979486248526\n",
            "Test loss:  1.600541782105106\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.600541782105106\n",
            "Epoch 14: | Loss: 1.47663 | Acc: 0.428\n",
            "Test acc:  38.38613052555142\n",
            "Test loss:  1.5934753623502007\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5934753623502007\n",
            "Epoch 15: | Loss: 1.45159 | Acc: 0.441\n",
            "Test acc:  39.448125624035576\n",
            "Test loss:  1.5817579209119423\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.5817579209119423\n",
            "Epoch 16: | Loss: 1.43327 | Acc: 0.451\n",
            "Test acc:  39.420894980484704\n",
            "Test loss:  1.576900132771196\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.576900132771196\n",
            "Epoch 17: | Loss: 1.41845 | Acc: 0.456\n",
            "Test acc:  38.957974040119815\n",
            "Test loss:  1.5877400965526187\n",
            "BEST TEST LOSS:  1.576900132771196\n",
            "Epoch 18: | Loss: 1.40291 | Acc: 0.463\n",
            "Test acc:  38.91258963420169\n",
            "Test loss:  1.6226929727642017\n",
            "BEST TEST LOSS:  1.576900132771196\n",
            "Epoch 19: | Loss: 1.38934 | Acc: 0.464\n",
            "Test acc:  38.60397567395843\n",
            "Test loss:  1.590437334159325\n",
            "Early stopping at epoch 20\n",
            "BEST TEST LOSS:  1.576900132771196\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.93867 | Acc: 0.191\n",
            "Test acc:  21.46682399927385\n",
            "Test loss:  1.8714535633722942\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8714535633722942\n",
            "Epoch 1: | Loss: 1.85311 | Acc: 0.230\n",
            "Test acc:  24.398656621584824\n",
            "Test loss:  1.8394077303765834\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8394077303765834\n",
            "Epoch 2: | Loss: 1.83163 | Acc: 0.244\n",
            "Test acc:  25.16111464100935\n",
            "Test loss:  1.823781449219276\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.823781449219276\n",
            "Epoch 3: | Loss: 1.82187 | Acc: 0.252\n",
            "Test acc:  25.460651720068984\n",
            "Test loss:  1.8153065662274415\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8153065662274415\n",
            "Epoch 4: | Loss: 1.81247 | Acc: 0.260\n",
            "Test acc:  25.787419442679493\n",
            "Test loss:  1.807671611336456\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.807671611336456\n",
            "Epoch 5: | Loss: 1.80247 | Acc: 0.263\n",
            "Test acc:  26.849414541163657\n",
            "Test loss:  1.8017797264559516\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8017797264559516\n",
            "Epoch 6: | Loss: 1.79770 | Acc: 0.268\n",
            "Test acc:  26.695107561042025\n",
            "Test loss:  1.7960824418341976\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7960824418341976\n",
            "Epoch 7: | Loss: 1.79104 | Acc: 0.270\n",
            "Test acc:  27.248797313243166\n",
            "Test loss:  1.7862425508170292\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7862425508170292\n",
            "Epoch 8: | Loss: 1.78664 | Acc: 0.275\n",
            "Test acc:  27.375873649813926\n",
            "Test loss:  1.785340135124908\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.785340135124908\n",
            "Epoch 9: | Loss: 1.78476 | Acc: 0.275\n",
            "Test acc:  27.41218117454843\n",
            "Test loss:  1.7874445654880042\n",
            "BEST TEST LOSS:  1.785340135124908\n",
            "Epoch 10: | Loss: 1.77936 | Acc: 0.278\n",
            "Test acc:  27.303258600344922\n",
            "Test loss:  1.7837721081985825\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7837721081985825\n",
            "Epoch 11: | Loss: 1.77790 | Acc: 0.280\n",
            "Test acc:  27.294181719161298\n",
            "Test loss:  1.7822012545048505\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7822012545048505\n",
            "Epoch 12: | Loss: 1.77652 | Acc: 0.281\n",
            "Test acc:  27.911409639647815\n",
            "Test loss:  1.773821551224281\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.773821551224281\n",
            "Epoch 13: | Loss: 1.77310 | Acc: 0.282\n",
            "Test acc:  27.802487065444314\n",
            "Test loss:  1.77723507908569\n",
            "BEST TEST LOSS:  1.773821551224281\n",
            "Epoch 14: | Loss: 1.76678 | Acc: 0.288\n",
            "Test acc:  27.81156394662794\n",
            "Test loss:  1.7739664466901757\n",
            "BEST TEST LOSS:  1.773821551224281\n",
            "Epoch 15: | Loss: 1.76615 | Acc: 0.282\n",
            "Test acc:  28.437868748298083\n",
            "Test loss:  1.7732007476105087\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7732007476105087\n",
            "Epoch 16: | Loss: 1.76406 | Acc: 0.285\n",
            "Test acc:  28.120177906871195\n",
            "Test loss:  1.7687114641584198\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7687114641584198\n",
            "Epoch 17: | Loss: 1.76227 | Acc: 0.290\n",
            "Test acc:  28.474176273032587\n",
            "Test loss:  1.7684786388243752\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7684786388243752\n",
            "Epoch 18: | Loss: 1.75991 | Acc: 0.290\n",
            "Test acc:  28.537714441317963\n",
            "Test loss:  1.7653156751873849\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7653156751873849\n",
            "Epoch 19: | Loss: 1.75674 | Acc: 0.289\n",
            "Test acc:  28.60125260960334\n",
            "Test loss:  1.7687929032862872\n",
            "BEST TEST LOSS:  1.7653156751873849\n",
            "Epoch 20: | Loss: 1.75415 | Acc: 0.294\n",
            "Test acc:  28.900789688662975\n",
            "Test loss:  1.7669743367995339\n",
            "BEST TEST LOSS:  1.7653156751873849\n",
            "Epoch 21: | Loss: 1.75432 | Acc: 0.292\n",
            "Test acc:  28.365253698829086\n",
            "Test loss:  1.7591063674839063\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7591063674839063\n",
            "Epoch 22: | Loss: 1.75167 | Acc: 0.294\n",
            "Test acc:  28.692021421439595\n",
            "Test loss:  1.765803376833598\n",
            "BEST TEST LOSS:  1.7591063674839063\n",
            "Epoch 23: | Loss: 1.75246 | Acc: 0.293\n",
            "Test acc:  28.764636470908595\n",
            "Test loss:  1.7609690934762188\n",
            "BEST TEST LOSS:  1.7591063674839063\n",
            "Epoch 24: | Loss: 1.74803 | Acc: 0.294\n",
            "Test acc:  29.06417354996823\n",
            "Test loss:  1.7582443240045131\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7582443240045131\n",
            "Epoch 25: | Loss: 1.74412 | Acc: 0.302\n",
            "Test acc:  29.091404193519104\n",
            "Test loss:  1.7582294379157581\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7582294379157581\n",
            "Epoch 26: | Loss: 1.74362 | Acc: 0.302\n",
            "Test acc:  29.218480530089863\n",
            "Test loss:  1.755272325428053\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.755272325428053\n",
            "Epoch 27: | Loss: 1.74556 | Acc: 0.301\n",
            "Test acc:  29.327403104293364\n",
            "Test loss:  1.7537032215074562\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7537032215074562\n",
            "Epoch 28: | Loss: 1.74144 | Acc: 0.304\n",
            "Test acc:  29.28201869837524\n",
            "Test loss:  1.7533341892834367\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7533341892834367\n",
            "Epoch 29: | Loss: 1.74255 | Acc: 0.301\n",
            "Test acc:  29.136788599437235\n",
            "Test loss:  1.753023073591035\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.753023073591035\n",
            "Epoch 30: | Loss: 1.73996 | Acc: 0.301\n",
            "Test acc:  29.336479985476988\n",
            "Test loss:  1.7531875769297283\n",
            "BEST TEST LOSS:  1.753023073591035\n",
            "Epoch 31: | Loss: 1.73525 | Acc: 0.305\n",
            "Test acc:  29.263864936007987\n",
            "Test loss:  1.750830054283142\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.750830054283142\n",
            "Epoch 32: | Loss: 1.73660 | Acc: 0.302\n",
            "Test acc:  29.74493963874013\n",
            "Test loss:  1.7487715619733963\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7487715619733963\n",
            "Epoch 33: | Loss: 1.73204 | Acc: 0.305\n",
            "Test acc:  29.545248252700375\n",
            "Test loss:  1.750648602672007\n",
            "BEST TEST LOSS:  1.7487715619733963\n",
            "Epoch 34: | Loss: 1.73350 | Acc: 0.306\n",
            "Test acc:  29.754016519923752\n",
            "Test loss:  1.747442067354575\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.747442067354575\n",
            "Epoch 35: | Loss: 1.73352 | Acc: 0.307\n",
            "Test acc:  29.917400381229008\n",
            "Test loss:  1.7449755284978055\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7449755284978055\n",
            "Epoch 36: | Loss: 1.72816 | Acc: 0.309\n",
            "Test acc:  29.944631024779884\n",
            "Test loss:  1.7457189806576432\n",
            "BEST TEST LOSS:  1.7449755284978055\n",
            "Epoch 37: | Loss: 1.72611 | Acc: 0.310\n",
            "Test acc:  30.12616864845239\n",
            "Test loss:  1.7398776980652206\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7398776980652206\n",
            "Epoch 38: | Loss: 1.72716 | Acc: 0.308\n",
            "Test acc:  29.617863302169372\n",
            "Test loss:  1.7433200923875831\n",
            "BEST TEST LOSS:  1.7398776980652206\n",
            "Epoch 39: | Loss: 1.72739 | Acc: 0.306\n",
            "Test acc:  29.93555414359626\n",
            "Test loss:  1.7400425590317825\n",
            "BEST TEST LOSS:  1.7398776980652206\n",
            "Epoch 40: | Loss: 1.72315 | Acc: 0.312\n",
            "Test acc:  29.872015975310884\n",
            "Test loss:  1.7418761061525894\n",
            "Early stopping at epoch 41\n",
            "BEST TEST LOSS:  1.7398776980652206\n",
            "Finished Training\n",
            "Epoch 0: | Loss: 1.91407 | Acc: 0.212\n",
            "Test acc:  23.28220023599891\n",
            "Test loss:  1.858331848835123\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.858331848835123\n",
            "Epoch 1: | Loss: 1.84421 | Acc: 0.244\n",
            "Test acc:  26.059725878188257\n",
            "Test loss:  1.828593188318713\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.828593188318713\n",
            "Epoch 2: | Loss: 1.81877 | Acc: 0.258\n",
            "Test acc:  25.87818825451575\n",
            "Test loss:  1.816916373954422\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.816916373954422\n",
            "Epoch 3: | Loss: 1.80727 | Acc: 0.267\n",
            "Test acc:  26.486339293818645\n",
            "Test loss:  1.8025075594584148\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.8025075594584148\n",
            "Epoch 4: | Loss: 1.80068 | Acc: 0.268\n",
            "Test acc:  26.63156939275665\n",
            "Test loss:  1.7989484003220482\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7989484003220482\n",
            "Epoch 5: | Loss: 1.79342 | Acc: 0.272\n",
            "Test acc:  27.058182808387038\n",
            "Test loss:  1.7951414530304657\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7951414530304657\n",
            "Epoch 6: | Loss: 1.78981 | Acc: 0.278\n",
            "Test acc:  27.584641917037306\n",
            "Test loss:  1.7892283625986385\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7892283625986385\n",
            "Epoch 7: | Loss: 1.78194 | Acc: 0.281\n",
            "Test acc:  27.86602523372969\n",
            "Test loss:  1.7780861073526844\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7780861073526844\n",
            "Epoch 8: | Loss: 1.77875 | Acc: 0.280\n",
            "Test acc:  28.229100481074703\n",
            "Test loss:  1.7768507839619427\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7768507839619427\n",
            "Epoch 9: | Loss: 1.76914 | Acc: 0.286\n",
            "Test acc:  28.70109830262322\n",
            "Test loss:  1.7718939233100277\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7718939233100277\n",
            "Epoch 10: | Loss: 1.76758 | Acc: 0.288\n",
            "Test acc:  28.129254788054826\n",
            "Test loss:  1.7684400026825653\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7684400026825653\n",
            "Epoch 11: | Loss: 1.76537 | Acc: 0.293\n",
            "Test acc:  28.664790777888715\n",
            "Test loss:  1.7659179958803901\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7659179958803901\n",
            "Epoch 12: | Loss: 1.76120 | Acc: 0.292\n",
            "Test acc:  28.70109830262322\n",
            "Test loss:  1.7606316859694733\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7606316859694733\n",
            "Epoch 13: | Loss: 1.75375 | Acc: 0.296\n",
            "Test acc:  28.846328401561223\n",
            "Test loss:  1.7625809291313435\n",
            "BEST TEST LOSS:  1.7606316859694733\n",
            "Epoch 14: | Loss: 1.75276 | Acc: 0.295\n",
            "Test acc:  29.136788599437235\n",
            "Test loss:  1.7587649301550854\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7587649301550854\n",
            "Epoch 15: | Loss: 1.75229 | Acc: 0.296\n",
            "Test acc:  29.572478896251248\n",
            "Test loss:  1.7544154559058704\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7544154559058704\n",
            "Epoch 16: | Loss: 1.75336 | Acc: 0.294\n",
            "Test acc:  28.991558500499227\n",
            "Test loss:  1.7595392013418263\n",
            "BEST TEST LOSS:  1.7544154559058704\n",
            "Epoch 17: | Loss: 1.74700 | Acc: 0.301\n",
            "Test acc:  29.5906326586185\n",
            "Test loss:  1.759455637000073\n",
            "BEST TEST LOSS:  1.7544154559058704\n",
            "Epoch 18: | Loss: 1.74700 | Acc: 0.297\n",
            "Test acc:  29.790324044658256\n",
            "Test loss:  1.7517148859199436\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7517148859199436\n",
            "Epoch 19: | Loss: 1.74374 | Acc: 0.303\n",
            "Test acc:  29.980938549514384\n",
            "Test loss:  1.7522044784721287\n",
            "BEST TEST LOSS:  1.7517148859199436\n",
            "Epoch 20: | Loss: 1.73835 | Acc: 0.306\n",
            "Test acc:  29.72678587637288\n",
            "Test loss:  1.7515459937610844\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7515459937610844\n",
            "Epoch 21: | Loss: 1.73674 | Acc: 0.306\n",
            "Test acc:  29.35463374784424\n",
            "Test loss:  1.7461395400694046\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7461395400694046\n",
            "Epoch 22: | Loss: 1.73903 | Acc: 0.302\n",
            "Test acc:  29.654170826903876\n",
            "Test loss:  1.7451582818195737\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7451582818195737\n",
            "Epoch 23: | Loss: 1.73492 | Acc: 0.306\n",
            "Test acc:  29.926477262412636\n",
            "Test loss:  1.7444631861544204\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7444631861544204\n",
            "Epoch 24: | Loss: 1.73221 | Acc: 0.306\n",
            "Test acc:  29.754016519923752\n",
            "Test loss:  1.7456415864242905\n",
            "BEST TEST LOSS:  1.7444631861544204\n",
            "Epoch 25: | Loss: 1.72733 | Acc: 0.310\n",
            "Test acc:  30.089861123717892\n",
            "Test loss:  1.7448115376220352\n",
            "BEST TEST LOSS:  1.7444631861544204\n",
            "Epoch 26: | Loss: 1.72851 | Acc: 0.312\n",
            "Test acc:  29.890169737678136\n",
            "Test loss:  1.7438365015490302\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7438365015490302\n",
            "Epoch 27: | Loss: 1.72359 | Acc: 0.314\n",
            "Test acc:  30.117091767268768\n",
            "Test loss:  1.7408100106250282\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7408100106250282\n",
            "Epoch 28: | Loss: 1.72057 | Acc: 0.315\n",
            "Test acc:  29.990015430698016\n",
            "Test loss:  1.7403298780835907\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7403298780835907\n",
            "Epoch 29: | Loss: 1.72179 | Acc: 0.315\n",
            "Test acc:  30.59816647000091\n",
            "Test loss:  1.737667202949524\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.737667202949524\n",
            "Epoch 30: | Loss: 1.72020 | Acc: 0.315\n",
            "Test acc:  30.679858400653536\n",
            "Test loss:  1.7376531677684566\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7376531677684566\n",
            "Epoch 31: | Loss: 1.71531 | Acc: 0.316\n",
            "Test acc:  30.643550875919033\n",
            "Test loss:  1.7330517988095338\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7330517988095338\n",
            "Epoch 32: | Loss: 1.71577 | Acc: 0.317\n",
            "Test acc:  30.870472905509665\n",
            "Test loss:  1.7374093532562256\n",
            "BEST TEST LOSS:  1.7330517988095338\n",
            "Epoch 33: | Loss: 1.71281 | Acc: 0.319\n",
            "Test acc:  30.816011618407913\n",
            "Test loss:  1.7377583281747226\n",
            "BEST TEST LOSS:  1.7330517988095338\n",
            "Epoch 34: | Loss: 1.71204 | Acc: 0.321\n",
            "Test acc:  30.852319143142417\n",
            "Test loss:  1.731113135129556\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.731113135129556\n",
            "Epoch 35: | Loss: 1.70904 | Acc: 0.324\n",
            "Test acc:  31.1700099845693\n",
            "Test loss:  1.7271691204487591\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7271691204487591\n",
            "Epoch 36: | Loss: 1.70544 | Acc: 0.326\n",
            "Test acc:  31.070164291549425\n",
            "Test loss:  1.7309867869848492\n",
            "BEST TEST LOSS:  1.7271691204487591\n",
            "Epoch 37: | Loss: 1.70650 | Acc: 0.324\n",
            "Test acc:  30.92493419261142\n",
            "Test loss:  1.725099475904443\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.725099475904443\n",
            "Epoch 38: | Loss: 1.69999 | Acc: 0.325\n",
            "Test acc:  31.01570300444767\n",
            "Test loss:  1.7258762847418072\n",
            "BEST TEST LOSS:  1.725099475904443\n",
            "Epoch 39: | Loss: 1.70017 | Acc: 0.329\n",
            "Test acc:  31.151856222202053\n",
            "Test loss:  1.7256231458707787\n",
            "BEST TEST LOSS:  1.725099475904443\n",
            "Epoch 40: | Loss: 1.69699 | Acc: 0.331\n",
            "Test acc:  31.35154760824181\n",
            "Test loss:  1.722712848378324\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.722712848378324\n",
            "Epoch 41: | Loss: 1.69769 | Acc: 0.329\n",
            "Test acc:  31.514931469547065\n",
            "Test loss:  1.718214720145039\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.718214720145039\n",
            "Epoch 42: | Loss: 1.69287 | Acc: 0.331\n",
            "Test acc:  31.78723790505582\n",
            "Test loss:  1.7189979936884738\n",
            "BEST TEST LOSS:  1.718214720145039\n",
            "Epoch 43: | Loss: 1.69049 | Acc: 0.332\n",
            "Test acc:  31.61477716256694\n",
            "Test loss:  1.7179962848794872\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7179962848794872\n",
            "Epoch 44: | Loss: 1.68752 | Acc: 0.333\n",
            "Test acc:  31.732776617954073\n",
            "Test loss:  1.715731738627642\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.715731738627642\n",
            "Epoch 45: | Loss: 1.68511 | Acc: 0.336\n",
            "Test acc:  31.968775528728326\n",
            "Test loss:  1.7146788273734608\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7146788273734608\n",
            "Epoch 46: | Loss: 1.68194 | Acc: 0.337\n",
            "Test acc:  31.8507760733412\n",
            "Test loss:  1.7189049638550857\n",
            "BEST TEST LOSS:  1.7146788273734608\n",
            "Epoch 47: | Loss: 1.68038 | Acc: 0.339\n",
            "Test acc:  31.705545974403194\n",
            "Test loss:  1.710284889429465\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.710284889429465\n",
            "Epoch 48: | Loss: 1.68182 | Acc: 0.339\n",
            "Test acc:  31.878006716892077\n",
            "Test loss:  1.7134637873748253\n",
            "BEST TEST LOSS:  1.710284889429465\n",
            "Epoch 49: | Loss: 1.67569 | Acc: 0.342\n",
            "Test acc:  31.9233911228102\n",
            "Test loss:  1.7099269738142517\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7099269738142517\n",
            "Epoch 50: | Loss: 1.67548 | Acc: 0.345\n",
            "Test acc:  33.07615503313062\n",
            "Test loss:  1.7044505415291622\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7044505415291622\n",
            "Epoch 51: | Loss: 1.66849 | Acc: 0.345\n",
            "Test acc:  32.58600344921485\n",
            "Test loss:  1.706295624546621\n",
            "BEST TEST LOSS:  1.7044505415291622\n",
            "Epoch 52: | Loss: 1.66369 | Acc: 0.347\n",
            "Test acc:  32.38631206317509\n",
            "Test loss:  1.7014500944093727\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.7014500944093727\n",
            "Epoch 53: | Loss: 1.66795 | Acc: 0.346\n",
            "Test acc:  33.185077607334115\n",
            "Test loss:  1.695322514950544\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.695322514950544\n",
            "Epoch 54: | Loss: 1.65960 | Acc: 0.346\n",
            "Test acc:  32.622310973949354\n",
            "Test loss:  1.6957864980588013\n",
            "BEST TEST LOSS:  1.695322514950544\n",
            "Epoch 55: | Loss: 1.65665 | Acc: 0.347\n",
            "Test acc:  33.239538894435874\n",
            "Test loss:  1.700828322048845\n",
            "BEST TEST LOSS:  1.695322514950544\n",
            "Epoch 56: | Loss: 1.65648 | Acc: 0.347\n",
            "Test acc:  33.357538349823\n",
            "Test loss:  1.6925174614478802\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6925174614478802\n",
            "Epoch 57: | Loss: 1.65415 | Acc: 0.353\n",
            "Test acc:  32.967232458927114\n",
            "Test loss:  1.689949856407341\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.689949856407341\n",
            "Epoch 58: | Loss: 1.64953 | Acc: 0.355\n",
            "Test acc:  33.52092221112826\n",
            "Test loss:  1.6875101327896118\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6875101327896118\n",
            "Epoch 59: | Loss: 1.64508 | Acc: 0.357\n",
            "Test acc:  33.76599800308614\n",
            "Test loss:  1.6884650224926827\n",
            "BEST TEST LOSS:  1.6875101327896118\n",
            "Epoch 60: | Loss: 1.64216 | Acc: 0.359\n",
            "Test acc:  33.62076790414814\n",
            "Test loss:  1.68826621154259\n",
            "BEST TEST LOSS:  1.6875101327896118\n",
            "Epoch 61: | Loss: 1.64192 | Acc: 0.359\n",
            "Test acc:  33.756921121902515\n",
            "Test loss:  1.6854166888642585\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6854166888642585\n",
            "Epoch 62: | Loss: 1.63827 | Acc: 0.360\n",
            "Test acc:  33.484614686393755\n",
            "Test loss:  1.6833228667577107\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6833228667577107\n",
            "Epoch 63: | Loss: 1.63366 | Acc: 0.364\n",
            "Test acc:  33.79322864663701\n",
            "Test loss:  1.679592939628952\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.679592939628952\n",
            "Epoch 64: | Loss: 1.62905 | Acc: 0.364\n",
            "Test acc:  34.1472270127984\n",
            "Test loss:  1.6792109272945885\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6792109272945885\n",
            "Epoch 65: | Loss: 1.62437 | Acc: 0.366\n",
            "Test acc:  33.729690478351635\n",
            "Test loss:  1.683174641653039\n",
            "BEST TEST LOSS:  1.6792109272945885\n",
            "Epoch 66: | Loss: 1.62626 | Acc: 0.366\n",
            "Test acc:  34.664609240265044\n",
            "Test loss:  1.6708138098661927\n",
            "MIGLIORATO\n",
            "BEST TEST LOSS:  1.6708138098661927\n"
          ]
        }
      ]
    }
  ]
}